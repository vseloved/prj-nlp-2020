{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Збір та анотування даних  \n",
    "### Опрацюйте один із архівів Wiktionary і витягніть усі синонімні ряди для будь-якої мови. Будь ласка, не обирайте англійську, українську чи російську мови. \n",
    "Был выбран шведский язык.  \n",
    "Пользовался последним дампом - `svwiktionary-latest-pages-articles.xml`  \n",
    "Скрипт - `parsing.py`  \n",
    "Результат выполнения скрипта:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "homework03.ipynb\r\n",
      "official-2014.combined-withalt.m2\r\n",
      "parsing.py\r\n",
      "svwiktionary-latest-pages-articles-multistream.xml\r\n",
      "svwiktionary-latest-pages-articles-multistream.xml.bz2\r\n",
      "syns.pkl\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true,
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>syn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>besserwisser [know-it-all]</td>\n",
       "      <td>[bättrevetare, viktigpetter, messerschmitt]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sverige [Sweden]</td>\n",
       "      <td>[landet lagom, moder Svea, Svea rike, Konungar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>barr [barre]</td>\n",
       "      <td>[balettstång, stång]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>samlag [intercourse]</td>\n",
       "      <td>[sex, knull, älskog]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>knulla [fuck]</td>\n",
       "      <td>[banga, borra, bulta, doppa, dra över, dunka, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22840</th>\n",
       "      <td>namnkristen</td>\n",
       "      <td>[skenkristen, mun kristen]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22841</th>\n",
       "      <td>omnipotente</td>\n",
       "      <td>[todo poderoso]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22842</th>\n",
       "      <td>förlängning</td>\n",
       "      <td>[sudden, övertid, sudden death, sudden death]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22843</th>\n",
       "      <td>tillägstid</td>\n",
       "      <td>[sudden, övertid, sudden death, sudden death]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22844</th>\n",
       "      <td>prosjektør</td>\n",
       "      <td>[projektor]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22845 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             word  \\\n",
       "0      besserwisser [know-it-all]   \n",
       "1                Sverige [Sweden]   \n",
       "2                    barr [barre]   \n",
       "3            samlag [intercourse]   \n",
       "4                   knulla [fuck]   \n",
       "...                           ...   \n",
       "22840                 namnkristen   \n",
       "22841                 omnipotente   \n",
       "22842                 förlängning   \n",
       "22843                  tillägstid   \n",
       "22844                  prosjektør   \n",
       "\n",
       "                                                     syn  \n",
       "0            [bättrevetare, viktigpetter, messerschmitt]  \n",
       "1      [landet lagom, moder Svea, Svea rike, Konungar...  \n",
       "2                                   [balettstång, stång]  \n",
       "3                                   [sex, knull, älskog]  \n",
       "4      [banga, borra, bulta, doppa, dra över, dunka, ...  \n",
       "...                                                  ...  \n",
       "22840                         [skenkristen, mun kristen]  \n",
       "22841                                    [todo poderoso]  \n",
       "22842      [sudden, övertid, sudden death, sudden death]  \n",
       "22843      [sudden, övertid, sudden death, sudden death]  \n",
       "22844                                        [projektor]  \n",
       "\n",
       "[22845 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unpickled_df = pd.read_pickle(\"./syns.pkl\")\n",
    "unpickled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Визначте рівень згоди між анотувальниками (або inter-annotator agreement) у корпусі NUCLE Error Corpus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "tags = \"\"\"Any Vt3 Vm V0 Vform SVA ArtOrDet Nn Npos Pform Pref Prep Wci Wa Wform Wtone Srun Smod Spar Sfrag Ssub WOinc WOadv Trans Mec Rloc Cit Others Um\"\"\".split(\" \")\n",
    "\n",
    "\n",
    "import pathlib\n",
    "curr_path = pathlib.Path().parent.absolute()\n",
    "path = curr_path / 'official-2014.combined-withalt.m2'\n",
    "\n",
    "lines = []\n",
    "with open(path) as file:\n",
    "    lines = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agreement by PAIR\n",
      "Pair: (0, 1) Score: 0.33398914582172073\n",
      "Pair: (0, 2) Score: 0.4069804408428973\n",
      "Pair: (0, 3) Score: 0.5096655053092518\n",
      "Pair: (0, 4) Score: 0.7188692571045512\n",
      "Pair: (1, 2) Score: 0.49448138169155953\n",
      "Pair: (1, 3) Score: 0.5614817226249059\n",
      "Pair: (1, 4) Score: 0.6329485329485329\n",
      "Pair: (2, 3) Score: 0.5457730206877925\n",
      "Pair: (2, 4) Score: 0.5416666666666667\n",
      "Pair: (3, 4) Score: 0.5035714285714286\n",
      "General agreement:\n",
      "0.3952901650568998\n",
      "Agreement by TAG\n",
      "For tag: Any score is: 0.4339096067012667\n",
      "For tag: Vt3 score is: 0\n",
      "For tag: Vm score is: 0.059583316422409\n",
      "For tag: V0 score is: 0.08932971231964114\n",
      "For tag: Vform score is: 0.1371039023483001\n",
      "For tag: SVA score is: 0.10700282848347095\n",
      "For tag: ArtOrDet score is: 0.1578472245092778\n",
      "For tag: Nn score is: 0.16807668845741963\n",
      "For tag: Npos score is: 0.05250616612549034\n",
      "For tag: Pform score is: 0.0683225705034294\n",
      "For tag: Pref score is: 0.08492123276948227\n",
      "For tag: Prep score is: 0.15783307874541927\n",
      "For tag: Wci score is: 0.14062958379625046\n",
      "For tag: Wa score is: 0.07407407407407407\n",
      "For tag: Wform score is: 0.10619317510807695\n",
      "For tag: Wtone score is: 0.08240740740740742\n",
      "For tag: Srun score is: 0.09647022829618404\n",
      "For tag: Smod score is: 0.06666666666666667\n",
      "For tag: Spar score is: 0.012630975245411865\n",
      "For tag: Sfrag score is: 0.013494318181818182\n",
      "For tag: Ssub score is: 0.08436944540097073\n",
      "For tag: WOinc score is: 0.034409080881520476\n",
      "For tag: WOadv score is: 0.04827790265290266\n",
      "For tag: Trans score is: 0.10150789412844352\n",
      "For tag: Mec score is: 0.14964562798747674\n",
      "For tag: Rloc score is: 0\n",
      "For tag: Cit score is: 0\n",
      "For tag: Others score is: 0.07992077015240927\n",
      "For tag: Um score is: 0.046067745446496944\n"
     ]
    }
   ],
   "source": [
    "comb = list(combinations(range(5), 2))\n",
    "\n",
    "data_for_tag = {}\n",
    "pairvise_agreement = {}\n",
    "\n",
    "for t in tags:\n",
    "    data_for_tag[t]={}\n",
    "\n",
    "for c in comb:\n",
    "    pairvise_agreement[c] = []\n",
    "\n",
    "#prepare data \n",
    "for t in tags:\n",
    "    for c in comb:\n",
    "        data_for_tag[t][c]=[]\n",
    "\n",
    "examples = []\n",
    "curr = []\n",
    "for line in lines:\n",
    "    if line!=\"\\n\":\n",
    "        curr.append(line)\n",
    "    else:\n",
    "        examples.append(curr)\n",
    "        curr = [] \n",
    "\n",
    "def create_dict():\n",
    "    d = {}\n",
    "    for tag in tags: \n",
    "        d[tag] = []\n",
    "    return d\n",
    "\n",
    "def get_anotator(s):\n",
    "    return int(s.strip()[-1])\n",
    "\n",
    "def get_anotation_string(s, sentense_number, tag):\n",
    "    i = s.find(\"REQUIRED\")\n",
    "    s = s.strip()[2:i]\n",
    "    token_range = \"\"\n",
    "    count = 0\n",
    "    for x in s:\n",
    "        if x==\"|\":\n",
    "            break\n",
    "        count += 1\n",
    "        token_range += x\n",
    "    s = s[count+3:]\n",
    "    count = 0 \n",
    "    anotation_tag=\"\"\n",
    "    for x in s:\n",
    "        if x==\"|\":\n",
    "            break\n",
    "        anotation_tag += x\n",
    "        count += 1\n",
    "    s = s[count+3:]\n",
    "    if tag!=\"Any\":\n",
    "        if anotation_tag!=tag:\n",
    "            return \"\"\n",
    "    correction=\"\"\n",
    "    count=0\n",
    "    for x in s:\n",
    "        if x==\"|\":\n",
    "            break\n",
    "        correction+=x\n",
    "        count+=1\n",
    "    return \" \".join([str(sentense_number), token_range, correction])\n",
    "\n",
    "def get_anotation_range(s):\n",
    "    range_string = \"\"\n",
    "    for x in s[2:]:\n",
    "        if x==\"|\":\n",
    "            break\n",
    "        range_string+=x\n",
    "    return tuple(map(int, range_string.split(' '))) \n",
    "\n",
    "def get_fix(s):\n",
    "    return get_anotation_string(s, 0, \"Any\").split(' ')[-1]\n",
    "\n",
    "def dist(r):\n",
    "    return r[1]-r[0]\n",
    "    \n",
    "def process_block(l, index):\n",
    "    anotations = l[1:]\n",
    "    if len(anotations) > 1:\n",
    "        anotation_tags = create_dict()\n",
    "        t = [\"\"]*5\n",
    "        ranges = [[] for _ in range(5)]\n",
    "        fixes = [[] for _ in range(5)]\n",
    "        curr_anotator = -1\n",
    "        for x in anotations:\n",
    "            an = get_anotator(x)\n",
    "            if an != curr_anotator:\n",
    "                if curr_anotator!=-1:\n",
    "                    t[curr_anotator] = anotation_tags\n",
    "                    anotation_tags = create_dict()\n",
    "                curr_anotator = an\n",
    "            ranges[an].append(get_anotation_range(x))\n",
    "            fixes[an].append(get_fix(x))\n",
    "            for tag in tags:\n",
    "                anotation_tags[tag].append(get_anotation_string(x, index, tag))\n",
    "\n",
    "        t[curr_anotator] = anotation_tags\n",
    "        #append processed lines to data \n",
    "        indexes = [i for i, j in enumerate(t) if j!='']\n",
    "        if len(indexes)>1:\n",
    "            #process in general \n",
    "            for idx in combinations(indexes, 2):\n",
    "                i, j = idx\n",
    "                ri=ranges[i]\n",
    "                rj=ranges[j]\n",
    "                fi=fixes[i]\n",
    "                fj=fixes[j]\n",
    "                #go through ranges (check if range needs to be expanded) for left term\n",
    "                expanded_ri = []\n",
    "                expanded_fi = []\n",
    "                for i, r in enumerate(ri):\n",
    "                    if dist(r)==2:\n",
    "                        fix = fi[i]\n",
    "                        if len(fix.split())==1: #we're dealing with 2->1 word fix, meaning second word would be deleted\n",
    "                            expanded_ri.append((r[0],r[0]+1))\n",
    "                            expanded_fi.append(fi[i])\n",
    "                            expanded_ri.append((r[1],r[1]+1))\n",
    "                            expanded_fi.append(\"\")\n",
    "                    else:\n",
    "                        expanded_ri.append(r)\n",
    "                        expanded_fi.append(fi[i])\n",
    "                #go through ranges (check if range needs to be expanded) for right term\n",
    "                expanded_rj = []\n",
    "                expanded_fj = []\n",
    "                for i, r in enumerate(rj):\n",
    "                    if dist(r)==2:\n",
    "                        fix = fj[i]\n",
    "                        if len(fix.split())==1: #we're dealing with 2->1 word fix, meaning second word would be deleted\n",
    "                            expanded_rj.append((r[0],r[0]+1))\n",
    "                            expanded_fj.append(fj[i])\n",
    "                            expanded_rj.append((r[1],r[1]+1))\n",
    "                            expanded_fj.append(\"\")\n",
    "                    else:\n",
    "                        expanded_rj.append(r)\n",
    "                        expanded_fj.append(fj[i])\n",
    "                g = [expanded_rj.count(el) for el in expanded_ri]\n",
    "                if len(g)>0:\n",
    "                    c = sum(g)*2/(len(expanded_ri)+len(expanded_rj))\n",
    "                    pairvise_agreement[idx].append(c)\n",
    "\n",
    "            #process for each tag\n",
    "            for tag in tags:\n",
    "                for idx in combinations(indexes, 2):\n",
    "                    d1 = t[idx[0]][tag]\n",
    "                    d2 = t[idx[1]][tag]\n",
    "                    g = [d2.count(el) for el in d1 if el!='']\n",
    "                    if len(g)!=0:\n",
    "                        c = sum(g)*2/(len(d1)+len(d2))\n",
    "                        data_for_tag[tag][idx].append(c)\n",
    "\n",
    "\n",
    "for i, e in enumerate(examples):\n",
    "    process_block(e,i)\n",
    "\n",
    "\n",
    "#calculating result \n",
    "print(\"Agreement by PAIR:\")\n",
    "all=[]\n",
    "for c in comb:\n",
    "    d = pairvise_agreement[c]\n",
    "    all.extend(d)\n",
    "    if len(d)!=0: \n",
    "        combined_score = sum(d)/len(d)\n",
    "        print(\"Pair: {} Score: {}\".format(c, combined_score))\n",
    "\n",
    "print(\"General agreement:\")\n",
    "print(sum(all)/len(all))\n",
    "\n",
    "print(\"Agreement by TAG:\")\n",
    "for tag in tags:\n",
    "    data = data_for_tag[tag]\n",
    "    combined_score = 0\n",
    "    count = 0\n",
    "    for k in data:\n",
    "        d = data[k]\n",
    "        if len(d)!=0: # Means this annotators annotated same sentences with this tag\n",
    "            combined_score += sum(d)/len(d)\n",
    "            count += 1\n",
    "\n",
    "    res = combined_score/count if count!=0 else 0\n",
    "    print(\"For tag: {} score is: {}\".format(tag, res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusions:\n",
    "Multiple,  different  corrections  are  of-ten acceptable. In general considering all tags score showed moderate agreement between peers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Higher scores are between annotators who have less common sentences. The lowest score is between two annotators who have the most sentences processed together. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tags that have 0 agreement are the ones that werent used by any two annotators on a same sample \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit",
   "language": "python",
   "name": "python37364bit38067c8f20464c0595342e0599bfab1d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
