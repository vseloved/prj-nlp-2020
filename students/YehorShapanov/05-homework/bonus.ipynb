{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import gutenberg\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import bigrams\n",
    "from math import log \n",
    "import heapq\n",
    "from operator import itemgetter\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте попробуем проанализировать роман Джейн Остин \"Эмма\"\n",
    "Возьмём только предложения из корпуса проекта Гутенберг."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "emma = gutenberg.sents('austen-emma.txt')\n",
    "emma_sents = []\n",
    "def filterFunc(a):\n",
    "    v = ['[',']','--']\n",
    "    return not (a in v)\n",
    "\n",
    "for sent in emma:\n",
    "    emma_sents.append(list(filter(filterFunc, sent)))\n",
    "# Term frequencies cache\n",
    "D = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем смотреть на среднее значение tf-idf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf(term, sentence):\n",
    "    return sentence.count(term)/len(sentence)\n",
    "\n",
    "def idf(term, documents):\n",
    "    N = len(documents)\n",
    "    d = D.get(term)\n",
    "    if d==None:\n",
    "        d = sum([1 if d.count(term)>0 else 0 for d in documents])\n",
    "        D[term]=d\n",
    "    return log(N/d)\n",
    "\n",
    "def tf_idf(term, sentence, documents):\n",
    "    return tf(term, sentence)*idf(term, documents)\n",
    "\n",
    "def process_sentence(s):\n",
    "    if len(s)<2:\n",
    "        return 0\n",
    "    terms = set(s)\n",
    "    mean_ti = statistics.mean([tf_idf(w, s, emma_sents) for w in terms])\n",
    "    return mean_ti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_means():\n",
    "    mean_tis = []\n",
    "    for i, s in enumerate(emma_sents):\n",
    "        mean_tis.append((i, process_sentence(s)))\n",
    "    return mean_tis\n",
    "N = 5\n",
    "def print_top(m):\n",
    "    top = heapq.nlargest(N, m, itemgetter(1))\n",
    "    top_indexes = [i[0] for i in top]\n",
    "    for i in sorted(top_indexes):\n",
    "        print(emma_sents[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CHAPTER', 'IV']\n",
      "['CHAPTER', 'V']\n",
      "['VOLUME', 'II']\n",
      "['VOLUME', 'III']\n",
      "['CHAPTER', 'XIX']\n"
     ]
    }
   ],
   "source": [
    "print_top(calculate_means())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ха! Ну что ж, разумно. Попробуем удалить названия глав и частей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_remove = []\n",
    "#Also remove author name \n",
    "index_to_remove.append(0)\n",
    "for i, sent in enumerate(emma_sents):\n",
    "    if len(sent)<1:\n",
    "        continue\n",
    "    if sent[0] in ['CHAPTER', 'VOLUME', 'FINIS']:\n",
    "        index_to_remove.append(i)\n",
    "        \n",
    "for idx in reversed(index_to_remove):\n",
    "    del emma_sents[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Nonsense', '!']\n",
      "['Alas', '!']\n",
      "['Heavens', '!']\n",
      "['Alas', '!']\n",
      "['Weston', '.]']\n"
     ]
    }
   ],
   "source": [
    "print_top(calculate_means())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ага! Средняя tf-idf мало чего нам даёт т.к. не учитывает длинну самого предложения. Попробуем считать суммы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sentence(s):\n",
    "    terms = set(s)\n",
    "    mean_ti = sum([tf_idf(w, s, emma_sents) for w in terms])\n",
    "    return mean_ti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Former', 'provocations', 'reappeared', '.']\n",
      "['Absolutely', 'insufferable', '!']\n",
      "['then', ',', 'don', \"'\", 't', 'speak', 'it', ',', 'don', \"'\", 't', 'speak', 'it', ',\"', 'she', 'eagerly', 'cried', '.']\n",
      "['MY', 'DEAR', 'MADAM', ',']\n",
      "['\"`', 'Smallridge', \"!'\"]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-90-3070f1461b03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprint_top\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalculate_means\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "for el in print_top(calculate_means()):\n",
    "    print(\" \".join(el))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это уже похоже на роман нравов. Давайте провернём ещё одну итерацию и добавим биграммы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigam_count(sentense, term):\n",
    "    count=0\n",
    "    for i, el in enumerate(sentense):\n",
    "        if el==term[0]:\n",
    "            if i < len(sentense)-1 and sentense[i+1]==term[1]:\n",
    "                count+=1\n",
    "    return count\n",
    "\n",
    "def btf(term, sentence):\n",
    "    return bigam_count(sentence, term)/len(list(bigrams(sentence)))\n",
    "\n",
    "def bidf(term, documents):\n",
    "    N = len(documents)\n",
    "    d = D.get(term)\n",
    "    if d==None:\n",
    "        d = sum([1 if bigam_count(d, term)>0 else 0 for d in documents])\n",
    "        D[term]=d\n",
    "    return log(N/d)\n",
    "\n",
    "def btf_idf(term, sentence, documents):\n",
    "    return btf(term, sentence)*bidf(term, documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sentence(s):\n",
    "    if len(s)<2:\n",
    "        return 0\n",
    "    terms = set(s)\n",
    "    mean_ti = sum([tf_idf(w, s, emma_sents) for w in terms])\n",
    "    mean_ti += sum([btf_idf(bi, s, emma_sents) for bi in bigrams(s)])\n",
    "    return mean_ti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Former', 'provocations', 'reappeared', '.']\n",
      "['Absolutely', 'insufferable', '!']\n",
      "['then', ',', 'don', \"'\", 't', 'speak', 'it', ',', 'don', \"'\", 't', 'speak', 'it', ',\"', 'she', 'eagerly', 'cried', '.']\n",
      "['MY', 'DEAR', 'MADAM', ',']\n",
      "['\"`', 'Smallridge', \"!'\"]\n"
     ]
    }
   ],
   "source": [
    "print_top(calculate_means())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "К сожалению, в моём корпусе некоторые предложения были разбиты пополам но то, что выдача выглядит более информативной очевидно!\n",
    "Интересно посмотреть, какие токены получили самый высокий скор."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('.', 5509),\n",
       " (',', 4499),\n",
       " ('to', 3120),\n",
       " ('and', 2721),\n",
       " ('the', 2697),\n",
       " ('of', 2655),\n",
       " ('a', 2172),\n",
       " ('I', 2116),\n",
       " ('not', 1769),\n",
       " ('was', 1744)]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(D.items(), key=itemgetter(1), reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'filter' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-106-9070fc73fa9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mitemgetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'filter' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "filter(lambda x: isinstance(p, tuple), sorted(D.items(), key=itemgetter(1), reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
