{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_core_web_md\n",
    "nlp = en_core_web_md.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truth, truth, truth, countertruth, untruth, untruth, trutholog\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "template = \"{:15}{:15}{:15}{:15}\"\n",
    "quote = nlp(\"truth truthful truthfulness countertruth untruth untruthful truthology\")\n",
    "original = [token.text.lower() for token in quote]\n",
    "lemmas = [token.lemma_ for token in quote]\n",
    "stems = [stemmer.stem(token.text.lower()) for token in quote]\n",
    "lemmas_stems = [stemmer.stem(text.lower()) for text in lemmas]\n",
    "print(\", \".join(stems))\n",
    "# print(template.format(\"original: \", \"lemmas: \", \"stems: \", \"lemmas+stems: \"))\n",
    "# for o, l, s, ls in zip(original, lemmas, stems, lemmas_stems): \n",
    "#     print(template.format(o, l, s, ls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flaw, flaw, flaw, flawless, flawless, flawless\n"
     ]
    }
   ],
   "source": [
    "quote = nlp(\"flaw flaws flawed flawless flawlessness flawlessly\")\n",
    "original = [token.text.lower() for token in quote]\n",
    "lemmas = [token.lemma_ for token in quote]\n",
    "stems = [stemmer.stem(token.text.lower()) for token in quote]\n",
    "lemmas_stems = [stemmer.stem(text.lower()) for text in lemmas]\n",
    "print(\", \".join(stems))\n",
    "# print(template.format(\"original: \", \"lemmas: \", \"stems: \", \"lemmas+stems: \"))\n",
    "# for o, l, s, ls in zip(original, lemmas, stems, lemmas_stems): \n",
    "#     print(template.format(o, l, s, ls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "лес, лесн, лесник, леснич, лесничеств, пролес\n"
     ]
    }
   ],
   "source": [
    "stemmer = SnowballStemmer(\"russian\")\n",
    "quote = nlp(\"лес лесной лесник лесничий лесничество пролесье\")\n",
    "original = [token.text.lower() for token in quote]\n",
    "lemmas = [token.lemma_ for token in quote]\n",
    "stems = [stemmer.stem(word) for word in original]\n",
    "lemmas_stems = [stemmer.stem(text.lower()) for text in lemmas]\n",
    "print(\", \".join(stems))\n",
    "# print(template.format(\"original: \", \"lemmas: \", \"stems: \", \"lemmas+stems: \"))\n",
    "# for o, l, s, ls in zip(original, lemmas, stems, lemmas_stems): \n",
    "#     print(template.format(o, l, s, ls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "окн, окошк, подоконник, окон, окнищ\n"
     ]
    }
   ],
   "source": [
    "quote = nlp(\"окно окошко подоконник оконный окнище\")\n",
    "original = [token.text.lower() for token in quote]\n",
    "lemmas = [token.lemma_ for token in quote]\n",
    "stems = [stemmer.stem(word) for word in original]\n",
    "lemmas_stems = [stemmer.stem(text.lower()) for text in lemmas]\n",
    "print(\", \".join(stems))\n",
    "# print(template.format(\"original: \", \"lemmas: \", \"stems: \", \"lemmas+stems: \"))\n",
    "# for o, l, s, ls in zip(original, lemmas, stems, lemmas_stems): \n",
    "#     print(template.format(o, l, s, ls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import spacy\n",
    "def pos_father_tag(sentence):\n",
    "    idx = sentence.find(\"{\")\n",
    "    processed = nlp(re.sub('[{}]', '', sentence))\n",
    "    token = next(token for token in processed if token.idx == idx)\n",
    "\n",
    "    processor = lambda token: (spacy.explain(token.pos_), ('ROOT' if token.dep_ == 'ROOT' else token.head.text))\n",
    "    data = processor(token)\n",
    "\n",
    "    return \"{}: {}, {}\".format(sentence, data[0], data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We can {but} hope that everything will be fine.: coordinating conjunction, hope\n",
      "It's sad {but} true.: coordinating conjunction, sad\n",
      "Jack brings nothing {but} trouble.: adposition, nothing\n",
      "Let's do it this {way}!: noun, do\n",
      "This is {way} too much!: adverb, much\n",
      "The prices are going {down}.: adverb, going\n",
      "Someone pushed him and he fell {down} the stairs.: adposition, fell\n",
      "I’ve been feeling rather {down} lately.: adverb, feeling\n",
      "It's not easy to {down} a cup of coffee in one gulp.: adposition, 's\n",
      "Bring a {down} jacket and a pair of gloves, and you'll be fine.: adjective, jacket\n"
     ]
    }
   ],
   "source": [
    "raw_text = \"\"\"\n",
    "We can {but} hope that everything will be fine.\n",
    "It's sad {but} true.\n",
    "Jack brings nothing {but} trouble.\n",
    "Let's do it this {way}!\n",
    "This is {way} too much!\n",
    "The prices are going {down}.\n",
    "Someone pushed him and he fell {down} the stairs.\n",
    "I’ve been feeling rather {down} lately.\n",
    "It's not easy to {down} a cup of coffee in one gulp.\n",
    "Bring a {down} jacket and a pair of gloves, and you'll be fine.\n",
    "\"\"\"\n",
    "text = raw_text.strip().split('\\n')\n",
    "print(\"\\n\".join([pos_father_tag(s) for s in text]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{I} love turtles.: pronoun, love\n",
      "I {love} turtles.: verb, ROOT\n",
      "I love {turtles}.: noun, love\n"
     ]
    }
   ],
   "source": [
    "raw_text = \"\"\"\n",
    "{I} love turtles.\n",
    "I {love} turtles.\n",
    "I love {turtles}.\n",
    "\"\"\"\n",
    "text = raw_text.strip().split('\\n')\n",
    "print(\"\\n\".join([pos_father_tag(s) for s in text]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymorphy2\n",
    "import tokenize_uk\n",
    "morph = pymorphy2.MorphAnalyzer(lang='uk')\n",
    "\n",
    "grammeme = {\n",
    "    \"NOUN\" \t:\"іменник\",\n",
    "    \"ADJF\" \t:\"прикметник\",\n",
    "    \"ADJS\" \t:\"прикметник\",\n",
    "    \"COMP\" \t:\"компаратив\",\n",
    "    \"VERB\" \t:\"дієслово\",\n",
    "    \"INFN\" \t:\"дієслово (інфінітив)\",\n",
    "    \"PRTF\" \t:\"дієприкметник\",\n",
    "    \"PRTS\" \t:\"дієприкметник\",\n",
    "    \"GRND\" \t:\"дієприслівник\",\n",
    "    \"NUMR\" \t:\"числівник\",\n",
    "    \"ADVB\" \t:\"прислівник\",\n",
    "    \"NPRO\" \t:\"займенник\",\n",
    "    \"PRED\" \t:\"предікатів\",\n",
    "    \"PREP\" \t:\"прийменник\",\n",
    "    \"CONJ\" \t:\"союз\",\n",
    "    \"PRCL\" \t:\"частка\",\n",
    "    \"INTJ\" \t:\"вигук\"\n",
    "}\n",
    "\n",
    "def explain_ru(text):\n",
    "    return grammeme[morph.parse(text)[0].tag.POS]\n",
    "\n",
    "def pos_father_tag_ru(sentence):\n",
    "    idx = sentence.find(\"{\")\n",
    "    processed = nlp(re.sub('[{}]', '', sentence))\n",
    "    token = next(token for token in processed if token.idx == idx)\n",
    "\n",
    "    processor = lambda token: (explain_ru(token.text), ('ROOT' if token.dep_ == 'ROOT' else token.head.text))\n",
    "    data = processor(token)\n",
    "\n",
    "    return \"{}: {}, {}\".format(sentence, data[0], data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{Я} люблю черепашок.: займенник, черепашок\n",
      "Я {люблю} черепашок.: дієслово, черепашок\n",
      "Я люблю {черепашок}.: іменник, ROOT\n"
     ]
    }
   ],
   "source": [
    "raw_text = \"\"\"\n",
    "{Я} люблю черепашок.\n",
    "Я {люблю} черепашок.\n",
    "Я люблю {черепашок}.\n",
    "\"\"\"\n",
    "text = raw_text.strip().split('\\n')\n",
    "print(\"\\n\".join([pos_father_tag_ru(s) for s in text]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Рада міністрів Європейського союзу затвердила угоду про спрощений порядок видачі {віз} для України.: іменник, для\n",
      "Батько Себастьяна {віз} на санях їх театральний гурт до Львова.: іменник, на\n",
      "А ще дивний елемент інтер’єру – {віз} із продукцією одного з херсонських виробників.: іменник, ROOT\n",
      "У цю мить {повз} Євгена пролетів останній вагон товарняка.: дієслово, ROOT\n",
      "Кліпнув очима і побачив малого песика, який саме пробігав {повз} у бік села.: дієслово, ROOT\n",
      "Степанко перестав кричати, тільки ламкий стогін {повз} йому із грудей.: дієслово, кричати\n",
      "Ось присіла на {край} ліжка.: дієслово, присіла\n",
      "Поставив ту кузню не {край} дороги, як було заведено, а на Красній горі, біля Прадуба.: дієслово, ROOT\n",
      "Розповідаючи про передній {край} лінґвістики, фон Лібіх, як завжди, мислив широко і глобально.: дієслово, лінґвістики\n",
      "Не {край} мені серце.: дієслово, серце\n"
     ]
    }
   ],
   "source": [
    "raw_text = \"\"\"\n",
    "Рада міністрів Європейського союзу затвердила угоду про спрощений порядок видачі {віз} для України.\n",
    "Батько Себастьяна {віз} на санях їх театральний гурт до Львова.\n",
    "А ще дивний елемент інтер’єру – {віз} із продукцією одного з херсонських виробників.\n",
    "У цю мить {повз} Євгена пролетів останній вагон товарняка.\n",
    "Кліпнув очима і побачив малого песика, який саме пробігав {повз} у бік села.\n",
    "Степанко перестав кричати, тільки ламкий стогін {повз} йому із грудей.\n",
    "Ось присіла на {край} ліжка.\n",
    "Поставив ту кузню не {край} дороги, як було заведено, а на Красній горі, біля Прадуба.\n",
    "Розповідаючи про передній {край} лінґвістики, фон Лібіх, як завжди, мислив широко і глобально.\n",
    "Не {край} мені серце.\n",
    "\"\"\"\n",
    "text = raw_text.strip().split('\\n')\n",
    "print(\"\\n\".join([pos_father_tag_ru(s) for s in text]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Council of Ministers of the European Union has approved an agreement on a simplified procedure for issuing {visas} for Ukraine.: noun, issuing\n",
      "Sebastian's father {cart} on a sleigh their theatrical group to Lviv.: noun, ROOT\n",
      "And a strange element of the interior is the {cart} with the products of one of the Kherson producers.: noun, is\n",
      "At that moment, the last wagon of the trucker flew {past} Eugene.: adposition, flew\n",
      "He glanced up and saw a small dog walking just {past} the village.: adposition, walking\n",
      "Stepanko stopped yelling, only a fragile groan {crawling} from his chest.: noun, groan\n",
      "Here she sat on the {edge} of the bed.: noun, on\n",
      "He set up that forge not on the {edge} of road, as it was started, but on the Red Mountain, near Pradub.: noun, on\n",
      "In discussing the {forefront} of linguistics, von Liebig, as always, thought broadly and globally.: noun, discussing\n",
      "Don't {torment} my heart.: verb, ROOT\n"
     ]
    }
   ],
   "source": [
    "raw_text = \"\"\"\n",
    "The Council of Ministers of the European Union has approved an agreement on a simplified procedure for issuing {visas} for Ukraine.\n",
    "Sebastian's father {cart} on a sleigh their theatrical group to Lviv.\n",
    "And a strange element of the interior is the {cart} with the products of one of the Kherson producers.\n",
    "At that moment, the last wagon of the trucker flew {past} Eugene.\n",
    "He glanced up and saw a small dog walking just {past} the village.\n",
    "Stepanko stopped yelling, only a fragile groan {crawling} from his chest.\n",
    "Here she sat on the {edge} of the bed.\n",
    "He set up that forge not on the {edge} of road, as it was started, but on the Red Mountain, near Pradub.\n",
    "In discussing the {forefront} of linguistics, von Liebig, as always, thought broadly and globally.\n",
    "Don't {torment} my heart.\n",
    "\"\"\"\n",
    "\n",
    "text = raw_text.strip().split('\\n')\n",
    "print(\"\\n\".join([pos_father_tag(s) for s in text]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "text = \"The girl was standing where she was, trying to tidy up her tousled hair, extremely angry that that was seen by the drivers that were waiting at the crossing.\"\n",
    "doc = nlp(text)\n",
    "# Since this is an interactive Jupyter environment, we can use displacy.render here\n",
    "svg = displacy.render(doc, style='dep', jupyter=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"doc.svg\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet \n",
    "syns = wordnet.synsets(\"age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('age.n.01'), Synset('historic_period.n.01'), Synset('age.n.03'), Synset('long_time.n.01'), Synset('old_age.n.01'), Synset('age.v.01'), Synset('senesce.v.01'), Synset('age.v.03')]\n"
     ]
    }
   ],
   "source": [
    "print(syns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how long something has existed\n",
      "age\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "def print_info(s):\n",
    "    print(s.definition())\n",
    "    for l in s.lemmas():\n",
    "        print(l.name())\n",
    "        print(l.antonyms())\n",
    "s = syns[0]\n",
    "print_info(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "an era of history having some distinctive feature\n",
      "historic_period\n",
      "[]\n",
      "age\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "s = syns[1]\n",
    "print_info(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin to seem older; get older\n",
      "age\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "s = syns[5]\n",
    "print_info(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

