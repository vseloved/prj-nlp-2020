{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from conllu import parse\n",
    "from enum import Enum\n",
    "\n",
    "with open(\"UD_Ukrainian-IU/uk_iu-ud-train.conllu\", \"r\") as f:\n",
    "    data = f.read()\n",
    "\n",
    "trees = parse(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tree = trees[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('id', 1), ('form', 'У'), ('lemma', 'у'), ('upostag', 'ADP'), ('xpostag', 'Spsl'), ('feats', OrderedDict([('Case', 'Loc')])), ('head', 2), ('deprel', 'case'), ('deps', [('case', 2)]), ('misc', OrderedDict([('Id', '0003'), ('LTranslit', 'u'), ('Translit', 'U')]))])\n"
     ]
    }
   ],
   "source": [
    "print(tree[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "У <-- домі: case\n",
      "домі <-- була: obl\n",
      "римського <-- патриція: amod\n",
      "патриція <-- домі: nmod\n",
      "Руфіна <-- патриція: flat:title\n",
      "була <-- root: root\n",
      "прегарна <-- фреска: amod\n",
      "фреска <-- була: nsubj\n",
      ", <-- зображення: punct\n",
      "зображення <-- фреска: appos\n",
      "Венери <-- зображення: nmod\n",
      "та <-- Адоніса: cc\n",
      "Адоніса <-- Венери: conj\n",
      ". <-- була: punct\n"
     ]
    }
   ],
   "source": [
    "for node in tree:\n",
    "    head = node[\"head\"]\n",
    "    print(\"{} <-- {}: {}\".format(node[\"form\"],\n",
    "                                 tree[head - 1][\"form\"] if head > 0 else \"root\",\n",
    "                                 node[\"deprel\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actions(str, Enum):\n",
    "    SHIFT = \"shift\"\n",
    "    REDUCE = \"reduce\"\n",
    "    RIGHT = \"right\"\n",
    "    LEFT = \"left\"\n",
    "    \n",
    "    \n",
    "\n",
    "def oracle(stack, top_queue, relations):\n",
    "    top_stack = stack[-1]\n",
    "    if top_stack and not top_queue:\n",
    "        return Actions.REDUCE\n",
    "    elif top_queue[\"head\"] == top_stack[\"id\"]:\n",
    "        return Actions.RIGHT\n",
    "    elif top_stack[\"head\"] == top_queue[\"id\"]:\n",
    "        return Actions.LEFT\n",
    "    elif top_stack[\"id\"] in [i[0] for i in relations] and (top_queue[\"head\"] < top_stack[\"id\"] or [s for s in stack if s[\"head\"] == top_queue[\"id\"]]):\n",
    "        return Actions.REDUCE\n",
    "    else:\n",
    "        return Actions.SHIFT\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = OrderedDict([('id', 0), ('form', 'ROOT'), ('lemma', 'ROOT'), ('upostag', 'ROOT'),\n",
    "                    ('xpostag', None), ('feats', None), ('head', None), ('deprel', None),\n",
    "                    ('deps', None), ('misc', None)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(stack, queue):\n",
    "    features = dict()\n",
    "    if len(stack) > 0:\n",
    "        stack_top = stack[-1]\n",
    "        features[\"s0-word\"] = stack_top[\"form\"]\n",
    "        features[\"s0-lemma\"] = stack_top[\"lemma\"]\n",
    "        features[\"s0-tag\"] = stack_top[\"upostag\"]\n",
    "        if stack_top[\"feats\"]:\n",
    "            for k, v in stack_top[\"feats\"].items():\n",
    "                features[\"s0-\" + k] = v\n",
    "    if len(stack) > 1:\n",
    "        features[\"s1-tag\"] = stack_top[\"upostag\"]\n",
    "    if queue:\n",
    "        queue_top = queue[0]\n",
    "        features[\"q0-word\"] = queue_top[\"form\"]\n",
    "        features[\"q0-lemma\"] = queue_top[\"lemma\"]\n",
    "        features[\"q0-tag\"] = queue_top[\"upostag\"]\n",
    "        if queue_top[\"feats\"]:\n",
    "            for k, v in queue_top[\"feats\"].items():\n",
    "                features[\"q0-\" + k] = v\n",
    "    if len(queue) > 1:\n",
    "        queue_next = queue[1]\n",
    "        features[\"q1-word\"] = queue_next[\"form\"]\n",
    "        features[\"q1-tag\"] = queue_next[\"upostag\"]\n",
    "    if len(queue) > 2:\n",
    "        features[\"q2-tag\"] = queue[2][\"upostag\"]\n",
    "    if len(queue) > 3:\n",
    "        features[\"q3-tag\"] = queue[3][\"upostag\"]\n",
    "    if stack and queue:\n",
    "        features[\"distance\"] = queue[0][\"id\"] - stack[-1][\"id\"]\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(tree):\n",
    "    features, labels = [], []\n",
    "    stack, queue, relations = [ROOT], tree[:], []\n",
    "\n",
    "    while queue or stack:\n",
    "        action = oracle(stack if len(stack) > 0 else None,\n",
    "                        queue[0] if len(queue) > 0 else None,\n",
    "                        relations)\n",
    "        features.append(extract_features(stack, queue))\n",
    "        labels.append(action.value)\n",
    "        if action == Actions.SHIFT:\n",
    "            stack.append(queue.pop(0))\n",
    "        elif action == Actions.REDUCE:\n",
    "            stack.pop()\n",
    "        elif action == Actions.LEFT:\n",
    "            relations.append((stack[-1][\"id\"], queue[0][\"id\"]))\n",
    "            stack.pop()\n",
    "        elif action == Actions.RIGHT:\n",
    "            relations.append((queue[0][\"id\"], stack[-1][\"id\"]))\n",
    "            stack.append(queue.pop(0))\n",
    "        else:\n",
    "            print(\"Unknown action.\")\n",
    "    return features, labels, relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words: 14\n",
      "Number of actions: 29\n",
      "List of actions taken: ['shift', 'left', 'shift', 'shift', 'left', 'right', 'right', 'reduce', 'reduce', 'left', 'right', 'shift', 'left', 'right', 'shift', 'left', 'right', 'right', 'shift', 'left', 'right', 'reduce', 'reduce', 'reduce', 'reduce', 'right', 'reduce', 'reduce', 'reduce']\n",
      "Features: 29\n",
      "Relations:  [(1, 2), (3, 4), (4, 2), (5, 4), (2, 6), (6, 0), (7, 8), (8, 6), (9, 10), (10, 8), (11, 10), (12, 13), (13, 11), (14, 6)]\n"
     ]
    }
   ],
   "source": [
    "features, labels, relations = get_data(tree)\n",
    "print(\"Number of words:\", len(tree))\n",
    "print(\"Number of actions:\", len(labels))\n",
    "print(\"List of actions taken:\", labels)\n",
    "print(\"Features:\", len(features))\n",
    "print(\"Relations: \", relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190298 190298\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels = [], []\n",
    "for tree in trees:\n",
    "    tree_features, tree_labels = get_data([t for t in tree if type(t[\"id\"])==int])\n",
    "    train_features += tree_features\n",
    "    train_labels += tree_labels\n",
    "\n",
    "print(len(train_features), len(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35124 35124\n"
     ]
    }
   ],
   "source": [
    "with open(\"UD_Ukrainian-IU/uk_iu-ud-test.conllu\", \"r\") as f:\n",
    "    data = f.read()\n",
    "test_trees = parse(data)\n",
    "\n",
    "test_features, test_labels = [], []\n",
    "for tree in test_trees:\n",
    "    tree_features, tree_labels = get_data([t for t in tree if type(t[\"id\"])==int])\n",
    "    test_features += tree_features\n",
    "    test_labels += tree_labels\n",
    "\n",
    "print(len(test_features), len(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total number of features:  111260\n"
     ]
    }
   ],
   "source": [
    "vectorizer = DictVectorizer()\n",
    "vec = vectorizer.fit(train_features)\n",
    "\n",
    "print(\"\\nTotal number of features: \", len(vec.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190298 35124\n"
     ]
    }
   ],
   "source": [
    "train_features_vectorized = vec.transform(train_features)\n",
    "test_features_vectorized = vec.transform(test_features)\n",
    "\n",
    "print(len(train_features_vectorized.toarray()), len(test_features_vectorized.toarray()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x111260 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 20 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features_vectorized[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb = MultinomialNB()\n",
    "mnb_pred = mnb.fit(train_features_vectorized, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left       0.76      0.86      0.81      8658\n",
      "      reduce       0.72      0.47      0.57      9350\n",
      "       right       0.63      0.77      0.69      8291\n",
      "       shift       0.77      0.78      0.78      8825\n",
      "\n",
      "    accuracy                           0.72     35124\n",
      "   macro avg       0.72      0.72      0.71     35124\n",
      "weighted avg       0.72      0.72      0.71     35124\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted_mnb = mnb.predict(test_features_vectorized)\n",
    "print(classification_report(test_labels, predicted_mnb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yehorshapanov/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(50, 15), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
       "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "              power_t=0.5, random_state=3, shuffle=True, solver='lbfgs',\n",
       "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(50, 15), random_state=3)\n",
    "clf.fit(train_features_vectorized, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left       0.85      0.88      0.86      8658\n",
      "      reduce       0.80      0.72      0.76      9350\n",
      "       right       0.74      0.80      0.77      8291\n",
      "       shift       0.90      0.90      0.90      8825\n",
      "\n",
      "    accuracy                           0.82     35124\n",
      "   macro avg       0.82      0.82      0.82     35124\n",
      "weighted avg       0.82      0.82      0.82     35124\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted_clf = clf.predict(test_features_vectorized)\n",
    "print(classification_report(test_labels, predicted_clf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 209 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yehorshapanov/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  3.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
       "                   multi_class='multinomial', n_jobs=None, penalty='l2',\n",
       "                   random_state=50, solver='sag', tol=0.0001, verbose=1,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrc = LogisticRegression(random_state=50, solver=\"sag\", multi_class=\"multinomial\", max_iter=1000, verbose=1)\n",
    "lrc.fit(train_features_vectorized, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_lrc = lrc.predict(test_features_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left       0.85      0.87      0.86      8658\n",
      "      reduce       0.82      0.72      0.77      9350\n",
      "       right       0.74      0.80      0.77      8291\n",
      "       shift       0.88      0.89      0.88      8825\n",
      "\n",
      "    accuracy                           0.82     35124\n",
      "   macro avg       0.82      0.82      0.82     35124\n",
      "weighted avg       0.82      0.82      0.82     35124\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels, predicted_lrc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5496"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "892"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(sent, child_id, parent_id):\n",
    "    l = len(sent)\n",
    "    features = dict()\n",
    "    features[\"child_lemma\"] = sent[child_id]['lemma']\n",
    "    features[\"parent_lemma\"] = sent[parent_id]['lemma']\n",
    "    features[\"child_pos\"] = sent[child_id]['upostag']\n",
    "    features[\"parent_pos\"] = sent[parent_id]['upostag']\n",
    "    if child_id>0:\n",
    "        features[\"left_child_lemma\"] = sent[child_id-1]['lemma']\n",
    "        features[\"left_child_pos\"] = sent[child_id-1]['upostag']\n",
    "    if child_id<l-1:\n",
    "        features[\"right_child_lemma\"] = sent[child_id+1]['lemma']\n",
    "        features[\"right_child_pos\"] = sent[child_id+1]['upostag']\n",
    "    if parent_id>0:\n",
    "        features[\"left_parent_lemma\"] = sent[parent_id-1]['lemma']\n",
    "        features[\"left_parent_pos\"] = sent[parent_id-1]['upostag']\n",
    "    if parent_id<l-1:\n",
    "        features[\"right_parent_lemma\"] = sent[parent_id+1]['lemma']\n",
    "        features[\"right_parent_pos\"] = sent[parent_id+1]['upostag']\n",
    "    return features\n",
    "\n",
    "    \n",
    "def get_connections_from_sentence(s):\n",
    "    connections = []\n",
    "    features_list = []\n",
    "    for node in s:\n",
    "        head = node[\"head\"]\n",
    "        if not head is None and head > 0:\n",
    "            connection = node[\"deprel\"]\n",
    "            features = get_features(s, node['id']-1, head-1)\n",
    "            connections.append(connection)\n",
    "            features_list.append(features)\n",
    "    return connections, features_list\n",
    "            \n",
    "c, f = get_connections_from_sentence(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labeled_data(t):\n",
    "    connections = []\n",
    "    features = []\n",
    "    for tree in t:\n",
    "        c, f = get_connections_from_sentence(tree)\n",
    "        connections.extend(c)\n",
    "        features.extend(f)\n",
    "    return connections, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_connections, train_labeled_features = get_labeled_data(trees)\n",
    "test_connections, test_labeled_features = get_labeled_data(test_trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16224"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_labeled_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total number of features:  68737\n"
     ]
    }
   ],
   "source": [
    "v2 = DictVectorizer()\n",
    "vec2 = v2.fit(train_labeled_features)\n",
    "\n",
    "print(\"\\nTotal number of features: \", len(vec.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86905 16224\n"
     ]
    }
   ],
   "source": [
    "train_labeled_features_vectorized = vec2.transform(train_labeled_features)\n",
    "test_labeled_features_vectorized = vec2.transform(test_labeled_features)\n",
    "\n",
    "print(len(train_labeled_features_vectorized.toarray()), len(test_labeled_features_vectorized.toarray()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 282 epochs took 105 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
       "                   multi_class='multinomial', n_jobs=None, penalty='l2',\n",
       "                   random_state=50, solver='sag', tol=0.0001, verbose=1,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrc2 = LogisticRegression(random_state=50, solver=\"sag\", multi_class=\"multinomial\", max_iter=1000, verbose=1)\n",
    "lrc2.fit(train_labeled_features_vectorized, train_connections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_lrc2 = lrc2.predict(test_labeled_features_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     precision    recall  f1-score   support\n",
      "\n",
      "                acl       0.74      0.59      0.66        66\n",
      "            acl:adv       1.00      0.14      0.25         7\n",
      "          acl:relcl       0.78      0.84      0.81       132\n",
      "              advcl       0.40      0.39      0.39       153\n",
      "           advcl:sp       0.00      0.00      0.00         5\n",
      "          advcl:svc       0.00      0.00      0.00         5\n",
      "             advmod       0.91      0.99      0.95       743\n",
      "         advmod:det       1.00      0.83      0.91         6\n",
      "               amod       0.94      0.96      0.95      1648\n",
      "              appos       0.56      0.52      0.54       128\n",
      "                aux       1.00      1.00      1.00        27\n",
      "               case       0.96      0.98      0.97      1580\n",
      "                 cc       0.96      0.98      0.97       630\n",
      "              ccomp       0.73      0.51      0.60        88\n",
      "           compound       0.73      0.77      0.75       100\n",
      "               conj       0.74      0.70      0.72       886\n",
      "           conj:svc       0.00      0.00      0.00         2\n",
      "                cop       1.00      1.00      1.00        93\n",
      "              csubj       0.84      0.72      0.77        57\n",
      "                det       0.94      0.96      0.95       475\n",
      "         det:numgov       0.79      0.79      0.79        14\n",
      "         det:nummod       0.00      0.00      0.00         4\n",
      "          discourse       0.90      0.88      0.89       227\n",
      "         dislocated       0.00      0.00      0.00         1\n",
      "               expl       0.64      0.69      0.67        13\n",
      "              fixed       0.93      0.71      0.81        38\n",
      "           flat:abs       1.00      0.50      0.67         4\n",
      "       flat:foreign       0.95      0.97      0.96        62\n",
      "          flat:name       0.89      0.96      0.93       106\n",
      "         flat:range       0.47      0.47      0.47        15\n",
      "        flat:repeat       0.50      0.17      0.25         6\n",
      "          flat:sibl       1.00      0.05      0.10        19\n",
      "         flat:title       0.78      0.57      0.66       227\n",
      "           goeswith       0.00      0.00      0.00         2\n",
      "               iobj       0.60      0.09      0.16        33\n",
      "               list       0.00      0.00      0.00         2\n",
      "               mark       0.98      0.96      0.97       264\n",
      "               nmod       0.87      0.92      0.90      1923\n",
      "              nsubj       0.64      0.69      0.66       913\n",
      "             nummod       0.77      0.64      0.70        76\n",
      "         nummod:gov       0.62      0.71      0.66        76\n",
      "                obj       0.62      0.68      0.65       697\n",
      "                obl       0.79      0.81      0.80      1170\n",
      "             orphan       0.43      0.09      0.15        33\n",
      "          parataxis       0.58      0.34      0.43       170\n",
      "parataxis:discourse       1.00      0.17      0.29        41\n",
      "  parataxis:newsent       0.00      0.00      0.00         1\n",
      "      parataxis:rel       0.00      0.00      0.00         8\n",
      "              punct       0.97      0.97      0.97      3097\n",
      "           vocative       0.00      0.00      0.00         6\n",
      "              xcomp       0.80      0.80      0.80       106\n",
      "           xcomp:sp       0.62      0.26      0.36        39\n",
      "\n",
      "           accuracy                           0.86     16224\n",
      "          macro avg       0.64      0.53      0.56     16224\n",
      "       weighted avg       0.86      0.86      0.86     16224\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yehorshapanov/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_connections, predicted_lrc2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relations(tree):\n",
    "    relations = [(node[\"id\"], node[\"head\"]) for node in tree]\n",
    "    return relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dep_parse_labels(sentence, model, vectorizer):\n",
    "    relations = get_relations(sentence)\n",
    "    labels = []\n",
    "    for rel in relations:\n",
    "        child_id, parent_id = rel\n",
    "        if not parent_id is None and parent_id>0:\n",
    "            features = get_features(sentence, child_id-1, parent_id-1)\n",
    "            label = model.predict(vectorizer.transform([features]))\n",
    "            labels.extend(label)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 17148\n",
      "Correctly defined: 6887\n",
      "UAS: 0.4\n",
      "Full match: 0.32\n"
     ]
    }
   ],
   "source": [
    "total, tp, full_match = 0, 0, 0\n",
    "for tree in test_trees:\n",
    "    golden, _ = get_connections_from_sentence(tree)\n",
    "    predicted = dep_parse_labels(tree, lrc2, vec2)\n",
    "    total += len(tree)\n",
    "    tp += len(set(golden).intersection(set(predicted)))\n",
    "    if set(golden) == set(predicted):\n",
    "        full_match += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(\"Total:\", total)\n",
    "print(\"Correctly defined:\", tp)\n",
    "print(\"UAS:\", round(tp/total, 2))\n",
    "print(\"Full match:\", round(full_match/len(test_trees), 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
