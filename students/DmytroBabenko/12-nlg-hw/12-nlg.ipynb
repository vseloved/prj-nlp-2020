{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspired by the [tutorial](https://keras.io/examples/lstm_seq2seq/), I am going to implement character-level seq2seq for paraphrasing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16  # Batch size for training.\n",
    "epochs = 100  # Number of epochs to train for.\n",
    "latent_dim = 256  # Latent dimensionality of the encoding space.\n",
    "# num_samples = 10000  # Number of samples to train on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file):\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        lines = f.read().split('\\n')\n",
    "        return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'opusparcus_v2/en-train-100K.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data(file, line_validator, bi_directional=False):\n",
    "    lines = load_data(file)\n",
    "    input_texts, target_texts =[], []\n",
    "    \n",
    "    for line in lines:\n",
    "        input_text, target_text = line_validator(line)\n",
    "        \n",
    "        if input_text is not None and target_text is not None:\n",
    "            \n",
    "            input_texts.append(input_text)\n",
    "            target_texts.append(target_text)\n",
    "            \n",
    "            if bi_directional:\n",
    "                input_texts.append(target_text)\n",
    "                target_texts.append(input_text)\n",
    "        \n",
    "    \n",
    "    return input_texts, target_texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_for_charectr_level(line):\n",
    "    splited_lines = line.split('\\t')\n",
    "    if len(splited_lines) < 3:\n",
    "        return None, None\n",
    "    \n",
    "    input_text = splited_lines[1]\n",
    "    target_text = splited_lines[2]\n",
    "\n",
    "\n",
    "    # input_text, target_text, _ = line.split('\\t')\n",
    "    # We use \"tab\" as the \"start sequence\" character\n",
    "    # for the targets, and \"\\n\" as \"end sequence\" character.\n",
    "    target_text = '\\t' + target_text + '\\n'\n",
    "   \n",
    "    return input_text, target_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_texts, target_texts = parse_data(data_path, validate_for_charectr_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_texts, val_input_texts, target_texts, val_target_texts = train_test_split(input_texts, target_texts, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_characters = set()\n",
    "target_characters = set()\n",
    "\n",
    "for i in range(len(input_characters)):\n",
    "    for char in input_texts[i]:\n",
    "        if char not in input_characters:\n",
    "            input_characters.add(char)\n",
    "    \n",
    "    for char in target_texts[i]:\n",
    "        if char not in target_characters:\n",
    "            target_characters.add(char)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_characters = sorted(list(input_characters))\n",
    "target_characters = sorted(list(target_characters))\n",
    "num_encoder_tokens = len(input_characters) + 1\n",
    "num_decoder_tokens = len(target_characters) + 1\n",
    "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
    "max_decoder_seq_length = max([len(txt) for txt in target_texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 80000\n",
      "Number of unique input tokens: 105\n",
      "Number of unique output tokens: 143\n",
      "Max sequence length for inputs: 209\n",
      "Max sequence length for outputs: 210\n"
     ]
    }
   ],
   "source": [
    "print('Number of samples:', len(input_texts))\n",
    "print('Number of unique input tokens:', num_encoder_tokens)\n",
    "print('Number of unique output tokens:', num_decoder_tokens)\n",
    "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
    "print('Max sequence length for outputs:', max_decoder_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_token_index = dict(\n",
    "    [(char, i) for i, char in enumerate(input_characters)])\n",
    "input_token_index['oov'] = len(input_token_index)\n",
    "\n",
    "target_token_index = dict(\n",
    "    [(char, i) for i, char in enumerate(target_characters)])\n",
    "target_token_index['oov'] = len(target_token_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the training data is big, and creating sparse matrix cannot be load into RAM, let's create Dataset Generator to avoid out of memory error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/keras-data-generators-and-how-to-use-them-b69129ed779c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset_generator import DataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DataGenerator(input_texts=input_texts, target_texts=target_texts,\n",
    "                        input_token_index=input_token_index, target_token_index=target_token_index,\n",
    "                        max_encoder_seq_length=max_encoder_seq_length, num_encoder_tokens=num_encoder_tokens,\n",
    "                        max_decoder_seq_length=max_decoder_seq_length, num_decoder_tokens=num_decoder_tokens,\n",
    "                        batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = DataGenerator(input_texts=val_input_texts, target_texts=val_target_texts,\n",
    "                        input_token_index=input_token_index, target_token_index=target_token_index,\n",
    "                        max_encoder_seq_length=max_encoder_seq_length, num_encoder_tokens=num_encoder_tokens,\n",
    "                        max_decoder_seq_length=max_decoder_seq_length, num_decoder_tokens=num_decoder_tokens,\n",
    "                        batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an input sequence and process it.\n",
    "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "encoder = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "# Run training\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5000/5000 [==============================] - 157s 31ms/step - loss: 0.1689 - accuracy: 0.9529 - val_loss: 0.1228 - val_accuracy: 0.9640\n",
      "Epoch 2/100\n",
      "5000/5000 [==============================] - 157s 31ms/step - loss: 0.1122 - accuracy: 0.9672 - val_loss: 0.1053 - val_accuracy: 0.9689\n",
      "Epoch 3/100\n",
      "5000/5000 [==============================] - 153s 31ms/step - loss: 0.0996 - accuracy: 0.9704 - val_loss: 0.0989 - val_accuracy: 0.9706\n",
      "Epoch 4/100\n",
      "5000/5000 [==============================] - 155s 31ms/step - loss: 0.0938 - accuracy: 0.9719 - val_loss: 0.0951 - val_accuracy: 0.9717\n",
      "Epoch 5/100\n",
      "5000/5000 [==============================] - 153s 31ms/step - loss: 0.0902 - accuracy: 0.9729 - val_loss: 0.0930 - val_accuracy: 0.9722\n",
      "Epoch 6/100\n",
      "5000/5000 [==============================] - 154s 31ms/step - loss: 0.0875 - accuracy: 0.9735 - val_loss: 0.0914 - val_accuracy: 0.9728\n",
      "Epoch 7/100\n",
      "5000/5000 [==============================] - 154s 31ms/step - loss: 0.0855 - accuracy: 0.9741 - val_loss: 0.0903 - val_accuracy: 0.9730\n",
      "Epoch 8/100\n",
      "5000/5000 [==============================] - 154s 31ms/step - loss: 0.0840 - accuracy: 0.9745 - val_loss: 0.0897 - val_accuracy: 0.9732\n",
      "Epoch 9/100\n",
      "5000/5000 [==============================] - 156s 31ms/step - loss: 0.0832 - accuracy: 0.9747 - val_loss: 0.0892 - val_accuracy: 0.9732\n",
      "Epoch 10/100\n",
      "5000/5000 [==============================] - 156s 31ms/step - loss: 0.0817 - accuracy: 0.9750 - val_loss: 0.0891 - val_accuracy: 0.9733\n",
      "Epoch 11/100\n",
      "5000/5000 [==============================] - 153s 31ms/step - loss: 0.0808 - accuracy: 0.9752 - val_loss: 0.0888 - val_accuracy: 0.9735\n",
      "Epoch 12/100\n",
      "5000/5000 [==============================] - 153s 31ms/step - loss: 0.0800 - accuracy: 0.9754 - val_loss: 0.0884 - val_accuracy: 0.9737\n",
      "Epoch 13/100\n",
      "5000/5000 [==============================] - 155s 31ms/step - loss: 0.0794 - accuracy: 0.9756 - val_loss: 0.0884 - val_accuracy: 0.9738\n",
      "Epoch 14/100\n",
      "5000/5000 [==============================] - 152s 30ms/step - loss: 0.0788 - accuracy: 0.9757 - val_loss: 0.0881 - val_accuracy: 0.9737\n",
      "Epoch 15/100\n",
      "5000/5000 [==============================] - 154s 31ms/step - loss: 0.0782 - accuracy: 0.9759 - val_loss: 0.0880 - val_accuracy: 0.9737\n",
      "Epoch 16/100\n",
      "5000/5000 [==============================] - 152s 30ms/step - loss: 0.0778 - accuracy: 0.9760 - val_loss: 0.0883 - val_accuracy: 0.9739\n",
      "Epoch 17/100\n",
      "5000/5000 [==============================] - 155s 31ms/step - loss: 0.0773 - accuracy: 0.9761 - val_loss: 0.0881 - val_accuracy: 0.9740\n",
      "Epoch 18/100\n",
      "5000/5000 [==============================] - 152s 30ms/step - loss: 0.0770 - accuracy: 0.9762 - val_loss: 0.0881 - val_accuracy: 0.9739\n",
      "Epoch 19/100\n",
      "5000/5000 [==============================] - 151s 30ms/step - loss: 0.0766 - accuracy: 0.9762 - val_loss: 0.0881 - val_accuracy: 0.9739\n",
      "Epoch 20/100\n",
      "5000/5000 [==============================] - 151s 30ms/step - loss: 0.0764 - accuracy: 0.9763 - val_loss: 0.0878 - val_accuracy: 0.9739\n",
      "Epoch 21/100\n",
      "5000/5000 [==============================] - 153s 31ms/step - loss: 0.0760 - accuracy: 0.9764 - val_loss: 0.0882 - val_accuracy: 0.9739\n",
      "Epoch 22/100\n",
      "5000/5000 [==============================] - 150s 30ms/step - loss: 0.0758 - accuracy: 0.9765 - val_loss: 0.0883 - val_accuracy: 0.9739\n",
      "Epoch 23/100\n",
      "5000/5000 [==============================] - 149s 30ms/step - loss: 0.0756 - accuracy: 0.9765 - val_loss: 0.0880 - val_accuracy: 0.9740\n",
      "Epoch 24/100\n",
      "5000/5000 [==============================] - 152s 30ms/step - loss: 0.0861 - accuracy: 0.9741 - val_loss: 0.0883 - val_accuracy: 0.9739\n",
      "Epoch 25/100\n",
      "5000/5000 [==============================] - 153s 31ms/step - loss: 0.0755 - accuracy: 0.9765 - val_loss: 0.0883 - val_accuracy: 0.9738\n",
      "Epoch 26/100\n",
      "5000/5000 [==============================] - 150s 30ms/step - loss: 0.0751 - accuracy: 0.9766 - val_loss: 0.0881 - val_accuracy: 0.9739\n",
      "Epoch 27/100\n",
      "5000/5000 [==============================] - 151s 30ms/step - loss: 0.0749 - accuracy: 0.9766 - val_loss: 0.0881 - val_accuracy: 0.9740\n",
      "Epoch 28/100\n",
      "5000/5000 [==============================] - 152s 30ms/step - loss: 0.0747 - accuracy: 0.9767 - val_loss: 0.0884 - val_accuracy: 0.9740\n",
      "Epoch 29/100\n",
      "5000/5000 [==============================] - 151s 30ms/step - loss: 0.0746 - accuracy: 0.9767 - val_loss: 0.0881 - val_accuracy: 0.9741\n",
      "Epoch 30/100\n",
      "5000/5000 [==============================] - 154s 31ms/step - loss: 0.0744 - accuracy: 0.9768 - val_loss: 0.0882 - val_accuracy: 0.9741\n",
      "Epoch 31/100\n",
      "5000/5000 [==============================] - 150s 30ms/step - loss: 0.0743 - accuracy: 0.9768 - val_loss: 0.0885 - val_accuracy: 0.9739\n",
      "Epoch 32/100\n",
      "5000/5000 [==============================] - 150s 30ms/step - loss: 0.0741 - accuracy: 0.9768 - val_loss: 0.0881 - val_accuracy: 0.9741\n",
      "Epoch 33/100\n",
      "5000/5000 [==============================] - 150s 30ms/step - loss: 0.0748 - accuracy: 0.9766 - val_loss: 0.0883 - val_accuracy: 0.9741\n",
      "Epoch 34/100\n",
      "5000/5000 [==============================] - 149s 30ms/step - loss: 0.0733 - accuracy: 0.9773 - val_loss: 0.0872 - val_accuracy: 0.9749\n",
      "Epoch 35/100\n",
      "5000/5000 [==============================] - 148s 30ms/step - loss: 0.0728 - accuracy: 0.9775 - val_loss: 0.0874 - val_accuracy: 0.9746\n",
      "Epoch 36/100\n",
      "5000/5000 [==============================] - 148s 30ms/step - loss: 0.0761 - accuracy: 0.9766 - val_loss: 0.0881 - val_accuracy: 0.9746\n",
      "Epoch 37/100\n",
      "5000/5000 [==============================] - 143s 29ms/step - loss: 0.0733 - accuracy: 0.9773 - val_loss: 0.0882 - val_accuracy: 0.9742\n",
      "Epoch 38/100\n",
      "5000/5000 [==============================] - 141s 28ms/step - loss: 0.0733 - accuracy: 0.9771 - val_loss: 0.0881 - val_accuracy: 0.9744\n",
      "Epoch 39/100\n",
      "5000/5000 [==============================] - 143s 29ms/step - loss: 0.0733 - accuracy: 0.9771 - val_loss: 0.0881 - val_accuracy: 0.9744\n",
      "Epoch 40/100\n",
      "5000/5000 [==============================] - 143s 29ms/step - loss: 0.0752 - accuracy: 0.9766 - val_loss: 0.0889 - val_accuracy: 0.9740\n",
      "Epoch 41/100\n",
      "5000/5000 [==============================] - 144s 29ms/step - loss: 0.0735 - accuracy: 0.9770 - val_loss: 0.0888 - val_accuracy: 0.9741\n",
      "Epoch 42/100\n",
      "5000/5000 [==============================] - 143s 29ms/step - loss: 0.0736 - accuracy: 0.9770 - val_loss: 0.0884 - val_accuracy: 0.9744\n",
      "Epoch 43/100\n",
      "5000/5000 [==============================] - 147s 29ms/step - loss: 0.0731 - accuracy: 0.9771 - val_loss: 0.0876 - val_accuracy: 0.9748\n",
      "Epoch 44/100\n",
      "5000/5000 [==============================] - 141s 28ms/step - loss: 0.0723 - accuracy: 0.9776 - val_loss: 0.0873 - val_accuracy: 0.9749\n",
      "Epoch 45/100\n",
      "5000/5000 [==============================] - 146s 29ms/step - loss: 0.0720 - accuracy: 0.9778 - val_loss: 0.0882 - val_accuracy: 0.9748\n",
      "Epoch 46/100\n",
      "5000/5000 [==============================] - 139s 28ms/step - loss: 0.0722 - accuracy: 0.9777 - val_loss: 0.0883 - val_accuracy: 0.9748\n",
      "Epoch 47/100\n",
      "5000/5000 [==============================] - 142s 28ms/step - loss: 0.0719 - accuracy: 0.9778 - val_loss: 0.0874 - val_accuracy: 0.9749\n",
      "Epoch 48/100\n",
      "5000/5000 [==============================] - 143s 29ms/step - loss: 0.0731 - accuracy: 0.9775 - val_loss: 0.0876 - val_accuracy: 0.9749\n",
      "Epoch 49/100\n",
      "5000/5000 [==============================] - 139s 28ms/step - loss: 0.0719 - accuracy: 0.9778 - val_loss: 0.0883 - val_accuracy: 0.9749\n",
      "Epoch 50/100\n",
      "5000/5000 [==============================] - 140s 28ms/step - loss: 0.0719 - accuracy: 0.9778 - val_loss: 0.0879 - val_accuracy: 0.9749\n",
      "Epoch 51/100\n",
      "5000/5000 [==============================] - 141s 28ms/step - loss: 0.0734 - accuracy: 0.9775 - val_loss: 0.0879 - val_accuracy: 0.9749\n",
      "Epoch 52/100\n",
      "5000/5000 [==============================] - 140s 28ms/step - loss: 0.0721 - accuracy: 0.9777 - val_loss: 0.0879 - val_accuracy: 0.9750\n",
      "Epoch 53/100\n",
      "5000/5000 [==============================] - 139s 28ms/step - loss: 0.0720 - accuracy: 0.9777 - val_loss: 0.0875 - val_accuracy: 0.9750\n",
      "Epoch 54/100\n",
      "5000/5000 [==============================] - 141s 28ms/step - loss: 0.0716 - accuracy: 0.9779 - val_loss: 0.0883 - val_accuracy: 0.9749\n",
      "Epoch 55/100\n",
      "5000/5000 [==============================] - 140s 28ms/step - loss: 0.0716 - accuracy: 0.9778 - val_loss: 0.0878 - val_accuracy: 0.9750\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 163s 33ms/step - loss: 0.0715 - accuracy: 0.9779 - val_loss: 0.0878 - val_accuracy: 0.9750\n",
      "Epoch 57/100\n",
      "5000/5000 [==============================] - 162s 32ms/step - loss: 0.0714 - accuracy: 0.9779 - val_loss: 0.0879 - val_accuracy: 0.9750\n",
      "Epoch 58/100\n",
      "5000/5000 [==============================] - 157s 31ms/step - loss: 0.0716 - accuracy: 0.9779 - val_loss: 0.0882 - val_accuracy: 0.9748\n",
      "Epoch 59/100\n",
      "5000/5000 [==============================] - 160s 32ms/step - loss: 0.0713 - accuracy: 0.9779 - val_loss: 0.0877 - val_accuracy: 0.9750\n",
      "Epoch 60/100\n",
      "5000/5000 [==============================] - 161s 32ms/step - loss: 0.0711 - accuracy: 0.9780 - val_loss: 0.0880 - val_accuracy: 0.9750\n",
      "Epoch 61/100\n",
      "5000/5000 [==============================] - 161s 32ms/step - loss: 0.0711 - accuracy: 0.9780 - val_loss: 0.0880 - val_accuracy: 0.9750\n",
      "Epoch 62/100\n",
      "5000/5000 [==============================] - 161s 32ms/step - loss: 0.0713 - accuracy: 0.9779 - val_loss: 0.0881 - val_accuracy: 0.9750\n",
      "Epoch 63/100\n",
      "5000/5000 [==============================] - 160s 32ms/step - loss: 0.0712 - accuracy: 0.9779 - val_loss: 0.0886 - val_accuracy: 0.9748\n",
      "Epoch 64/100\n",
      "5000/5000 [==============================] - 160s 32ms/step - loss: 0.0711 - accuracy: 0.9779 - val_loss: 0.0884 - val_accuracy: 0.9749\n",
      "Epoch 65/100\n",
      "5000/5000 [==============================] - 158s 32ms/step - loss: 0.0713 - accuracy: 0.9778 - val_loss: 0.0885 - val_accuracy: 0.9749\n",
      "Epoch 66/100\n",
      "5000/5000 [==============================] - 158s 32ms/step - loss: 0.0735 - accuracy: 0.9771 - val_loss: 0.0890 - val_accuracy: 0.9742\n",
      "Epoch 67/100\n",
      "5000/5000 [==============================] - 159s 32ms/step - loss: 0.0717 - accuracy: 0.9776 - val_loss: 0.0884 - val_accuracy: 0.9750\n",
      "Epoch 68/100\n",
      "5000/5000 [==============================] - 158s 32ms/step - loss: 0.0704 - accuracy: 0.9782 - val_loss: 0.0860 - val_accuracy: 0.9759\n",
      "Epoch 69/100\n",
      "5000/5000 [==============================] - 155s 31ms/step - loss: 0.0711 - accuracy: 0.9783 - val_loss: 0.0857 - val_accuracy: 0.9759\n",
      "Epoch 70/100\n",
      "5000/5000 [==============================] - 156s 31ms/step - loss: 0.0687 - accuracy: 0.9790 - val_loss: 0.0846 - val_accuracy: 0.9762\n",
      "Epoch 71/100\n",
      "5000/5000 [==============================] - 158s 32ms/step - loss: 0.0677 - accuracy: 0.9793 - val_loss: 0.0838 - val_accuracy: 0.9766\n",
      "Epoch 72/100\n",
      "5000/5000 [==============================] - 158s 32ms/step - loss: 0.0670 - accuracy: 0.9795 - val_loss: 0.0838 - val_accuracy: 0.9766\n",
      "Epoch 73/100\n",
      "5000/5000 [==============================] - 155s 31ms/step - loss: 0.0671 - accuracy: 0.9795 - val_loss: 0.0855 - val_accuracy: 0.9762\n",
      "Epoch 74/100\n",
      "5000/5000 [==============================] - 157s 31ms/step - loss: 0.0690 - accuracy: 0.9792 - val_loss: 0.0838 - val_accuracy: 0.9767\n",
      "Epoch 75/100\n",
      "5000/5000 [==============================] - 155s 31ms/step - loss: 0.0676 - accuracy: 0.9796 - val_loss: 0.0827 - val_accuracy: 0.9770\n",
      "Epoch 76/100\n",
      "5000/5000 [==============================] - 157s 31ms/step - loss: 0.0664 - accuracy: 0.9799 - val_loss: 0.0818 - val_accuracy: 0.9773\n",
      "Epoch 77/100\n",
      "5000/5000 [==============================] - 159s 32ms/step - loss: 0.0654 - accuracy: 0.9803 - val_loss: 0.0807 - val_accuracy: 0.9777\n",
      "Epoch 78/100\n",
      "5000/5000 [==============================] - 155s 31ms/step - loss: 0.0646 - accuracy: 0.9805 - val_loss: 0.0805 - val_accuracy: 0.9778\n",
      "Epoch 79/100\n",
      "5000/5000 [==============================] - 158s 32ms/step - loss: 0.0639 - accuracy: 0.9807 - val_loss: 0.0804 - val_accuracy: 0.9779\n",
      "Epoch 80/100\n",
      "5000/5000 [==============================] - 155s 31ms/step - loss: 0.0647 - accuracy: 0.9806 - val_loss: 0.0797 - val_accuracy: 0.9780\n",
      "Epoch 81/100\n",
      "5000/5000 [==============================] - 154s 31ms/step - loss: 0.0637 - accuracy: 0.9808 - val_loss: 0.0800 - val_accuracy: 0.9781\n",
      "Epoch 82/100\n",
      "5000/5000 [==============================] - 153s 31ms/step - loss: 0.0628 - accuracy: 0.9811 - val_loss: 0.0798 - val_accuracy: 0.9782\n",
      "Epoch 83/100\n",
      "5000/5000 [==============================] - 155s 31ms/step - loss: 0.0623 - accuracy: 0.9812 - val_loss: 0.0791 - val_accuracy: 0.9783\n",
      "Epoch 84/100\n",
      "5000/5000 [==============================] - 153s 31ms/step - loss: 0.0619 - accuracy: 0.9814 - val_loss: 0.0791 - val_accuracy: 0.9784\n",
      "Epoch 85/100\n",
      "5000/5000 [==============================] - 153s 31ms/step - loss: 0.0616 - accuracy: 0.9815 - val_loss: 0.0793 - val_accuracy: 0.9784\n",
      "Epoch 86/100\n",
      "5000/5000 [==============================] - 154s 31ms/step - loss: 0.0612 - accuracy: 0.9816 - val_loss: 0.0791 - val_accuracy: 0.9784\n",
      "Epoch 87/100\n",
      "5000/5000 [==============================] - 151s 30ms/step - loss: 0.0610 - accuracy: 0.9816 - val_loss: 0.0791 - val_accuracy: 0.9784\n",
      "Epoch 88/100\n",
      "5000/5000 [==============================] - 152s 30ms/step - loss: 0.0607 - accuracy: 0.9817 - val_loss: 0.0788 - val_accuracy: 0.9786\n",
      "Epoch 89/100\n",
      "5000/5000 [==============================] - 150s 30ms/step - loss: 0.0604 - accuracy: 0.9819 - val_loss: 0.0787 - val_accuracy: 0.9786\n",
      "Epoch 90/100\n",
      "5000/5000 [==============================] - 153s 31ms/step - loss: 0.0602 - accuracy: 0.9819 - val_loss: 0.0784 - val_accuracy: 0.9787\n",
      "Epoch 91/100\n",
      "5000/5000 [==============================] - 153s 31ms/step - loss: 0.0600 - accuracy: 0.9819 - val_loss: 0.0783 - val_accuracy: 0.9787\n",
      "Epoch 92/100\n",
      "5000/5000 [==============================] - 150s 30ms/step - loss: 0.0598 - accuracy: 0.9820 - val_loss: 0.0783 - val_accuracy: 0.9788\n",
      "Epoch 93/100\n",
      "5000/5000 [==============================] - 150s 30ms/step - loss: 0.0595 - accuracy: 0.9821 - val_loss: 0.0784 - val_accuracy: 0.9788\n",
      "Epoch 94/100\n",
      "5000/5000 [==============================] - 153s 31ms/step - loss: 0.0592 - accuracy: 0.9822 - val_loss: 0.0783 - val_accuracy: 0.9788\n",
      "Epoch 95/100\n",
      "5000/5000 [==============================] - 152s 30ms/step - loss: 0.0590 - accuracy: 0.9822 - val_loss: 0.0783 - val_accuracy: 0.9789\n",
      "Epoch 96/100\n",
      "5000/5000 [==============================] - 149s 30ms/step - loss: 0.0588 - accuracy: 0.9823 - val_loss: 0.0783 - val_accuracy: 0.9790\n",
      "Epoch 97/100\n",
      "5000/5000 [==============================] - 150s 30ms/step - loss: 0.0586 - accuracy: 0.9824 - val_loss: 0.0786 - val_accuracy: 0.9789\n",
      "Epoch 98/100\n",
      "5000/5000 [==============================] - 153s 31ms/step - loss: 0.0584 - accuracy: 0.9824 - val_loss: 0.0783 - val_accuracy: 0.9789\n",
      "Epoch 99/100\n",
      "5000/5000 [==============================] - 149s 30ms/step - loss: 0.0582 - accuracy: 0.9825 - val_loss: 0.0779 - val_accuracy: 0.9790\n",
      "Epoch 100/100\n",
      "5000/5000 [==============================] - 151s 30ms/step - loss: 0.0580 - accuracy: 0.9825 - val_loss: 0.0782 - val_accuracy: 0.9790\n",
      "CPU times: user 5h 36min 59s, sys: 15min 37s, total: 5h 52min 36s\n",
      "Wall time: 4h 13min 1s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9b3804c9d0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "model.fit(dataset,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=val_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model.save('s2s_paraphrase.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run several examples to see the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sampling models\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)\n",
    "\n",
    "# Reverse-lookup token index to decode sequences back to\n",
    "# something readable.\n",
    "reverse_input_char_index = dict(\n",
    "    (i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict(\n",
    "    (i, char) for char, i in target_token_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_for_dev_corpus(line):\n",
    "    splited_lines = line.split('\\t')\n",
    "    if len(splited_lines) < 3:\n",
    "        return None, None\n",
    "\n",
    "    input_text = splited_lines[1]\n",
    "    target_text = splited_lines[2]\n",
    "    mark = float(splited_lines[3])\n",
    "    \n",
    "    if mark < 3.0 or mark > 4.0:\n",
    "        return None, None\n",
    "    \n",
    "    target_text = '\\t' + target_text + '\\n'\n",
    "    \n",
    "    return input_text, target_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_input_texts, dev_target_texts = parse_data(\"opusparcus_v2/en-dev.txt\", validate_for_dev_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------\n",
      "Input sentence: When 'd you last see him ?\n",
      "Decoded sentence: When will you be back ?\n",
      "\n",
      "-Reverse example-\n",
      "Input sentence: When was the last time you saw him ?\n",
      "Decoded sentence: When will you be back ?\n",
      "\n",
      "----------------------------------------------------\n",
      "Input sentence: Anyone who can verify that ?\n",
      "Decoded sentence: Is there anything you need ?\n",
      "\n",
      "-Reverse example-\n",
      "Input sentence: Can anyone corroborate that ?\n",
      "Decoded sentence: Can anyone hear me ?\n",
      "\n",
      "----------------------------------------------------\n",
      "Input sentence: I 'm not promising anything .\n",
      "Decoded sentence: I don 't feel so good .\n",
      "\n",
      "-Reverse example-\n",
      "Input sentence: No promises , okay ?\n",
      "Decoded sentence: There 's no need to .\n",
      "\n",
      "----------------------------------------------------\n",
      "Input sentence: Nothing 's changed .\n",
      "Decoded sentence: Nothing that matters .\n",
      "\n",
      "-Reverse example-\n",
      "Input sentence: Things ain 't no different .\n",
      "Decoded sentence: Things will be fine .\n",
      "\n",
      "----------------------------------------------------\n",
      "Input sentence: Anybody hearing me ?\n",
      "Decoded sentence: Is anyone here ?\n",
      "\n",
      "-Reverse example-\n",
      "Input sentence: Can anyone hear me ?\n",
      "Decoded sentence: Can anyone hear me ?\n",
      "\n",
      "----------------------------------------------------\n",
      "Input sentence: I 'm not familiar with who that is .\n",
      "Decoded sentence: I don 't feel so good .\n",
      "\n",
      "-Reverse example-\n",
      "Input sentence: I don 't know who that is .\n",
      "Decoded sentence: I don 't want to talk about it .\n",
      "\n",
      "----------------------------------------------------\n",
      "Input sentence: I need you to trust me .\n",
      "Decoded sentence: You have to leave .\n",
      "\n",
      "-Reverse example-\n",
      "Input sentence: Please , you gotta trust me on this .\n",
      "Decoded sentence: Please , sit down .\n",
      "\n",
      "----------------------------------------------------\n",
      "Input sentence: We hope you enjoy the flight .\n",
      "Decoded sentence: We have to get out .\n",
      "\n",
      "-Reverse example-\n",
      "Input sentence: We hope you have a pleasant flight .\n",
      "Decoded sentence: We have to get out .\n",
      "\n",
      "----------------------------------------------------\n",
      "Input sentence: That 's why you rollin ' with the P.L.C. .\n",
      "Decoded sentence: That 's what I 'm talking about .\n",
      "\n",
      "-Reverse example-\n",
      "Input sentence: That 's why you with the P.L.C. , dawg .\n",
      "Decoded sentence: That 's what I 'm talking about .\n",
      "\n",
      "----------------------------------------------------\n",
      "Input sentence: Did you see him ?\n",
      "Decoded sentence: Have you been finished ?\n",
      "\n",
      "-Reverse example-\n",
      "Input sentence: You get a look at ' im ?\n",
      "Decoded sentence: You know what I 'm saying ?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for seq_index in range(10):\n",
    "    # Take one sequence (part of the training set)\n",
    "    # for trying out decoding.\n",
    "    input_seq = dataset.create_encoder_input_item_for_text(dev_input_texts[seq_index])\n",
    "    input_seq = np.array([input_seq])\n",
    "#     print(input_seq)\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('----------------------------------------------------')\n",
    "    print('Input sentence:', dev_input_texts[seq_index])\n",
    "    print('Decoded sentence:', decoded_sentence)\n",
    "    \n",
    "    print(\"-Reverse example-\")\n",
    "    target_text = dev_target_texts[seq_index].strip()\n",
    "    input_seq = dataset.create_encoder_input_item_for_text(target_text)\n",
    "    input_seq = np.array([input_seq])\n",
    "#     print(input_seq)\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('Input sentence:', target_text)\n",
    "    print('Decoded sentence:', decoded_sentence)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data_path = 'opusparcus_v2/en-dev.txt'\n",
    "dev_lines = load_data(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = rouge.Rouge(['rouge-l'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(input_texts, target_texts, evaluator):\n",
    "    predicted_texts = []\n",
    "    for input_text in input_texts:\n",
    "        input_seq = dataset.create_encoder_input_item_for_text(input_text)\n",
    "        input_seq = np.array([input_seq])\n",
    "\n",
    "        decoded_sentence = decode_sequence(input_seq)\n",
    "\n",
    "        predicted_texts.append(decoded_sentence)\n",
    "\n",
    "    return evaluator.get_scores(target_texts, predicted_texts, avg=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = evaluate(dev_input_texts, dev_target_texts, evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge-l': {'f': 0.320527282671693,\n",
       "  'p': 0.3191297290558371,\n",
       "  'r': 0.3353515450067171}}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word level seq2seq for paraphrasing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from scipy.ndimage.interpolation import shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lines = load_data(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['en-N7\\tJumby now wants to be born .\\tJumby want birth .\\t77.5163\\t2.5\\t5\\t9',\n",
       " 'en-N8\\tIt was a difficult and long delivery .\\tThe delivery was difficult and long .\\t77.5163\\t2.5\\t5\\t14',\n",
       " 'en-N12\\tI like to be beautiful everyday .\\tI like to be pretty everyday .\\t77.5163\\t2.5\\t5\\t8',\n",
       " 'en-N22\\tBernadette wants a prenup .\\tBernadette wants to get a prenup .\\t77.5163\\t2.5\\t5\\t7',\n",
       " \"en-N45\\tDon 't say you don 't remember me .\\tDon 't tell me you don 't remember me .\\t74.3904\\t3.33333\\t5\\t7\",\n",
       " 'en-N71\\tHyah ! Hmm .\\tWiggle your big toe .\\t72.2903\\t3.35714\\t5\\t9',\n",
       " 'en-N127\\tHe believes in you .\\tHe has faith in you .\\t70.2803\\t3.66667\\t5\\t9',\n",
       " \"en-N153\\tSun 's going to come up soon .\\tThe sun 's coming up soon .\\t69.6198\\t0.842262\\t5\\t12\",\n",
       " 'en-N180\\tMars-1 , Houston .\\tMars-1 , this is Houston .\\t69.1678\\t2.50758\\t5\\t7',\n",
       " \"en-N202\\tBut we have no money .\\tBut we haven 't got any money .\\t68.7652\\t1.35256\\t5\\t8\"]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_lines[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_for_word_level(line):\n",
    "    splited_lines = line.split('\\t')\n",
    "    if len(splited_lines) < 3:\n",
    "        return None, None\n",
    "    \n",
    "    input_text = splited_lines[1].strip().lower()\n",
    "    target_text = splited_lines[2].strip().lower()\n",
    "    \n",
    "    \n",
    "    input_text = 'start_ '+ input_text + ' _end'\n",
    "    target_text = 'start_ '+ target_text + ' _end'\n",
    "\n",
    "   \n",
    "    return input_text, target_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_texts, target_input_texts = parse_data(data_path, validate_for_word_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "oov_token='<oov>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(filters='', oov_token=oov_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(np.concatenate([train_input_texts, target_input_texts]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = max([len(txt) for txt in tokenizer.texts_to_sequences(np.concatenate([train_input_texts, target_input_texts]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_texts, val_input_texts, target_input_texts, val_target_input_texts = train_test_split(train_input_texts, target_input_texts, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### decoder_target_data should be one-hot-encoded "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As matrix which contains one hot vectors is too big, sometimes it is caused to out of memory, so we need to have dataset generator to avoid this issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordLevelDatasetGenerator(Sequence):\n",
    "\n",
    "    def __init__(self, input_texts, \n",
    "                 target_texts, \n",
    "                 word_index,\n",
    "                 batch_size,\n",
    "                 vocab_size,\n",
    "                 max_length):\n",
    "        \n",
    "        self.input_texts = input_texts\n",
    "        self.target_texts = target_texts        \n",
    "        self.indexes = np.arange(len(self.input_texts))\n",
    "        self.word_index = word_index\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.max_length = max_length\n",
    "\n",
    "    \n",
    "    def create_encoder_input_item_for_text(self, text):\n",
    "        encoder_input_data = np.zeros(self.max_length, dtype='float32')\n",
    "        \n",
    "        for t, word in enumerate(text.split()):\n",
    "            if t >= len(encoder_input_data):\n",
    "                break\n",
    "            encoder_input_data[t] = self.__get_token_value(word)\n",
    "            \n",
    "        return encoder_input_data\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        encoder_input_data, decoder_input_data, decoder_target_data = self.__create_zero_data()\n",
    "        \n",
    "        \n",
    "        # generate data\n",
    "        for i, idx in enumerate(indexes):\n",
    "            input_text = self.input_texts[idx]\n",
    "            target_text = self.target_texts[idx]\n",
    "\n",
    "            for t, word in enumerate(input_text.split()):\n",
    "                encoder_input_data[i, t] = self.word_index[word]\n",
    "            for t, word in enumerate(target_text.split()):\n",
    "                # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "                decoder_input_data[i, t] = self.__get_token_value(word)\n",
    "                if t > 0:\n",
    "                    # decoder_target_data will be ahead by one timestep\n",
    "                    # and will not include the start character.\n",
    "                    decoder_target_data[i, t - 1, self.__get_token_value(word)] = 1.\n",
    "\n",
    "\n",
    "        X = [encoder_input_data, decoder_input_data]\n",
    "        y = decoder_target_data\n",
    "\n",
    "        return X, y    \n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"Denotes the number of batches per epoch\n",
    "        :return: number of batches per epoch\n",
    "        \"\"\"\n",
    "        return int(np.floor(len(self.input_texts) / self.batch_size))\n",
    "    \n",
    "    def __create_zero_data(self):\n",
    "        encoder_input_data = np.zeros(\n",
    "            (self.batch_size, self.max_length),\n",
    "            dtype='float32')\n",
    "        decoder_input_data = np.zeros(\n",
    "            (self.batch_size, self.max_length),\n",
    "            dtype='float32')\n",
    "        decoder_target_data = np.zeros(\n",
    "            (self.batch_size, self.max_length, self.vocab_size),\n",
    "            dtype='float32')\n",
    "        \n",
    "        return encoder_input_data, decoder_input_data, decoder_target_data\n",
    "    \n",
    "    def __get_token_value(self, token):\n",
    "        if token in self.word_index:\n",
    "            return self.word_index[token]\n",
    "        \n",
    "        return self.word_index[oov_token]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seq2SEQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "num_encoder_tokens = vocab_size\n",
    "num_decoder_tokens = vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16  # Batch size for training.\n",
    "epochs = 10  # Number of epochs to train for.\n",
    "embedding_size = 256\n",
    "latent_dim = 256  # Latent dimensionality of the encoding space.\n",
    "# num_samples = 10000  # Number of samples to train on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = WordLevelDatasetGenerator(train_input_texts, \n",
    "                                    target_input_texts, \n",
    "                                    tokenizer.word_index,\n",
    "                                    batch_size, \n",
    "                                    vocab_size,\n",
    "                                    max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = WordLevelDatasetGenerator(val_input_texts, \n",
    "                                    val_target_input_texts, \n",
    "                                    tokenizer.word_index,\n",
    "                                    batch_size, \n",
    "                                    vocab_size,\n",
    "                                    max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an input sequence and process it.\n",
    "encoder_inputs = Input(shape=(None,))\n",
    "x = tf.keras.layers.Embedding(num_encoder_tokens, embedding_size)(encoder_inputs)\n",
    "x, state_h, state_c = LSTM(latent_dim,\n",
    "                           return_state=True)(x)\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "dex = tf.keras.layers.Embedding(num_decoder_tokens, embedding_size)\n",
    "final_dex = dex(decoder_inputs)\n",
    "\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(final_dex, initial_state=encoder_states)\n",
    "\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "# Compile & run training\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5000/5000 [==============================] - 224s 45ms/step - loss: 0.4471 - acc: 0.0629 - val_loss: 0.3871 - val_acc: 0.0724\n",
      "Epoch 2/10\n",
      "5000/5000 [==============================] - 228s 46ms/step - loss: 0.3624 - acc: 0.0766 - val_loss: 0.3460 - val_acc: 0.0795\n",
      "Epoch 3/10\n",
      "5000/5000 [==============================] - 229s 46ms/step - loss: 0.3346 - acc: 0.0827 - val_loss: 0.3332 - val_acc: 0.0834\n",
      "Epoch 4/10\n",
      "5000/5000 [==============================] - 226s 45ms/step - loss: 0.3174 - acc: 0.0865 - val_loss: 0.3226 - val_acc: 0.0862\n",
      "Epoch 5/10\n",
      "5000/5000 [==============================] - 227s 45ms/step - loss: 0.3052 - acc: 0.0893 - val_loss: 0.3137 - val_acc: 0.0879\n",
      "Epoch 6/10\n",
      "5000/5000 [==============================] - 230s 46ms/step - loss: 0.2927 - acc: 0.0912 - val_loss: 0.3040 - val_acc: 0.0894\n",
      "Epoch 7/10\n",
      "5000/5000 [==============================] - 229s 46ms/step - loss: 0.2803 - acc: 0.0929 - val_loss: 0.2966 - val_acc: 0.0899\n",
      "Epoch 8/10\n",
      "5000/5000 [==============================] - 229s 46ms/step - loss: 0.2689 - acc: 0.0944 - val_loss: 0.2895 - val_acc: 0.0912\n",
      "Epoch 9/10\n",
      "5000/5000 [==============================] - 231s 46ms/step - loss: 0.2593 - acc: 0.0957 - val_loss: 0.2863 - val_acc: 0.0915\n",
      "Epoch 10/10\n",
      "5000/5000 [==============================] - 227s 45ms/step - loss: 0.2512 - acc: 0.0969 - val_loss: 0.2826 - val_acc: 0.0920\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9140798dd0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(dataset,\n",
    "          validation_data=val_dataset,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "embedding_4 (Embedding)      (None, None, 256)         2494208   \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                [(None, 256), (None, 256) 525312    \n",
      "=================================================================\n",
      "Total params: 3,019,520\n",
      "Trainable params: 3,019,520\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# define the encoder model \n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redefine the decoder model with decoder will be getting below inputs from encoder while in prediction\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "final_dex2= dex(decoder_inputs)\n",
    "\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(final_dex2, initial_state=decoder_states_inputs)\n",
    "decoder_states2 = [state_h2, state_c2]\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling model will take encoder states and decoder_input(seed initially) and output the predictions(french word index) We dont care about decoder_states2\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs2] + decoder_states2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverse-lookup token index to decode sequences back to\n",
    "# something readable.\n",
    "reverse_input_char_index = dict(\n",
    "    (i, char) for char, i in tokenizer.word_index.items())\n",
    "reverse_target_char_index = dict(\n",
    "    (i, char) for char, i in tokenizer.word_index.items())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_text):\n",
    "    input_seq = np.array([dataset.create_encoder_input_item_for_text(input_text)])\n",
    "\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0] = tokenizer.word_index['start_']\n",
    "# Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "# Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += ' '+sampled_char\n",
    "# Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '_end' or\n",
    "           len(decoded_sentence) > max_length):\n",
    "            stop_condition = True\n",
    "# Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "# Update states\n",
    "        states_value = [h, c]\n",
    "    \n",
    "    return decoded_sentence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate on dev-corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_for_word_level_dev_corpus(line):\n",
    "    splited_lines = line.split('\\t')\n",
    "    if len(splited_lines) < 3:\n",
    "        return None, None\n",
    "    \n",
    "    input_text = splited_lines[1].strip().lower()\n",
    "    target_text = splited_lines[2].strip().lower()\n",
    "    mark = float(splited_lines[3])\n",
    "    \n",
    "    if mark < 3.0 or mark > 4.0:\n",
    "        return None, None\n",
    "    \n",
    "    \n",
    "    input_text = 'start_ '+ input_text + ' _end'\n",
    "    target_text = 'start_ '+ target_text + ' _end'\n",
    "\n",
    "   \n",
    "    return input_text, target_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_input_texts, dev_target_texts = parse_data(\"opusparcus_v2/en-dev.txt\", validate_for_word_level_dev_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_start_end(text):\n",
    "    text = text.replace(\"start_ \", \"\")\n",
    "    text = text.replace(\" _end\", \"\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_input_texts, original_target_texts = [], []\n",
    "predicted_texts = []\n",
    "for i in range(len(dev_input_texts)):\n",
    "    input_text = dev_input_texts[i]\n",
    "    predicted_text = decode_sequence(input_text)\n",
    "    predicted_text = remove_start_end(predicted_text)\n",
    "    target_text = dev_target_texts[i]\n",
    "    \n",
    "    original_input_texts.append(remove_start_end(input_text))\n",
    "    original_target_texts.append(remove_start_end(target_text))\n",
    "    \n",
    "    predicted_texts.append(predicted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------\n",
      "Input sentence: when 'd you last see him ?\n",
      "Decoded sentence:  when did you get here ?\n",
      "----------------------------------------------------\n",
      "Input sentence: anyone who can verify that ?\n",
      "Decoded sentence:  did they find him ?\n",
      "----------------------------------------------------\n",
      "Input sentence: i 'm not promising anything .\n",
      "Decoded sentence:  i can 't do anything .\n",
      "----------------------------------------------------\n",
      "Input sentence: nothing 's changed .\n",
      "Decoded sentence:  nothing to say .\n",
      "----------------------------------------------------\n",
      "Input sentence: anybody hearing me ?\n",
      "Decoded sentence:  hear me ?\n",
      "----------------------------------------------------\n",
      "Input sentence: i 'm not familiar with who that is .\n",
      "Decoded sentence:  i 'm not sure you are .\n",
      "----------------------------------------------------\n",
      "Input sentence: i need you to trust me .\n",
      "Decoded sentence:  you have to trust me .\n",
      "----------------------------------------------------\n",
      "Input sentence: we hope you enjoy the flight .\n",
      "Decoded sentence:  you 've had a good call .\n",
      "----------------------------------------------------\n",
      "Input sentence: that 's why you rollin ' with the p.l.c. .\n",
      "Decoded sentence:  this is your and i know what it 's .\n",
      "----------------------------------------------------\n",
      "Input sentence: did you see him ?\n",
      "Decoded sentence:  you 've seen him ?\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print('----------------------------------------------------')\n",
    "    print('Input sentence:', original_input_texts[i])\n",
    "    print('Decoded sentence:', predicted_texts[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = rouge.Rouge(['rouge-l'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge-l': {'f': 0.39533632010766623,\n",
       "  'p': 0.3864904498894639,\n",
       "  'r': 0.4244862417276205}}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.get_scores(original_input_texts, predicted_texts, avg=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As wee can see word level seq2seq gave us better rouge-l average (by the way, we trained word level se2seq only on 10 epoch while charecter level on 100). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotaion of 50 examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'text': original_input_texts,\n",
    "    'paraphrase_text': predicted_texts,\n",
    "    'macthed' : len(predicted_texts) * [None]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>paraphrase_text</th>\n",
       "      <th>macthed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>when 'd you last see him ?</td>\n",
       "      <td>when did you get here ?</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anyone who can verify that ?</td>\n",
       "      <td>did they find him ?</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i 'm not promising anything .</td>\n",
       "      <td>i can 't do anything .</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nothing 's changed .</td>\n",
       "      <td>nothing to say .</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>anybody hearing me ?</td>\n",
       "      <td>hear me ?</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>i 'm not familiar with who that is .</td>\n",
       "      <td>i 'm not sure you are .</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>i need you to trust me .</td>\n",
       "      <td>you have to trust me .</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>we hope you enjoy the flight .</td>\n",
       "      <td>you 've had a good call .</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>that 's why you rollin ' with the p.l.c. .</td>\n",
       "      <td>this is your and i know what it 's .</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>did you see him ?</td>\n",
       "      <td>you 've seen him ?</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>do you need any help ?</td>\n",
       "      <td>you need help ?</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>do as i say .</td>\n",
       "      <td>do what i tell you .</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>let me see your belly .</td>\n",
       "      <td>show me your hands .</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>guard against an evil eye .</td>\n",
       "      <td>i 'll be with you in the this just have a .</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>i 'm joking .</td>\n",
       "      <td>i 'm kidding .</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>let me out of here .</td>\n",
       "      <td>let me see .</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ain 't no next time .</td>\n",
       "      <td>there 's no time .</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>are you guys having issues ?</td>\n",
       "      <td>are you here ?</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>they 're not going to listen to us .</td>\n",
       "      <td>they will not be waiting .</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>i 'm a fast learner .</td>\n",
       "      <td>i 'm a is that ?</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>maybe it 'll be better this way .</td>\n",
       "      <td>well , maybe wrong .</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>but , everybody 's a liar .</td>\n",
       "      <td>they 're all the you .</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>there 's an issue .</td>\n",
       "      <td>there 's a problem .</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>oh , what year is this ?</td>\n",
       "      <td>what 's the way ?</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>get your goddamn hands up .</td>\n",
       "      <td>put your you down .</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>do not shoot .</td>\n",
       "      <td>stop that .</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>she 's doing the best she can .</td>\n",
       "      <td>she is gonna do that .</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>are you in want of cash ?</td>\n",
       "      <td>you 're the with me ?</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>i was startin ' to get worried .</td>\n",
       "      <td>i 've had how i have to do this .</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>he 's in one of his moods .</td>\n",
       "      <td>he 's got a it with him .</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>come sit over here .</td>\n",
       "      <td>come here again .</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>i 'll be a daddy .</td>\n",
       "      <td>i 'll be with you in a minute .</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>well , you didn 't tell me .</td>\n",
       "      <td>you never said that .</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>nothing is impossible .</td>\n",
       "      <td>there 's no way .</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>hold it right there .</td>\n",
       "      <td>you stay where you are .</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>i 'm gonna miss you guys .</td>\n",
       "      <td>i 'm gonna miss you .</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>you did all you could do .</td>\n",
       "      <td>you did everything you could .</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>i 'll give myself up .</td>\n",
       "      <td>i 'm gonna try .</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>help is coming , kid .</td>\n",
       "      <td>help us .</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>are you fucking kidding me ?</td>\n",
       "      <td>are you this way ?</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>can i just say one thing ?</td>\n",
       "      <td>can i tell you something ?</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>it 's just the beginning .</td>\n",
       "      <td>this is just the start .</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>what are we supposed to do ?</td>\n",
       "      <td>what should we do ?</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>and that 's just the start .</td>\n",
       "      <td>that 's the only the way .</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>i 'll take care of them .</td>\n",
       "      <td>i 'm gonna take care of it .</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>how much time do i have ?</td>\n",
       "      <td>how much time have i got ?</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>doesn 't make any sense .</td>\n",
       "      <td>that doesn 't make any sense .</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>i mean , do you understand what i 'm talking a...</td>\n",
       "      <td>you know what i 'm saying ?</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>i 've lost everything .</td>\n",
       "      <td>i 've had it all .</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>it wasn 't like that .</td>\n",
       "      <td>that 's not what it 's .</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  \\\n",
       "0                          when 'd you last see him ?   \n",
       "1                        anyone who can verify that ?   \n",
       "2                       i 'm not promising anything .   \n",
       "3                                nothing 's changed .   \n",
       "4                                anybody hearing me ?   \n",
       "5                i 'm not familiar with who that is .   \n",
       "6                            i need you to trust me .   \n",
       "7                      we hope you enjoy the flight .   \n",
       "8          that 's why you rollin ' with the p.l.c. .   \n",
       "9                                   did you see him ?   \n",
       "10                             do you need any help ?   \n",
       "11                                      do as i say .   \n",
       "12                            let me see your belly .   \n",
       "13                        guard against an evil eye .   \n",
       "14                                      i 'm joking .   \n",
       "15                               let me out of here .   \n",
       "16                              ain 't no next time .   \n",
       "17                       are you guys having issues ?   \n",
       "18               they 're not going to listen to us .   \n",
       "19                              i 'm a fast learner .   \n",
       "20                  maybe it 'll be better this way .   \n",
       "21                        but , everybody 's a liar .   \n",
       "22                                there 's an issue .   \n",
       "23                           oh , what year is this ?   \n",
       "24                        get your goddamn hands up .   \n",
       "25                                     do not shoot .   \n",
       "26                    she 's doing the best she can .   \n",
       "27                          are you in want of cash ?   \n",
       "28                   i was startin ' to get worried .   \n",
       "29                        he 's in one of his moods .   \n",
       "30                               come sit over here .   \n",
       "31                                 i 'll be a daddy .   \n",
       "32                       well , you didn 't tell me .   \n",
       "33                            nothing is impossible .   \n",
       "34                              hold it right there .   \n",
       "35                         i 'm gonna miss you guys .   \n",
       "36                         you did all you could do .   \n",
       "37                             i 'll give myself up .   \n",
       "38                             help is coming , kid .   \n",
       "39                       are you fucking kidding me ?   \n",
       "40                         can i just say one thing ?   \n",
       "41                         it 's just the beginning .   \n",
       "42                       what are we supposed to do ?   \n",
       "43                       and that 's just the start .   \n",
       "44                          i 'll take care of them .   \n",
       "45                          how much time do i have ?   \n",
       "46                          doesn 't make any sense .   \n",
       "47  i mean , do you understand what i 'm talking a...   \n",
       "48                            i 've lost everything .   \n",
       "49                             it wasn 't like that .   \n",
       "\n",
       "                                 paraphrase_text macthed  \n",
       "0                        when did you get here ?    None  \n",
       "1                            did they find him ?    None  \n",
       "2                         i can 't do anything .    None  \n",
       "3                               nothing to say .    None  \n",
       "4                                      hear me ?    None  \n",
       "5                        i 'm not sure you are .    None  \n",
       "6                         you have to trust me .    None  \n",
       "7                      you 've had a good call .    None  \n",
       "8           this is your and i know what it 's .    None  \n",
       "9                             you 've seen him ?    None  \n",
       "10                               you need help ?    None  \n",
       "11                          do what i tell you .    None  \n",
       "12                          show me your hands .    None  \n",
       "13   i 'll be with you in the this just have a .    None  \n",
       "14                                i 'm kidding .    None  \n",
       "15                                  let me see .    None  \n",
       "16                            there 's no time .    None  \n",
       "17                                are you here ?    None  \n",
       "18                    they will not be waiting .    None  \n",
       "19                              i 'm a is that ?    None  \n",
       "20                          well , maybe wrong .    None  \n",
       "21                        they 're all the you .    None  \n",
       "22                          there 's a problem .    None  \n",
       "23                             what 's the way ?    None  \n",
       "24                           put your you down .    None  \n",
       "25                                   stop that .    None  \n",
       "26                        she is gonna do that .    None  \n",
       "27                         you 're the with me ?    None  \n",
       "28             i 've had how i have to do this .    None  \n",
       "29                     he 's got a it with him .    None  \n",
       "30                             come here again .    None  \n",
       "31               i 'll be with you in a minute .    None  \n",
       "32                         you never said that .    None  \n",
       "33                             there 's no way .    None  \n",
       "34                      you stay where you are .    None  \n",
       "35                         i 'm gonna miss you .    None  \n",
       "36                you did everything you could .    None  \n",
       "37                              i 'm gonna try .    None  \n",
       "38                                     help us .    None  \n",
       "39                            are you this way ?    None  \n",
       "40                    can i tell you something ?    None  \n",
       "41                      this is just the start .    None  \n",
       "42                           what should we do ?    None  \n",
       "43                    that 's the only the way .    None  \n",
       "44                  i 'm gonna take care of it .    None  \n",
       "45                    how much time have i got ?    None  \n",
       "46                that doesn 't make any sense .    None  \n",
       "47                   you know what i 'm saying ?    None  \n",
       "48                            i 've had it all .    None  \n",
       "49                      that 's not what it 's .    None  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(50).to_csv(\"generated-data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Review annotated examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_annotated = pd.read_csv(\"generated-data-annotated.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>paraphrase_text</th>\n",
       "      <th>macthed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>when 'd you last see him ?</td>\n",
       "      <td>when did you get here ?</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>anyone who can verify that ?</td>\n",
       "      <td>did they find him ?</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>i 'm not promising anything .</td>\n",
       "      <td>i can 't do anything .</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>nothing 's changed .</td>\n",
       "      <td>nothing to say .</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>anybody hearing me ?</td>\n",
       "      <td>hear me ?</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>i 'm not familiar with who that is .</td>\n",
       "      <td>i 'm not sure you are .</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>i need you to trust me .</td>\n",
       "      <td>you have to trust me .</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>we hope you enjoy the flight .</td>\n",
       "      <td>you 've had a good call .</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>that 's why you rollin ' with the p.l.c. .</td>\n",
       "      <td>this is your and i know what it 's .</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>did you see him ?</td>\n",
       "      <td>you 've seen him ?</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>do you need any help ?</td>\n",
       "      <td>you need help ?</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>do as i say .</td>\n",
       "      <td>do what i tell you .</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>let me see your belly .</td>\n",
       "      <td>show me your hands .</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>guard against an evil eye .</td>\n",
       "      <td>i 'll be with you in the this just have a .</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>i 'm joking .</td>\n",
       "      <td>i 'm kidding .</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>let me out of here .</td>\n",
       "      <td>let me see .</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>ain 't no next time .</td>\n",
       "      <td>there 's no time .</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>are you guys having issues ?</td>\n",
       "      <td>are you here ?</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>they 're not going to listen to us .</td>\n",
       "      <td>they will not be waiting .</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>i 'm a fast learner .</td>\n",
       "      <td>i 'm a is that ?</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>maybe it 'll be better this way .</td>\n",
       "      <td>well , maybe wrong .</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>but , everybody 's a liar .</td>\n",
       "      <td>they 're all the you .</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>there 's an issue .</td>\n",
       "      <td>there 's a problem .</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>oh , what year is this ?</td>\n",
       "      <td>what 's the way ?</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>get your goddamn hands up .</td>\n",
       "      <td>put your you down .</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>do not shoot .</td>\n",
       "      <td>stop that .</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>she 's doing the best she can .</td>\n",
       "      <td>she is gonna do that .</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>are you in want of cash ?</td>\n",
       "      <td>you 're the with me ?</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>i was startin ' to get worried .</td>\n",
       "      <td>i 've had how i have to do this .</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>he 's in one of his moods .</td>\n",
       "      <td>he 's got a it with him .</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>come sit over here .</td>\n",
       "      <td>come here again .</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>i 'll be a daddy .</td>\n",
       "      <td>i 'll be with you in a minute .</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>well , you didn 't tell me .</td>\n",
       "      <td>you never said that .</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>nothing is impossible .</td>\n",
       "      <td>there 's no way .</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>hold it right there .</td>\n",
       "      <td>you stay where you are .</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>i 'm gonna miss you guys .</td>\n",
       "      <td>i 'm gonna miss you .</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>you did all you could do .</td>\n",
       "      <td>you did everything you could .</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>i 'll give myself up .</td>\n",
       "      <td>i 'm gonna try .</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>help is coming , kid .</td>\n",
       "      <td>help us .</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>are you fucking kidding me ?</td>\n",
       "      <td>are you this way ?</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>can i just say one thing ?</td>\n",
       "      <td>can i tell you something ?</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>it 's just the beginning .</td>\n",
       "      <td>this is just the start .</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>what are we supposed to do ?</td>\n",
       "      <td>what should we do ?</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>and that 's just the start .</td>\n",
       "      <td>that 's the only the way .</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>i 'll take care of them .</td>\n",
       "      <td>i 'm gonna take care of it .</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>how much time do i have ?</td>\n",
       "      <td>how much time have i got ?</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>doesn 't make any sense .</td>\n",
       "      <td>that doesn 't make any sense .</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>i mean , do you understand what i 'm talking a...</td>\n",
       "      <td>you know what i 'm saying ?</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>i 've lost everything .</td>\n",
       "      <td>i 've had it all .</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>49</td>\n",
       "      <td>it wasn 't like that .</td>\n",
       "      <td>that 's not what it 's .</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                                               text  \\\n",
       "0            0                         when 'd you last see him ?   \n",
       "1            1                       anyone who can verify that ?   \n",
       "2            2                      i 'm not promising anything .   \n",
       "3            3                               nothing 's changed .   \n",
       "4            4                               anybody hearing me ?   \n",
       "5            5               i 'm not familiar with who that is .   \n",
       "6            6                           i need you to trust me .   \n",
       "7            7                     we hope you enjoy the flight .   \n",
       "8            8         that 's why you rollin ' with the p.l.c. .   \n",
       "9            9                                  did you see him ?   \n",
       "10          10                             do you need any help ?   \n",
       "11          11                                      do as i say .   \n",
       "12          12                            let me see your belly .   \n",
       "13          13                        guard against an evil eye .   \n",
       "14          14                                      i 'm joking .   \n",
       "15          15                               let me out of here .   \n",
       "16          16                              ain 't no next time .   \n",
       "17          17                       are you guys having issues ?   \n",
       "18          18               they 're not going to listen to us .   \n",
       "19          19                              i 'm a fast learner .   \n",
       "20          20                  maybe it 'll be better this way .   \n",
       "21          21                        but , everybody 's a liar .   \n",
       "22          22                                there 's an issue .   \n",
       "23          23                           oh , what year is this ?   \n",
       "24          24                        get your goddamn hands up .   \n",
       "25          25                                     do not shoot .   \n",
       "26          26                    she 's doing the best she can .   \n",
       "27          27                          are you in want of cash ?   \n",
       "28          28                   i was startin ' to get worried .   \n",
       "29          29                        he 's in one of his moods .   \n",
       "30          30                               come sit over here .   \n",
       "31          31                                 i 'll be a daddy .   \n",
       "32          32                       well , you didn 't tell me .   \n",
       "33          33                            nothing is impossible .   \n",
       "34          34                              hold it right there .   \n",
       "35          35                         i 'm gonna miss you guys .   \n",
       "36          36                         you did all you could do .   \n",
       "37          37                             i 'll give myself up .   \n",
       "38          38                             help is coming , kid .   \n",
       "39          39                       are you fucking kidding me ?   \n",
       "40          40                         can i just say one thing ?   \n",
       "41          41                         it 's just the beginning .   \n",
       "42          42                       what are we supposed to do ?   \n",
       "43          43                       and that 's just the start .   \n",
       "44          44                          i 'll take care of them .   \n",
       "45          45                          how much time do i have ?   \n",
       "46          46                          doesn 't make any sense .   \n",
       "47          47  i mean , do you understand what i 'm talking a...   \n",
       "48          48                            i 've lost everything .   \n",
       "49          49                             it wasn 't like that .   \n",
       "\n",
       "                                 paraphrase_text macthed  \n",
       "0                        when did you get here ?      No  \n",
       "1                            did they find him ?      No  \n",
       "2                         i can 't do anything .      No  \n",
       "3                               nothing to say .     Yes  \n",
       "4                                      hear me ?     Yes  \n",
       "5                        i 'm not sure you are .      No  \n",
       "6                         you have to trust me .     Yes  \n",
       "7                      you 've had a good call .      No  \n",
       "8           this is your and i know what it 's .      No  \n",
       "9                             you 've seen him ?     Yes  \n",
       "10                               you need help ?     Yes  \n",
       "11                          do what i tell you .      No  \n",
       "12                          show me your hands .      No  \n",
       "13   i 'll be with you in the this just have a .      No  \n",
       "14                                i 'm kidding .     Yes  \n",
       "15                                  let me see .     Yes  \n",
       "16                            there 's no time .     Yes  \n",
       "17                                are you here ?      No  \n",
       "18                    they will not be waiting .      No  \n",
       "19                              i 'm a is that ?      No  \n",
       "20                          well , maybe wrong .      No  \n",
       "21                        they 're all the you .      No  \n",
       "22                          there 's a problem .     Yes  \n",
       "23                             what 's the way ?      No  \n",
       "24                           put your you down .      No  \n",
       "25                                   stop that .      No  \n",
       "26                        she is gonna do that .      No  \n",
       "27                         you 're the with me ?      No  \n",
       "28             i 've had how i have to do this .      No  \n",
       "29                     he 's got a it with him .      No  \n",
       "30                             come here again .     Yes  \n",
       "31               i 'll be with you in a minute .      No  \n",
       "32                         you never said that .     Yes  \n",
       "33                             there 's no way .      No  \n",
       "34                      you stay where you are .     Yes  \n",
       "35                         i 'm gonna miss you .     Yes  \n",
       "36                you did everything you could .     Yes  \n",
       "37                              i 'm gonna try .     Yes  \n",
       "38                                     help us .      No  \n",
       "39                            are you this way ?      No  \n",
       "40                    can i tell you something ?     Yes  \n",
       "41                      this is just the start .     Yes  \n",
       "42                           what should we do ?     Yes  \n",
       "43                    that 's the only the way .      No  \n",
       "44                  i 'm gonna take care of it .     Yes  \n",
       "45                    how much time have i got ?     Yes  \n",
       "46                that doesn 't make any sense .     Yes  \n",
       "47                   you know what i 'm saying ?     Yes  \n",
       "48                            i 've had it all .      No  \n",
       "49                      that 's not what it 's .      No  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_annotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([None, None, None, ..., None, None, None], dtype=object)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['macthed'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yes = df_annotated.loc[df_annotated['macthed'] == 'Yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>paraphrase_text</th>\n",
       "      <th>macthed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>nothing 's changed .</td>\n",
       "      <td>nothing to say .</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>anybody hearing me ?</td>\n",
       "      <td>hear me ?</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>i need you to trust me .</td>\n",
       "      <td>you have to trust me .</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>did you see him ?</td>\n",
       "      <td>you 've seen him ?</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>do you need any help ?</td>\n",
       "      <td>you need help ?</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>i 'm joking .</td>\n",
       "      <td>i 'm kidding .</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>let me out of here .</td>\n",
       "      <td>let me see .</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>ain 't no next time .</td>\n",
       "      <td>there 's no time .</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>there 's an issue .</td>\n",
       "      <td>there 's a problem .</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>come sit over here .</td>\n",
       "      <td>come here again .</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>well , you didn 't tell me .</td>\n",
       "      <td>you never said that .</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>hold it right there .</td>\n",
       "      <td>you stay where you are .</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>i 'm gonna miss you guys .</td>\n",
       "      <td>i 'm gonna miss you .</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>you did all you could do .</td>\n",
       "      <td>you did everything you could .</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>i 'll give myself up .</td>\n",
       "      <td>i 'm gonna try .</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>can i just say one thing ?</td>\n",
       "      <td>can i tell you something ?</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>it 's just the beginning .</td>\n",
       "      <td>this is just the start .</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>what are we supposed to do ?</td>\n",
       "      <td>what should we do ?</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>i 'll take care of them .</td>\n",
       "      <td>i 'm gonna take care of it .</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>how much time do i have ?</td>\n",
       "      <td>how much time have i got ?</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>doesn 't make any sense .</td>\n",
       "      <td>that doesn 't make any sense .</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>i mean , do you understand what i 'm talking a...</td>\n",
       "      <td>you know what i 'm saying ?</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                                               text  \\\n",
       "3            3                               nothing 's changed .   \n",
       "4            4                               anybody hearing me ?   \n",
       "6            6                           i need you to trust me .   \n",
       "9            9                                  did you see him ?   \n",
       "10          10                             do you need any help ?   \n",
       "14          14                                      i 'm joking .   \n",
       "15          15                               let me out of here .   \n",
       "16          16                              ain 't no next time .   \n",
       "22          22                                there 's an issue .   \n",
       "30          30                               come sit over here .   \n",
       "32          32                       well , you didn 't tell me .   \n",
       "34          34                              hold it right there .   \n",
       "35          35                         i 'm gonna miss you guys .   \n",
       "36          36                         you did all you could do .   \n",
       "37          37                             i 'll give myself up .   \n",
       "40          40                         can i just say one thing ?   \n",
       "41          41                         it 's just the beginning .   \n",
       "42          42                       what are we supposed to do ?   \n",
       "44          44                          i 'll take care of them .   \n",
       "45          45                          how much time do i have ?   \n",
       "46          46                          doesn 't make any sense .   \n",
       "47          47  i mean , do you understand what i 'm talking a...   \n",
       "\n",
       "                    paraphrase_text macthed  \n",
       "3                  nothing to say .     Yes  \n",
       "4                         hear me ?     Yes  \n",
       "6            you have to trust me .     Yes  \n",
       "9                you 've seen him ?     Yes  \n",
       "10                  you need help ?     Yes  \n",
       "14                   i 'm kidding .     Yes  \n",
       "15                     let me see .     Yes  \n",
       "16               there 's no time .     Yes  \n",
       "22             there 's a problem .     Yes  \n",
       "30                come here again .     Yes  \n",
       "32            you never said that .     Yes  \n",
       "34         you stay where you are .     Yes  \n",
       "35            i 'm gonna miss you .     Yes  \n",
       "36   you did everything you could .     Yes  \n",
       "37                 i 'm gonna try .     Yes  \n",
       "40       can i tell you something ?     Yes  \n",
       "41         this is just the start .     Yes  \n",
       "42              what should we do ?     Yes  \n",
       "44     i 'm gonna take care of it .     Yes  \n",
       "45       how much time have i got ?     Yes  \n",
       "46   that doesn 't make any sense .     Yes  \n",
       "47      you know what i 'm saying ?     Yes  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_yes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The are several interesting behaviours, where sense are same but predicted paraphrase is grammatically incorrectly. For example: <br>\n",
    "*do you need any help ? - you need help ?* <br>\t\n",
    "*anybody hearing me ? - hear me ?* <br>\n",
    "It looks like informal speaking language. <br><br>\n",
    "Also, there are some interesing good examples like: <br>\n",
    "*i 'm joking . - i 'm kidding .*  <br>\n",
    "*there 's an issue  - there 's a problem .*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = len(df_yes) / len(df_annotated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The abstract estimation accuracy by annotation: 0.44\n"
     ]
    }
   ],
   "source": [
    "print(f\"The abstract estimation accuracy by annotation: {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average rouge-l estimation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge-l': {'f': 0.41068242427474727,\n",
       "  'p': 0.3900670995670996,\n",
       "  'r': 0.44760317460317467}}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.get_scores(original_input_texts[:50], predicted_texts[:50], avg=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is wonderful that averaged F1 score is less than annotated accuracy because I accepted vice versa behaviors. However, as we calculated the Longest Common Subsequence, maybe it is not so good metric for this task, because it should not consider synonyms and different order of subsequences, which was included by the annotator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
