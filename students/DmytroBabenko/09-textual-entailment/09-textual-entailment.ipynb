{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_jsonnl(file):\n",
    "    with open(file, \"r\") as f:\n",
    "        data = [json.loads(line) for line in f.readlines()]\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "snli_path = \"snli_1.0/snli_1.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = read_jsonnl(f\"{snli_path}/snli_1.0_train.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'annotator_labels': ['neutral'],\n",
       " 'captionID': '3416050480.jpg#4',\n",
       " 'gold_label': 'neutral',\n",
       " 'pairID': '3416050480.jpg#4r1n',\n",
       " 'sentence1': 'A person on a horse jumps over a broken down airplane.',\n",
       " 'sentence1_binary_parse': '( ( ( A person ) ( on ( a horse ) ) ) ( ( jumps ( over ( a ( broken ( down airplane ) ) ) ) ) . ) )',\n",
       " 'sentence1_parse': '(ROOT (S (NP (NP (DT A) (NN person)) (PP (IN on) (NP (DT a) (NN horse)))) (VP (VBZ jumps) (PP (IN over) (NP (DT a) (JJ broken) (JJ down) (NN airplane)))) (. .)))',\n",
       " 'sentence2': 'A person is training his horse for a competition.',\n",
       " 'sentence2_binary_parse': '( ( A person ) ( ( is ( ( training ( his horse ) ) ( for ( a competition ) ) ) ) . ) )',\n",
       " 'sentence2_parse': '(ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) (VP (VBG training) (NP (PRP$ his) (NN horse)) (PP (IN for) (NP (DT a) (NN competition))))) (. .)))'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data = read_jsonnl(f\"{snli_path}/snli_1.0_dev.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = read_jsonnl(f\"{snli_path}/snli_1.0_test.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nlp_data(nlp, data):\n",
    "    X, y = [], []\n",
    "    for i in range(0, len(data)):\n",
    "        yi = data[i]['gold_label']\n",
    "        if yi not in ['entailment', 'contradiction', 'neutral']:\n",
    "            continue\n",
    "            \n",
    "        text_sent = data[i]['sentence1']\n",
    "        text_sent_tokens = nlp(text_sent)\n",
    "\n",
    "        hypothesis_sent = data[i]['sentence2']\n",
    "        hypothesis_sent_tokens = nlp(hypothesis_sent)\n",
    "        \n",
    "        xi = [text_sent_tokens, hypothesis_sent_tokens]\n",
    "        X.append(xi)\n",
    "        y.append(yi)\n",
    "        \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "550152"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save time, let's do the experiments on smaller trainig data, then run the best result on full data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 10s, sys: 408 ms, total: 5min 11s\n",
      "Wall time: 5min 12s\n"
     ]
    }
   ],
   "source": [
    "%time X_train, y_train = get_nlp_data(nlp, train_data[:30000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 45s, sys: 204 ms, total: 1min 45s\n",
      "Wall time: 1min 45s\n"
     ]
    }
   ],
   "source": [
    "%time X_dev, y_dev = get_nlp_data(nlp, dev_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dev_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import svm\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_jaccard_sim_by_lemma(sent_tokens1, sent_tokens2): \n",
    "    lemmas1 = set([token.lemma_ for token in sent_tokens1])\n",
    "    lemmas2 = set([token.lemma_ for token in sent_tokens2])\n",
    "\n",
    "    matched = lemmas1.intersection(lemmas2)\n",
    "    return float(len(matched)) / (len(lemmas1) + len(lemmas2) - len(matched))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_jaccard_sim_by_verb(sent_tokens1, sent_tokens2): \n",
    "    verbs1 = set([token.lemma_ for token in sent_tokens1 if token.pos_ == \"VERB\" and not token.lemma == \"be\"])\n",
    "    verbs2 = set([token.lemma_ for token in sent_tokens2 if token.pos_ == \"VERB\" and not token.lemma == \"be\"])\n",
    "\n",
    "    matched = verbs1.intersection(verbs2)\n",
    "    if len(verbs1) + len(verbs2) - len(matched) == 0:\n",
    "        return None\n",
    "        \n",
    "    return float(len(matched)) / (len(verbs1) + len(verbs2) - len(matched))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_verbs_in_sent(sentence, nlp):\n",
    "    doc = nlp(sentence)\n",
    "    return set([token.lemma_ for token in doc if token.pos_ == \"VERB\" and not token.lemma == \"be\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exctract_features(text_sent_tokens, hypothesis_sent_tokens, updaters):\n",
    "    features = {}\n",
    "    \n",
    "    features['text-hyp-sim'] = get_jaccard_sim_by_lemma(text_sent_tokens, hypothesis_sent_tokens)\n",
    "    text_hyp_sim_verb = get_jaccard_sim_by_verb(text_sent_tokens, hypothesis_sent_tokens)\n",
    "    if text_hyp_sim_verb:\n",
    "        features['text-hyp-sim-verb'] = text_hyp_sim_verb\n",
    "\n",
    "    features['text-len'] = len(text_sent_tokens)\n",
    "    features['hyp-len'] = len(hypothesis_sent_tokens)\n",
    "    \n",
    "    for updater in updaters:\n",
    "        updater(features, text_sent_tokens, hypothesis_sent_tokens)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_f = [exctract_features(item[0], item[1], []) for item in X_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dev_f = [exctract_features(item[0], item[1], []) for item in X_dev]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Pipeline([\n",
    "    ('vect', DictVectorizer()),\n",
    "    ('svm', svm.SVC())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36.5 s, sys: 100 ms, total: 36.6 s\n",
      "Wall time: 36.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 DictVectorizer(dtype=<class 'numpy.float64'>, separator='=',\n",
       "                                sort=True, sparse=True)),\n",
       "                ('svm',\n",
       "                 SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None,\n",
       "                     coef0=0.0, decision_function_shape='ovr', degree=3,\n",
       "                     gamma='scale', kernel='rbf', max_iter=-1,\n",
       "                     probability=False, random_state=None, shrinking=True,\n",
       "                     tol=0.001, verbose=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.fit(X_train_f, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_clf = Pipeline([\n",
    "    ('vect', DictVectorizer()),\n",
    "    ('svm', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 77.2 ms, sys: 5 Âµs, total: 77.2 ms\n",
      "Wall time: 76.9 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 DictVectorizer(dtype=<class 'numpy.float64'>, separator='=',\n",
       "                                sort=True, sparse=True)),\n",
       "                ('svm',\n",
       "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time nb_clf.fit(X_train_f, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dev_pred = nb_clf.predict(X_dev_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "contradiction       0.41      0.42      0.41      3278\n",
      "   entailment       0.51      0.48      0.49      3329\n",
      "      neutral       0.43      0.43      0.43      3235\n",
      "\n",
      "     accuracy                           0.45      9842\n",
      "    macro avg       0.45      0.45      0.45      9842\n",
      " weighted avg       0.45      0.45      0.45      9842\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_dev, y_dev_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dev_pred = clf.predict(X_dev_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "contradiction       0.42      0.62      0.50      3278\n",
      "   entailment       0.57      0.54      0.56      3329\n",
      "      neutral       0.51      0.29      0.37      3235\n",
      "\n",
      "     accuracy                           0.49      9842\n",
      "    macro avg       0.50      0.48      0.48      9842\n",
      " weighted avg       0.50      0.49      0.48      9842\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_dev, y_dev_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improve baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspired by paper, let's try to add some important features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lexical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_jaccard_sim_by_noun(sent_tokens1, sent_tokens2): \n",
    "    verbs1 = set([token.lemma_ for token in sent_tokens1 if token.pos_ == \"NOUN\" or token.pos_ == \"PRON\"])\n",
    "    verbs2 = set([token.lemma_ for token in sent_tokens2 if token.pos_ == \"NOUN\" or token.pos_ == \"PRON\"])\n",
    "\n",
    "    matched = verbs1.intersection(verbs2)\n",
    "    if len(verbs1) + len(verbs2) - len(matched) == 0:\n",
    "        return None\n",
    "        \n",
    "    return float(len(matched)) / (len(verbs1) + len(verbs2) - len(matched))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_jaccard_sim_by_bigram_lemma(features, sent_tokens1, sent_tokens2): \n",
    "    lemmas1 = [token.lemma_ for token in sent_tokens1]\n",
    "    bigrams1 = set([''.join(lemmas1[i:i+2:]) for i in range(len(lemmas1) - 1)])\n",
    "    \n",
    "    lemmas2 = [token.lemma_ for token in sent_tokens2]\n",
    "    bigrams2 = set([''.join(lemmas2[i:i+2:]) for i in range(len(lemmas2) - 1)])\n",
    "\n",
    "    matched = bigrams1.intersection(bigrams2)\n",
    "    \n",
    "    if len(bigrams1) + len(bigrams2) - len(matched) != 0:\n",
    "        features['bigram-sim'] = float(len(matched)) / (len(bigrams1) + len(bigrams2) - len(matched))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_stop_words_features(features, text_sent_tokens, hypothesis_sent_tokens):\n",
    "    text_stop_words = [token.lemma_ for token in text_sent_tokens if token.lemma_ in en_stop_words]\n",
    "    hyp_stop_words = [token.lemma_ for token in hypothesis_sent_tokens if token.lemma_ in en_stop_words]\n",
    "    \n",
    "    features['text-num-stop'] = len(text_stop_words)\n",
    "    features['hyp-num-stop'] = len(hyp_stop_words)\n",
    "    \n",
    "    text_stop_words = set(text_stop_words)\n",
    "    hyp_stop_words = set(hyp_stop_words)\n",
    "    \n",
    "    matched = text_stop_words.intersection(hyp_stop_words)\n",
    "    \n",
    "    if len(hyp_stop_words) + len(text_stop_words) - len(matched) != 0:\n",
    "        features['text-hyp-stop-sim'] = float(len(matched)) / (len(hyp_stop_words) + len(text_stop_words) - len(matched))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_more_lexical_features(features, text_sent_tokens, hypothesis_sent_tokens):\n",
    "    text_hyp_sim_noun = get_jaccard_sim_by_verb(text_sent_tokens, hypothesis_sent_tokens)\n",
    "    if text_hyp_sim_noun:\n",
    "        features['text-hyp-sim-noun'] = text_hyp_sim_noun\n",
    "        \n",
    "    add_stop_words_features(features, text_sent_tokens, hypothesis_sent_tokens)\n",
    "    add_jaccard_sim_by_bigram_lemma(features, text_sent_tokens, hypothesis_sent_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exctract_features_with_lexical(text_sent_tokens, hypothesis_sent_tokens):\n",
    "    lexical_updaters = [add_more_lexical_features]\n",
    "    return exctract_features(text_sent_tokens, hypothesis_sent_tokens, lexical_updaters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.39 s, sys: 12 ms, total: 2.41 s\n",
      "Wall time: 2.42 s\n"
     ]
    }
   ],
   "source": [
    "%time X_train_f = [exctract_features_with_lexical(item[0], item[1]) for item in X_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 839 ms, sys: 3.96 ms, total: 843 ms\n",
      "Wall time: 848 ms\n"
     ]
    }
   ],
   "source": [
    "%time X_dev_f = [exctract_features_with_lexical(item[0], item[1]) for item in X_dev]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Pipeline([\n",
    "    ('vect', DictVectorizer()),\n",
    "    ('svm', svm.SVC())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 DictVectorizer(dtype=<class 'numpy.float64'>, separator='=',\n",
       "                                sort=True, sparse=True)),\n",
       "                ('svm',\n",
       "                 SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None,\n",
       "                     coef0=0.0, decision_function_shape='ovr', degree=3,\n",
       "                     gamma='scale', kernel='rbf', max_iter=-1,\n",
       "                     probability=False, random_state=None, shrinking=True,\n",
       "                     tol=0.001, verbose=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train_f, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dev_pred = clf.predict(X_dev_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "contradiction       0.42      0.64      0.51      3278\n",
      "   entailment       0.57      0.53      0.55      3329\n",
      "      neutral       0.52      0.29      0.37      3235\n",
      "\n",
      "     accuracy                           0.49      9842\n",
      "    macro avg       0.50      0.49      0.48      9842\n",
      " weighted avg       0.51      0.49      0.48      9842\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_dev, y_dev_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### semantic features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_synonyms_and_antonyms(word):\n",
    "    synonyms = []\n",
    "    antonyms = []\n",
    "\n",
    "    for syn in wordnet.synsets(word):\n",
    "        try:\n",
    "            for l in syn.lemmas():\n",
    "                synonyms.append(l.name())\n",
    "                if l.antonyms():\n",
    "                     antonyms.append(l.antonyms()[0].name())\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    return set(synonyms), set(antonyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entailments_for_word(word):\n",
    "    entailments = set()        \n",
    "    action_syn = wordnet.synsets(word, pos='v')\n",
    "    if len(action_syn) == 0:\n",
    "        return entailments\n",
    "    action_syn = action_syn[0]\n",
    "    for e in action_syn.entailments():\n",
    "        entailments.update(set(e.lemma_names()))\n",
    "        \n",
    "    return entailments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_root_hypernyms(word):\n",
    "    result = set()\n",
    "    \n",
    "    action_syn = wordnet.synsets(word, pos='v')\n",
    "    if len(action_syn) == 0:\n",
    "        return result\n",
    "    \n",
    "    action_syn = action_syn[0]\n",
    "    for e in action_syn.root_hypernyms():\n",
    "        result.update(set(e.lemma_names()))\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['move', 'displace']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordnet.synsets('cut', pos='v')[0].root_hypernyms()[0].lemma_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'call_off', 'cancel', 'reschedule', 'scratch', 'scrub'}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_entailments_for_word('table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "POS_FOR_SYNONYMS = [\"VERB\", \"NOUN\", \"PROPN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_num_synonyms_and_antonyms(text_sent_tokens, hypothesis_sent_tokens):\n",
    "    text_synonyms = set()\n",
    "    text_antonyms = set()\n",
    "    \n",
    "    \n",
    "    for token in text_sent_tokens:\n",
    "        if token.pos_ not in POS_FOR_SYNONYMS:\n",
    "            continue\n",
    "            \n",
    "        synonyms, antonyms = get_synonyms_and_antonyms(token.lemma_)\n",
    "        text_synonyms.update(synonyms)\n",
    "        text_antonyms.update(antonyms)\n",
    "        \n",
    "    num_synonyms, num_antonyms = 0, 0\n",
    "    for token in hypothesis_sent_tokens:\n",
    "        if token.lemma_ in text_synonyms:\n",
    "            num_synonyms += 1\n",
    "            \n",
    "        if token.lemma_ in text_antonyms:\n",
    "            num_antonyms += 1\n",
    "            \n",
    "    return num_synonyms, num_antonyms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_synonyms_antonyms_features(features, text_sent_tokens, hypothesis_sent_tokens):\n",
    "    num_synonyms, num_antonyms = calc_num_synonyms_and_antonyms(text_sent_tokens, hypothesis_sent_tokens)\n",
    "    features['text-hyp-synonims'] = num_synonyms\n",
    "    features['text-hyp-antonyms'] = num_antonyms\n",
    "    \n",
    "    num_synonyms, num_antonyms = calc_num_synonyms_and_antonyms(hypothesis_sent_tokens, text_sent_tokens)\n",
    "    features['hyp-text-synonims'] = num_synonyms\n",
    "    features['hyp-text-antonyms'] = num_antonyms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_synonyms_antonyms_inverse_features(features, text_sent_tokens, hypothesis_sent_tokens):\n",
    "    text_synonyms = set()\n",
    "    text_antonyms = set()\n",
    "    \n",
    "    \n",
    "    for token in text_sent_tokens:\n",
    "        if token.pos_ not in POS_FOR_SYNONYMS:\n",
    "            continue\n",
    "            \n",
    "        synonyms, antonyms = get_synonyms_and_antonyms(token.lemma_)\n",
    "        text_synonyms.update(synonyms)\n",
    "        text_antonyms.update(antonyms)\n",
    "        \n",
    "    num_synonyms, num_antonyms = 0, 0\n",
    "    for token in hypothesis_sent_tokens:\n",
    "        if token.lemma_ in text_synonyms:\n",
    "            num_synonyms += 1\n",
    "            \n",
    "        if token.lemma_ in text_antonyms:\n",
    "            num_antonyms += 1\n",
    "            \n",
    "    features['text-hyp-synonims'] = num_synonyms\n",
    "    features['text-hyp-antonyms'] = num_antonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_entailments_overlap_features(features, text_sent_tokens, hypothesis_sent_tokens, prefix=\"\"):\n",
    "    hyp_entailments = set()\n",
    "    \n",
    "    for token in hypothesis_sent_tokens:\n",
    "#         if token.pos_ != \"VERB\":\n",
    "#             continue\n",
    "            \n",
    "        entailments = get_entailments_for_word(token.lemma_)\n",
    "        hyp_entailments.update(entailments)\n",
    "        \n",
    "    num_entailments = 0\n",
    "    for token in text_sent_tokens:\n",
    "        if token.lemma_ in hyp_entailments:\n",
    "            num_entailments += 1\n",
    "            \n",
    "#     print(num_entailments)       \n",
    "    features[f'hyp-text-entailments'] = num_entailments\n",
    "    \n",
    "    \n",
    "    text_entailments = set()\n",
    "    for token in text_sent_tokens:\n",
    "#         if token.pos_ != \"VERB\":\n",
    "#             continue\n",
    "            \n",
    "        entailments = get_entailments_for_word(token.lemma_)\n",
    "        text_entailments.update(entailments)\n",
    "        \n",
    "    num_entailments = 0\n",
    "    for token in hypothesis_sent_tokens:\n",
    "        if token.lemma_ in text_entailments:\n",
    "            num_entailments += 1\n",
    "            \n",
    "#     print(num_entailments)       \n",
    "    features[f'text-hyp-entailments'] = num_entailments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_hypernyms_overlap_features(features, text_sent_tokens, hypothesis_sent_tokens):\n",
    "    text_hypernyms = set()\n",
    "    for token in text_sent_tokens:\n",
    "#         if token.pos_ != \"VERB\":\n",
    "#             continue\n",
    "            \n",
    "        hypernyms = get_root_hypernyms(token.lemma_)\n",
    "        text_hypernyms.update(hypernyms)\n",
    "        \n",
    "    num = 0\n",
    "    for token in hypothesis_sent_tokens:\n",
    "        if token.lemma_ in text_hypernyms:\n",
    "            num += 1\n",
    "            \n",
    "#     print(num_entailments)       \n",
    "    features['text-hyp-hypernyms'] = num\n",
    "    \n",
    "    \n",
    "    hyp_hypernyms = set()\n",
    "    for token in hypothesis_sent_tokens:\n",
    "#         if token.pos_ != \"VERB\":\n",
    "#             continue\n",
    "            \n",
    "        hypernyms = get_root_hypernyms(token.lemma_)\n",
    "        hyp_hypernyms.update(hypernyms)\n",
    "        \n",
    "    num = 0\n",
    "    for token in text_sent_tokens:\n",
    "        if token.lemma_ in hyp_hypernyms:\n",
    "            num += 1\n",
    "            \n",
    "    features['hyp-text-hypernyms'] = num\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exctract_features_with_sematic(nlp, snli_item):\n",
    "    updaters = [\n",
    "                add_more_lexical_features,\n",
    "                add_synonyms_antonyms_features, \n",
    "                add_entailments_overlap_features,\n",
    "                add_hypernyms_overlap_features]\n",
    "    return exctract_features(nlp, snli_item, updaters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.7 s, sys: 152 ms, total: 20.8 s\n",
      "Wall time: 21.2 s\n"
     ]
    }
   ],
   "source": [
    "%time X_train_f = [exctract_features_with_sematic(item[0], item[1]) for item in X_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.65 s, sys: 28 ms, total: 6.68 s\n",
      "Wall time: 6.72 s\n"
     ]
    }
   ],
   "source": [
    "%time X_dev_f = [exctract_features_with_sematic(item[0], item[1]) for item in X_dev]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Pipeline([\n",
    "    ('vect', DictVectorizer()),\n",
    "    ('svm', svm.SVC())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 DictVectorizer(dtype=<class 'numpy.float64'>, separator='=',\n",
       "                                sort=True, sparse=True)),\n",
       "                ('svm',\n",
       "                 SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None,\n",
       "                     coef0=0.0, decision_function_shape='ovr', degree=3,\n",
       "                     gamma='scale', kernel='rbf', max_iter=-1,\n",
       "                     probability=False, random_state=None, shrinking=True,\n",
       "                     tol=0.001, verbose=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train_f, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dev_pred = clf.predict(X_dev_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "contradiction       0.50      0.57      0.53      3278\n",
      "   entailment       0.59      0.63      0.61      3329\n",
      "      neutral       0.51      0.40      0.45      3235\n",
      "\n",
      "     accuracy                           0.54      9842\n",
      "    macro avg       0.53      0.53      0.53      9842\n",
      " weighted avg       0.53      0.54      0.53      9842\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_dev, y_dev_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the table above, adding semantic features improved F1 score, it is not significant improvement, as I expected after added entailments, hypernyms features. Why? It is need depper investigation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train classificatior with the best features on full data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 37min 26s, sys: 11.1 s, total: 1h 37min 37s\n",
      "Wall time: 1h 37min 50s\n"
     ]
    }
   ],
   "source": [
    "%time X_train, y_train = get_nlp_data(nlp, train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 51s, sys: 148 ms, total: 5min 51s\n",
      "Wall time: 5min 51s\n"
     ]
    }
   ],
   "source": [
    "%time X_train_f = [exctract_features_with_sematic(item[0], item[1]) for item in X_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Pipeline([\n",
    "    ('vect', DictVectorizer()),\n",
    "    ('svm', svm.SVC())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 DictVectorizer(dtype=<class 'numpy.float64'>, separator='=',\n",
       "                                sort=True, sparse=True)),\n",
       "                ('svm',\n",
       "                 SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None,\n",
       "                     coef0=0.0, decision_function_shape='ovr', degree=3,\n",
       "                     gamma='scale', kernel='rbf', max_iter=-1,\n",
       "                     probability=False, random_state=None, shrinking=True,\n",
       "                     tol=0.001, verbose=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train_f, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dev_pred = clf.predict(X_dev_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "contradiction       0.51      0.58      0.54      3278\n",
      "   entailment       0.63      0.63      0.63      3329\n",
      "      neutral       0.51      0.44      0.47      3235\n",
      "\n",
      "     accuracy                           0.55      9842\n",
      "    macro avg       0.55      0.55      0.55      9842\n",
      " weighted avg       0.55      0.55      0.55      9842\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_dev, y_dev_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure the result on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 45s, sys: 168 ms, total: 1min 46s\n",
      "Wall time: 1min 46s\n"
     ]
    }
   ],
   "source": [
    "%time X_test, y_test = get_nlp_data(nlp, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.61 s, sys: 12 ms, total: 6.62 s\n",
      "Wall time: 6.62 s\n"
     ]
    }
   ],
   "source": [
    "%time X_test_f = [exctract_features_with_sematic(item[0], item[1]) for item in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = clf.predict(X_test_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "contradiction       0.52      0.58      0.55      3237\n",
      "   entailment       0.63      0.63      0.63      3368\n",
      "      neutral       0.52      0.45      0.48      3219\n",
      "\n",
      "     accuracy                           0.56      9824\n",
      "    macro avg       0.55      0.55      0.55      9824\n",
      " weighted avg       0.56      0.56      0.55      9824\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
