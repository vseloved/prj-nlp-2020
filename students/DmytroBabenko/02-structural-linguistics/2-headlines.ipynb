{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import json\n",
    "import re\n",
    "from typing import List\n",
    "from spacy.tokenizer import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json(file: str):\n",
    "    with open(file) as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(file: str):\n",
    "    lines = []\n",
    "    with open(file) as file_in:        \n",
    "        for line in file_in:\n",
    "            lines.append(line)\n",
    "            \n",
    "    return lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Заголовки новин"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Форматування"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. напишіть програму, яка форматує заголовки за вказаними правилами"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) З великої літери потрібно писати слова довжиною 4 чи більше літер. <br/>\n",
    "2) З великої літери потрібно писати перше і останнє слово заголовку, незалежно від частини мови. <br/>\n",
    "3) З великої літери потрібно писати іменники, займенники, дієслова, прикметники, прислівники та підрядні сполучники. <br/>\n",
    "4) Якщо слово написане через дефіс, велику літеру потрібно додати для кожної частинки слова (наприклад, правильно \"Self-Reflection\", а не \"Self-reflection\"). <br/>\n",
    "5) З маленької літери потрібно писати всі інші частини мови: артиклі/визначники, сурядні сполучники, прийменники, частки, вигуки. <br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeadlineFormatter:\n",
    "    \n",
    "    TITLE_POS_TAGS = ['NOUN', 'PRON', 'PROPN', 'VERB', 'ADJ', 'ADV', 'SCONJ', 'AUX']\n",
    "    LOWER_POS_TAGS = ['DET', 'CCONJ', 'PREP', 'PART', 'INTJ']\n",
    "    \n",
    "    LOWER_EXCEPTION = [\"n't\", \"'s\"]\n",
    "    \n",
    "    def __init__(self):\n",
    "        nlp = spacy.load(\"en_core_web_sm\")\n",
    "        self.__tokenizer = spacy.load(\"en_core_web_sm\")\n",
    "        self.__upper_pattern = re.compile(\"[A-Z]+\")\n",
    "\n",
    "    \n",
    "    def format(self, headline: str) -> str:\n",
    "        tokens = self.__tokenize(headline)\n",
    "        size = len(tokens)\n",
    "        \n",
    "        text_with_ws_list = []\n",
    "\n",
    "        prev_title = False\n",
    "        is_prev_punct = False\n",
    "        \n",
    "        start_quotes = False\n",
    "    \n",
    "        for i in range(0, size):\n",
    "            token = tokens[i]\n",
    "            text_with_ws = token.text_with_ws\n",
    "            \n",
    "            \n",
    "#             if token.pos_ == 'PUNCT' and token.text == \"'\":\n",
    "#                 if start_quotes:\n",
    "#                     start_quotes = False\n",
    "#                 else:\n",
    "#                     start_quotes = True\n",
    "            \n",
    "            if start_quotes is True:\n",
    "                text_with_ws_list.append(text_with_ws)\n",
    "                continue\n",
    "\n",
    "            if token.pos_ == 'PUNCT':\n",
    "                is_prev_punct = True\n",
    "                text_with_ws_list.append(text_with_ws)\n",
    "                continue\n",
    "                \n",
    "            if len(token.text) > 1 and self.__is_upper(token.text):\n",
    "                text_with_ws_list.append(text_with_ws)\n",
    "                continue\n",
    "\n",
    "\n",
    "            \n",
    "            if i == 0 or i == size -1 or self.__should_be_title(token):\n",
    "                text_with_ws = self.__title_token(token)\n",
    "                prev_title = True\n",
    "            else:\n",
    "                if prev_title and is_prev_punct:\n",
    "                    text_with_ws = self.__title_token(token)\n",
    "                    prev_title = True\n",
    "                else:\n",
    "                    prev_title = False\n",
    "                    \n",
    "                    if self.__should_be_lower(token):\n",
    "                        text_with_ws = text_with_ws.lower()\n",
    "                    \n",
    "\n",
    "            text_with_ws_list.append(text_with_ws)\n",
    "            is_prev_punct = False\n",
    "                    \n",
    "        return self.__untokenize(text_with_ws_list)\n",
    "    \n",
    "    def __should_be_title(self, token):\n",
    "        if self.__is_article(token.text) is True:\n",
    "            return False\n",
    "        \n",
    "        if token.text in self.LOWER_EXCEPTION:\n",
    "            return False\n",
    "        \n",
    "        if token.pos_ in self.TITLE_POS_TAGS:\n",
    "            return True\n",
    "        \n",
    "        if len(token.text) >= 4:\n",
    "            return True\n",
    "        \n",
    "        return False\n",
    "    \n",
    "    def __should_be_lower(self, token):\n",
    "        if self.__is_article(token.text) is True:\n",
    "            return True\n",
    "        \n",
    "        if token.pos_ in self.LOWER_POS_TAGS:\n",
    "            return True\n",
    "        \n",
    "        return False\n",
    "\n",
    "\n",
    "    def __is_upper(self, text):\n",
    "        if self.__upper_pattern.fullmatch(text) is not None:\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def __is_article(self, text: str):\n",
    "        if text.lower() in ['a', 'an', 'the']:\n",
    "            return True\n",
    "        \n",
    "        return False\n",
    "\n",
    "\n",
    "        \n",
    "                \n",
    "    def __title_token(self, token)-> str:\n",
    "        return token.text_with_ws.title()\n",
    "    \n",
    "    def __title(self, token):\n",
    "        #TODO: consider \"-\n",
    "        return token.text_with_ws.title()\n",
    "    \n",
    "    \n",
    "    def __tokenize(self, text):\n",
    "        return self.__tokenizer(text)\n",
    "    \n",
    "    def __untokenize(self, text_with_ws_list):\n",
    "        return ''.join(text_with_ws for text_with_ws in text_with_ws_list)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "headline_formatter = HeadlineFormatter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Dicks Creek: Georgia's Go-To Trout Water\""
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headline_formatter.format(\"Dicks Creek: Georgia's Go-to Trout Water\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Friday Fun: Project Runway's Kayne at SWS, Manuel Dances for Charity, Laura Bell Bundy Sings at PLAY\""
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headline_formatter.format(\"Friday Fun: Project Runway's Kayne at SWS, Manuel dances for charity, Laura Bell Bundy sings at PLAY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. перевірте якість роботи програми на валідаційній вибірці"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(expected_headlines: List[str], actual_headlines: List[str], headlines):\n",
    "    \n",
    "    assert len(expected_headlines) == len(actual_headlines)\n",
    "    tp = 0\n",
    "    \n",
    "    for i in range(0, len(expected_headlines)):\n",
    "        if expected_headlines[i] == actual_headlines[i]:\n",
    "            tp += 1\n",
    "    accuracy = tp / len(expected_headlines)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_file = \"../../../tasks/02-structural-linguistics/data/headlines-test-set.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = read_json(val_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_headlines = [item[1] for item in val_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "headlines = [item[0] for item in val_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "headline_formatter = HeadlineFormatter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_headlines = [headline_formatter.format(headline) for headline in headlines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = calculate_accuracy(expected_headlines=expected_headlines, \n",
    "                              actual_headlines=formatted_headlines, \n",
    "                              headlines=headlines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.69\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. проженіть вашу програму на корпусі заголовків з The Examiner і вирахуйте, скільки заголовків там відформатовано за правилами (скільки заголовків залишились незмінними після форматування)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "examiner_file = \"../../../tasks/02-structural-linguistics/data/examiner-headlines.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "examiner_lines = read_file(examiner_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "headline_formatter = HeadlineFormatter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were formatted 4412 out of 5000\n",
      "There were not  formatted 588 out of 5000\n"
     ]
    }
   ],
   "source": [
    "num_changed = 0\n",
    "for headline in examiner_lines:\n",
    "    headline_formatted = headline_formatter.format(headline)\n",
    "    if headline_formatted != headline:\n",
    "        num_changed += 1\n",
    "        \n",
    "size = len(examiner_lines)\n",
    "print(f\"There were formatted {num_changed} out of {size}\")\n",
    "print(f\"There were not  formatted {size - num_changed} out of {size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Вірусні новини"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import nltk\n",
    "from spacy import displacy\n",
    "from collections import Counter\n",
    "import en_core_web_sm\n",
    "from nltk.corpus import sentiwordnet as swn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Напишіть програму, яка аналізує заголовок за першими трьома ознаками (у спрощеній формі) <br/>\n",
    "1.1 Чи є в заголовку іменовані стуності? <br/>\n",
    "1.2 Чи є заголовок позитивно чи негативно забарвлений? <br/>\n",
    "1.3 Чи є в заголовку прикметники та прислівники вищого і найвищого ступенів порівняння? <br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NERIdentifier:\n",
    "    def __init__(self):\n",
    "        self.nlp = en_core_web_sm.load()\n",
    "    \n",
    "    def contains_ner(self, text: str, person=False, org=False):\n",
    "        doc = self.nlp(text)\n",
    "        \n",
    "        for ner_item in doc.ents:\n",
    "            if person and ner_item.label_ == 'PERSON':\n",
    "                return True\n",
    "            \n",
    "            if org and ner_item.label_ == 'ORG':\n",
    "                return True\n",
    "            \n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentScoreCalculator:\n",
    "\n",
    "    MAX_COUNT_IN_SENTENCE = 5\n",
    "\n",
    "    TAG_SENT_DICT = {\n",
    "        'NOUN' : 'n',\n",
    "        'VERB' : 'v',\n",
    "        'ADJ' : 'a',\n",
    "        'ADV' : 'r'\n",
    "    }\n",
    "\n",
    "    def __init__(self):\n",
    "        self.wnl = nltk.WordNetLemmatizer()\n",
    "        self.nlp = en_core_web_sm.load()\n",
    "\n",
    "    def compute_pos_neg_score(self, headline: str):\n",
    "        full_pos_score, full_neg_score = [], []\n",
    "        count = 0\n",
    "\n",
    "        doc = self.nlp(headline)\n",
    "        for item in doc:\n",
    "            sent_tag = self.get_tag_for_sentiment(item.pos_)\n",
    "            if sent_tag is None:\n",
    "                continue\n",
    "\n",
    "            word = item.text\n",
    "            lemmatizedsent = self.wnl.lemmatize(word)\n",
    "            synsets = list(swn.senti_synsets(lemmatizedsent, sent_tag))\n",
    "\n",
    "            pos_score, neg_score = 0, 0\n",
    "            if len(synsets) > 0:\n",
    "                for syn in synsets:\n",
    "                    pos_score += syn.pos_score()\n",
    "                    neg_score += syn.neg_score()\n",
    "\n",
    "                if pos_score == 0 and neg_score == 0:\n",
    "                    continue\n",
    "\n",
    "                full_pos_score.append(pos_score / len(synsets))\n",
    "                full_neg_score.append(neg_score / len(synsets))\n",
    "\n",
    "                count += 1\n",
    "\n",
    "            if count >= self.MAX_COUNT_IN_SENTENCE:\n",
    "                break\n",
    "        if count == 0:\n",
    "            return 0, 0\n",
    "\n",
    "        return sum(full_pos_score) / count, sum(full_neg_score) / count\n",
    "\n",
    "    def get_tag_for_sentiment(self, pos_tag: str):\n",
    "        if pos_tag not in self.TAG_SENT_DICT:\n",
    "            return None\n",
    "\n",
    "        return self.TAG_SENT_DICT[pos_tag]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeadlineAnalyzer:\n",
    "    \n",
    "    \n",
    "    SENT_THRESHOLD = 0.5\n",
    "    \n",
    "    COMP_SUPER_LABELS = ['JJR', 'JJS', 'RBR', 'RBS']\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.__ner_identifier = NERIdentifier()  \n",
    "        self.__sentiment_score_calculator = SentimentScoreCalculator()\n",
    "    \n",
    "    def match(self, headline: str):\n",
    "        \n",
    "        if self.contains_ner(headline) is False:\n",
    "            return False\n",
    "        \n",
    "        if self.contains_enough_pos_or_neg_sentiments(headline) is False:\n",
    "            return False\n",
    "        \n",
    "        if self.contains_comparative_or_superlative(headline) is False:\n",
    "            return False\n",
    "        \n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def contains_ner(self, headline: str):\n",
    "        return self.__ner_identifier.contains_ner(headline, person=True, org=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def contains_comparative_or_superlative(self, headline: str):\n",
    "        text = nltk.word_tokenize(headline)\n",
    "        tags = nltk.pos_tag(text)\n",
    "        \n",
    "        for tag in tags:\n",
    "            label = tag[1]\n",
    "            if label in self.COMP_SUPER_LABELS:\n",
    "                return True\n",
    "            \n",
    "        return False\n",
    "    \n",
    "\n",
    "    def contains_enough_pos_or_neg_sentiments(self, headline: str):\n",
    "        pos_score, neg_score = self.__sentiment_score_calculator.compute_pos_neg_score(headline)\n",
    "        \n",
    "        if pos_score >= self.SENT_THRESHOLD:\n",
    "            return True\n",
    "        \n",
    "        if neg_score >= self.SENT_THRESHOLD:\n",
    "            return True\n",
    "        \n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_file = \"../../../tasks/02-structural-linguistics/data/examiner-headlines.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = read_file(corpus_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "headline_analyzer = HeadlineAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### headlines with NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_headlines = [headline for headline in corpus if headline_analyzer.contains_ner(headline)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Halep enters Rogers Cup final in straight sets win over Errani\\n',\n",
       " \"Talladega turmoil could spell trouble for NASCAR's Chase field\\n\",\n",
       " '2011-2012 NHL team preview: Detroit Red Wings\\n',\n",
       " 'Cal coach Jeff Tedford taking a different approach in 2010 -- Part 1\\n',\n",
       " \"SF Beer Week 2013: what's for dinner (part 2)\\n\"]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_headlines[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_headlines_percent = 100 * len(ner_headlines) / len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 50.26 % headlines with Named-entity recognition\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are {ner_headlines_percent} % headlines with Named-entity recognition\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### headlines with positve or negative sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_neg_headlines = [headline for headline in corpus if headline_analyzer.contains_enough_pos_or_neg_sentiments(headline)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Britney Spears Hair: Yesterday's bad hair stem back from her shaving it all off [VIDEO]\\n\",\n",
       " 'The worst marketing campaigns of 2011\\n',\n",
       " '20 photos of retired Military Working Dog Gunnery Sgt. Lucca K458\\n',\n",
       " 'Public League Coaches above it all again with wrong message.\\n',\n",
       " 'Support Richmond caregivers and their loved ones on Pancreatic Cancer Advocacy Day\\n']"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_neg_headlines[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_neg_headlines_percent = 100 * len(pos_neg_headlines) / len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1.62 % headlines with Named-entity recognition\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are {pos_neg_headlines_percent} % headlines with Named-entity recognition\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### headlines with comparative and superlative adjectives and adverbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparative_superlative_headlines = [headline for headline in corpus if headline_analyzer.contains_comparative_or_superlative(headline)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Jersey Shore Season 6 cast's salaries revealed; More than President Obama!\\n\",\n",
       " \"Sweeter than 'The Hummingbird and the Honey Bee'\\n\",\n",
       " 'Study finds that young Americans are Democrats, want government to do more\\n',\n",
       " 'Ooh la la! What a most sensational woman Josephine Baker was, and is!\\n',\n",
       " 'Best 2014 Black Friday TV deals online: Amazon, Best Buy, Walmart, Target\\n']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparative_superlative_headlines[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_super_headlines_per = 100 * len(comparative_superlative_headlines) / len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4.38 % headlines with comparative or superlative adjectives or adverbs\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are {comp_super_headlines_per} % headlines with comparative or superlative adjectives or adverbs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Headlines with NER and positive or negative sentiments and comparative or superlative adjectives and adverbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "interested_headlines = [headline for headline in corpus if headline_analyzer.match(headline)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Best 2014 Black Friday TV deals online: Amazon, Best Buy, Walmart, Target\\n',\n",
       " \"World's most expensive gingerbread house\\n\",\n",
       " 'Is Glenn Mills the best sprint coach in the world? (Video)\\n',\n",
       " \"George Eliot is 'A Most Dangerous Woman' at Shakespeare Theatre of New Jersey\\n\",\n",
       " 'Weekly sustainable seafood from H&H Fresh Fish: Santa Cruz, Campbell, and more\\n',\n",
       " \"UCLA's kidney transplant survival rate is best in the U.S.\\n\"]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interested_headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent = 100 * len(interested_headlines) / len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0.12 % interesting headlines\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are {percent} % interesting headlines\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
