{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import json\n",
    "import re\n",
    "from typing import List\n",
    "from spacy.tokenizer import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json(file: str):\n",
    "    with open(file) as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Заголовки новин"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Форматування"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. напишіть програму, яка форматує заголовки за вказаними правилами"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) З великої літери потрібно писати слова довжиною 4 чи більше літер. <br/>\n",
    "2) З великої літери потрібно писати перше і останнє слово заголовку, незалежно від частини мови. <br/>\n",
    "3) З великої літери потрібно писати іменники, займенники, дієслова, прикметники, прислівники та підрядні сполучники. <br/>\n",
    "4) Якщо слово написане через дефіс, велику літеру потрібно додати для кожної частинки слова (наприклад, правильно \"Self-Reflection\", а не \"Self-reflection\"). <br/>\n",
    "5) З маленької літери потрібно писати всі інші частини мови: артиклі/визначники, сурядні сполучники, прийменники, частки, вигуки. <br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeadlineFormatter:\n",
    "    \n",
    "    TITLE_POS_TAGS = ['NOUN', 'PRON', 'PROPN', 'VERB', 'ADJ', 'ADV', 'SCONJ', 'AUX']\n",
    "    LOWER_POS_TAGS = ['DET', 'CCONJ', 'PREP', 'PART', 'INTJ']\n",
    "    \n",
    "    LOWER_EXCEPTION = [\"n't\", \"'s\"]\n",
    "    \n",
    "    def __init__(self):\n",
    "        nlp = spacy.load(\"en_core_web_sm\")\n",
    "        self.__tokenizer = spacy.load(\"en_core_web_sm\")\n",
    "        self.__upper_pattern = re.compile(\"[A-Z]+\")\n",
    "\n",
    "    \n",
    "    def format(self, headline: str) -> str:\n",
    "        tokens = self.__tokenize(headline)\n",
    "        size = len(tokens)\n",
    "        \n",
    "        text_with_ws_list = []\n",
    "\n",
    "        prev_title = False\n",
    "        is_prev_punct = False\n",
    "        \n",
    "        start_quotes = False\n",
    "    \n",
    "        for i in range(0, size):\n",
    "            token = tokens[i]\n",
    "            text_with_ws = token.text_with_ws\n",
    "            \n",
    "            \n",
    "#             if token.pos_ == 'PUNCT' and token.text == \"'\":\n",
    "#                 if start_quotes:\n",
    "#                     start_quotes = False\n",
    "#                 else:\n",
    "#                     start_quotes = True\n",
    "            \n",
    "            if start_quotes is True:\n",
    "                text_with_ws_list.append(text_with_ws)\n",
    "                continue\n",
    "\n",
    "            if token.pos_ == 'PUNCT':\n",
    "                is_prev_punct = True\n",
    "                text_with_ws_list.append(text_with_ws)\n",
    "                continue\n",
    "                \n",
    "            if len(token.text) > 1 and self.__is_upper(token.text):\n",
    "                text_with_ws_list.append(text_with_ws)\n",
    "                continue\n",
    "\n",
    "\n",
    "            \n",
    "            if i == 0 or i == size -1 or self.__should_be_title(token):\n",
    "                text_with_ws = self.__title_token(token)\n",
    "                prev_title = True\n",
    "            else:\n",
    "                if prev_title and is_prev_punct:\n",
    "                    text_with_ws = self.__title_token(token)\n",
    "                    prev_title = True\n",
    "                else:\n",
    "                    prev_title = False\n",
    "                    \n",
    "                    if self.__should_be_lower(token):\n",
    "                        text_with_ws = text_with_ws.lower()\n",
    "                    \n",
    "\n",
    "            text_with_ws_list.append(text_with_ws)\n",
    "            is_prev_punct = False\n",
    "                    \n",
    "        return self.__untokenize(text_with_ws_list)\n",
    "    \n",
    "    def __should_be_title(self, token):\n",
    "        if self.__is_article(token.text) is True:\n",
    "            return False\n",
    "        \n",
    "        if token.text in self.LOWER_EXCEPTION:\n",
    "            return False\n",
    "        \n",
    "        if token.pos_ in self.TITLE_POS_TAGS:\n",
    "            return True\n",
    "        \n",
    "        if len(token.text) >= 4:\n",
    "            return True\n",
    "        \n",
    "        return False\n",
    "    \n",
    "    def __should_be_lower(self, token):\n",
    "        if self.__is_article(token.text) is True:\n",
    "            return True\n",
    "        \n",
    "        if token.pos_ in self.LOWER_POS_TAGS:\n",
    "            return True\n",
    "        \n",
    "        return False\n",
    "\n",
    "\n",
    "    def __is_upper(self, text):\n",
    "        if self.__upper_pattern.fullmatch(text) is not None:\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def __is_article(self, text: str):\n",
    "        if text.lower() in ['a', 'an', 'the']:\n",
    "            return True\n",
    "        \n",
    "        return False\n",
    "\n",
    "\n",
    "        \n",
    "                \n",
    "    def __title_token(self, token)-> str:\n",
    "        return token.text_with_ws.title()\n",
    "    \n",
    "    def __title(self, token):\n",
    "        #TODO: consider \"-\n",
    "        return token.text_with_ws.title()\n",
    "    \n",
    "    \n",
    "    def __tokenize(self, text):\n",
    "        return self.__tokenizer(text)\n",
    "    \n",
    "    def __untokenize(self, text_with_ws_list):\n",
    "        return ''.join(text_with_ws for text_with_ws in text_with_ws_list)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "headline_formatter = HeadlineFormatter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Dicks Creek: Georgia's Go-To Trout Water\""
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headline_formatter.format(\"Dicks Creek: Georgia's Go-to Trout Water\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Friday Fun: Project Runway's Kayne at SWS, Manuel Dances for Charity, Laura Bell Bundy Sings at PLAY\""
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headline_formatter.format(\"Friday Fun: Project Runway's Kayne at SWS, Manuel dances for charity, Laura Bell Bundy sings at PLAY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. перевірте якість роботи програми на валідаційній вибірці"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(expected_headlines: List[str], actual_headlines: List[str], headlines):\n",
    "    \n",
    "    assert len(expected_headlines) == len(actual_headlines)\n",
    "    tp = 0\n",
    "    \n",
    "    for i in range(0, len(expected_headlines)):\n",
    "        if expected_headlines[i] == actual_headlines[i]:\n",
    "            tp += 1\n",
    "    accuracy = tp / len(expected_headlines)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_file = \"../../../tasks/02-structural-linguistics/data/headlines-test-set.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = read_json(val_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_headlines = [item[1] for item in val_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "headlines = [item[0] for item in val_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "headline_formatter = HeadlineFormatter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_headlines = [headline_formatter.format(headline) for headline in headlines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = calculate_accuracy(expected_headlines=expected_headlines, \n",
    "                              actual_headlines=formatted_headlines, \n",
    "                              headlines=headlines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.69\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. проженіть вашу програму на корпусі заголовків з The Examiner і вирахуйте, скільки заголовків там відформатовано за правилами (скільки заголовків залишились незмінними після форматування)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(file: str):\n",
    "    lines = []\n",
    "    with open(file) as file_in:        \n",
    "        for line in file_in:\n",
    "            lines.append(line)\n",
    "            \n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "examiner_file = \"../../../tasks/02-structural-linguistics/data/examiner-headlines.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "examiner_lines = read_file(examiner_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "headline_formatter = HeadlineFormatter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were formatted 4412 out of 5000\n",
      "There were not  formatted 588 out of 5000\n"
     ]
    }
   ],
   "source": [
    "num_changed = 0\n",
    "for headline in examiner_lines:\n",
    "    headline_formatted = headline_formatter.format(headline)\n",
    "    if headline_formatted != headline:\n",
    "        num_changed += 1\n",
    "        \n",
    "size = len(examiner_lines)\n",
    "print(f\"There were formatted {num_changed} out of {size}\")\n",
    "print(f\"There were not  formatted {size - num_changed} out of {size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Вірусні новини"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
