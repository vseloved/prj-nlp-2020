{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "def products_url(cat_id, page=1):\n",
    "    return 'https://xl-catalog-api.rozetka.com.ua/v2/goods/get?front-type=xl&category_id={}&page={}&sort=rank'.format(cat_id, page)\n",
    "\n",
    "def comments_url(product_id, page=1):\n",
    "    return 'https://product-api.rozetka.com.ua/v3/comments/get?front-type=xl&goods={}&page={}&sort=date&limit=10'.format(product_id, page)\n",
    "\n",
    "def parse_comments(d):\n",
    "    for comment in d['data']['comments']:\n",
    "        yield {\n",
    "            'mark': comment['mark'],\n",
    "            'text': comment['text'],\n",
    "            'pros': comment['dignity'],\n",
    "            'cons': comment['shortcomings']\n",
    "        }\n",
    "\n",
    "def parse_product_comments(product_id):\n",
    "    first_page_url = comments_url(product_id)\n",
    "    resp = requests.get(first_page_url)\n",
    "    body = json.loads(resp.text)\n",
    "    pages_num = body['data']['pages']['count']\n",
    "\n",
    "    yield from parse_comments(body)\n",
    "\n",
    "    for page in range(2, pages_num + 1):\n",
    "        url = comments_url(product_id, page)\n",
    "        resp = requests.get(url)\n",
    "        body = json.loads(resp.text)\n",
    "        yield from parse_comments(body)\n",
    "\n",
    "def parse_products(d):\n",
    "    for product_id in d['data']['ids']:\n",
    "        yield from parse_product_comments(product_id)\n",
    "\n",
    "def parse_category(cat_id):\n",
    "    first_page_url = products_url(cat_id)\n",
    "    resp = requests.get(first_page_url)\n",
    "    body = json.loads(resp.text)\n",
    "    pages_num = body['data']['total_pages']\n",
    "\n",
    "    yield from parse_products(body)\n",
    "\n",
    "    for page in range(2, pages_num + 1):\n",
    "        url = products_url(cat_id, page)\n",
    "        resp = requests.get(url)\n",
    "        body = json.loads(resp.text)\n",
    "        yield from parse_products(body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mark': None, 'text': 'Як повернути товар?', 'pros': '', 'cons': ''}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tvs_cat = 80037\n",
    "smart_boxes_cat = 80015\n",
    "tv_remotes_cat = 80070\n",
    "tuners_cat = 165692\n",
    "home_theatres_cat = 84535\n",
    "av_receivers_cat = 283322\n",
    "\n",
    "next(parse_category(tvs_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63146"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import itertools\n",
    "\n",
    "def drain_gracefully(gen):\n",
    "    return list(map(lambda x: (time.sleep(0.2), x)[1], gen))\n",
    "\n",
    "tvs_comments = parse_category(tvs_cat)\n",
    "sb_comments = parse_category(smart_boxes_cat)\n",
    "tv_remotes_comments = parse_category(tv_remotes_cat)\n",
    "tuners_comments = parse_category(tuners_cat) \n",
    "home_theatres_comments = parse_category(home_theatres_cat)\n",
    "av_receivers_comments = parse_category(av_receivers_cat)\n",
    "\n",
    "all_comments = itertools.chain(tvs_comments, sb_comments, tv_remotes_comments, tuners_comments, home_theatres_comments, av_receivers_comments)\n",
    "\n",
    "# go to sleep now\n",
    "all_comments = drain_gracefully(all_comments)\n",
    "len(all_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('all-comments.json', 'w') as f:\n",
    "    json.dump(all_comments, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def sanitize_comments(comments):\n",
    "    for c in all_comments:\n",
    "        if c['text']:\n",
    "            c['text'] = re.sub('<br\\s*/?>', '', c['text'])\n",
    "        if c['pros']:\n",
    "            c['pros'] = re.sub('<br\\s*/?>', '', c['pros'])\n",
    "        if c['cons']:\n",
    "            c['cons'] = re.sub('<br\\s*/?>', '', c['cons'])\n",
    "\n",
    "sanitize_comments(all_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import cld2\n",
    "def is_ukrainian(text):\n",
    "    is_reliable, _, details = cld2.detect(text)\n",
    "    return is_reliable and details[0][0] == 'UKRAINIAN'\n",
    "\n",
    "print(is_ukrainian('я люблю котів'))\n",
    "print(is_ukrainian('я люблю котов'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nullify_non_ukrainian(comments):\n",
    "    for c in comments:\n",
    "        if not is_ukrainian(c['text']):\n",
    "            c['text'] = None\n",
    "        if not is_ukrainian(c['pros']):\n",
    "            c['pros'] = None\n",
    "        if not is_ukrainian(c['cons']):\n",
    "            c['cons'] = None\n",
    "\n",
    "nullify_non_ukrainian(all_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-10 00:43:27 INFO: Loading these models for language: uk (Ukrainian):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | iu      |\n",
      "| mwt       | iu      |\n",
      "| pos       | iu      |\n",
      "| lemma     | iu      |\n",
      "| depparse  | iu      |\n",
      "=======================\n",
      "\n",
      "2020-04-10 00:43:27 INFO: Use device: cpu\n",
      "2020-04-10 00:43:27 INFO: Loading: tokenize\n",
      "2020-04-10 00:43:27 INFO: Loading: mwt\n",
      "2020-04-10 00:43:27 INFO: Loading: pos\n",
      "2020-04-10 00:43:28 INFO: Loading: lemma\n",
      "2020-04-10 00:43:28 INFO: Loading: depparse\n",
      "2020-04-10 00:43:29 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "nlp = stanza.Pipeline(lang='uk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enrich_comments(comments):\n",
    "    for c in comments:\n",
    "        if c['text']:\n",
    "            c['text_model'] = nlp(c['text'])\n",
    "        else:\n",
    "            c['text_model'] = None\n",
    "            c['text'] = None\n",
    "        \n",
    "        if c['pros']:\n",
    "            c['pros_model'] = nlp(c['pros'])\n",
    "        else:\n",
    "            c['pros_model'] = None\n",
    "            c['pros'] = None\n",
    "\n",
    "        if c['cons']:\n",
    "            c['cons_model'] = nlp(c['cons'])\n",
    "        else:\n",
    "            c['cons_model'] = None\n",
    "            c['cons'] = None\n",
    "\n",
    "enrich_comments(all_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "cons_stop_regexps = [\n",
    "    re.compile('відсутні'),\n",
    "    re.compile('ніяких'),\n",
    "    re.compile('\\w*вияв\\w+'), # невиявлені\n",
    "    re.compile('нема\\w?'), # нема, немає\n",
    "    re.compile('\\w*знай[шд]\\w+'), # незнайшов, незнайдені\n",
    "    re.compile('\\w*бачи[вл]\\w*'), # непобачив, небачив\n",
    "    re.compile('\\w*поміти[вл]\\w*'),\n",
    "    re.compile('недолік\\w*'),\n",
    "    re.compile('невідом[іо]')\n",
    "]\n",
    "\n",
    "def is_relevant_pros_cons(model):\n",
    "    words = [w for sent in model.sentences for w in sent.words]\n",
    "    has_adj_adv = False\n",
    "    for sent in model.sentences:\n",
    "        for w in sent.words:\n",
    "            if w.upos in ['ADJ', 'ADV']:\n",
    "                has_adj_adv = True\n",
    "            if any([re.match(r, w.text) for r in cons_stop_regexps]):\n",
    "                return False\n",
    "            if w.text in ['має', \"знаю\"] and not w.id == '1' and sent.words[int(w.id) - 2] == 'не':\n",
    "                return False\n",
    "    return has_adj_adv\n",
    "    \n",
    "print(is_relevant_pros_cons(nlp('-')))\n",
    "print(is_relevant_pros_cons(nlp('невиявлені.')))\n",
    "print(is_relevant_pros_cons(nlp('не виявлені.')))\n",
    "print(is_relevant_pros_cons(nlp('поки що не виявлені.')))\n",
    "print(is_relevant_pros_cons(nlp('Поки що не знайшов.')))\n",
    "print(is_relevant_pros_cons(nlp('Поки не виявлено, стоїть поки на декілька годин відвгрівається після доставки.')))\n",
    "print(is_relevant_pros_cons(nlp('немає')))\n",
    "print(is_relevant_pros_cons(nlp('не має')))\n",
    "print(is_relevant_pros_cons(nlp('Поки не побачив')))\n",
    "print(is_relevant_pros_cons(nlp('пульт, ціна')))\n",
    "print(is_relevant_pros_cons(nlp('недоліки не виявлені.')))\n",
    "print(is_relevant_pros_cons(nlp('погано працює.')))\n",
    "print(is_relevant_pros_cons(nlp('поганий пульт.')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def has_question(doc):\n",
    "    for sent in doc.sentences:\n",
    "        for word in sent.words:\n",
    "            if word.lemma == '?':\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "has_question(nlp('який виробник?'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mark_to_sentiment(mark):\n",
    "    if mark <= 2:\n",
    "        return 'negative'\n",
    "    if mark == 3:\n",
    "        return 'neutral'\n",
    "    if mark >= 4:\n",
    "        return 'positive'\n",
    "\n",
    "def prepare_dataset(comments):\n",
    "    seen = set()\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    for c in comments:\n",
    "        # filter obvious junk\n",
    "        if c['pros'] and c['cons'] and c['pros'] == c['cons']:\n",
    "            continue\n",
    "        \n",
    "        if (c['text_model'] and \n",
    "                # filter potential duplicates\n",
    "                not c['text'] in seen and\n",
    "            \n",
    "                # filter comments with 3 stars.\n",
    "                # in most cases, 3-stars comments are clearly positive \n",
    "                # or clearly negative, but not neutral. we will drop \n",
    "                # them just not to confuse a classifier.\n",
    "                c['mark'] and (not c['mark'] == 3) and \n",
    "            \n",
    "                # if comment contains question - drop it right away\n",
    "                (not has_question(c['text_model']))):\n",
    "            seen.add(c['text'])\n",
    "            X.append(c['text_model'])\n",
    "            y.append(mark_to_sentiment(c['mark']))\n",
    "            \n",
    "        if (c['pros_model'] and \n",
    "                not c['pros'] in seen and\n",
    "                is_relevant_pros_cons(c['pros_model']) and \n",
    "                (not has_question(c['pros_model']))):\n",
    "            seen.add(c['pros'])\n",
    "            X.append(c['pros_model'])\n",
    "            y.append('positive')\n",
    "            \n",
    "        if (c['cons_model'] and \n",
    "                not c['cons'] in seen and\n",
    "                is_relevant_pros_cons(c['cons_model']) and\n",
    "                (not has_question(c['cons_model']))):\n",
    "            seen.add(c['cons'])\n",
    "            X.append(c['cons_model'])\n",
    "            y.append('negative')\n",
    "            \n",
    "    return (X, y)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7449"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = prepare_dataset(all_comments)\n",
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'positive': 4272, 'negative': 1314})\n",
      "Counter({'positive': 1408, 'negative': 455})\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import collections\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "print(collections.Counter(y_train))\n",
    "print(collections.Counter(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "def make_classifier(params, vect=None):\n",
    "    if vect == None:\n",
    "        vect = CountVectorizer()\n",
    "    classifier = Pipeline([('vect', vect),\n",
    "                           ('nb', MultinomialNB())])\n",
    "    final_params = {'nb__alpha': 0.001,\n",
    "                    'vect__lowercase': False}\n",
    "    final_params.update(params)\n",
    "    classifier.set_params(**final_params)\n",
    "\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['я', 'люблю', 'котів', '.']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize(doc):\n",
    "    return [w.text.lower() for sent in doc.sentences for w in sent.words]\n",
    "\n",
    "tokenize(nlp('Я люблю котів.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.40      0.52       455\n",
      "    positive       0.83      0.96      0.89      1408\n",
      "\n",
      "    accuracy                           0.82      1863\n",
      "   macro avg       0.79      0.68      0.70      1863\n",
      "weighted avg       0.81      0.82      0.80      1863\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Baseline\n",
    "tok_classifier = make_classifier({'vect__tokenizer': tokenize})\n",
    "tok_classifier.fit(X_train, y_train)\n",
    "print(classification_report(y_test, tok_classifier.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import make_scorer, recall_score, f1_score, precision_score\n",
    "\n",
    "cv_scoring = {'recall_pos': make_scorer(recall_score, average = None, labels = ['positive']), \n",
    "              'recall_neg': make_scorer(recall_score, average = None, labels = ['negative']),\n",
    "              'precision_pos': make_scorer(precision_score, average = None, labels = ['positive']),\n",
    "              'precision_neg': make_scorer(precision_score, average = None, labels = ['negative']),\n",
    "              'f1_pos': make_scorer(f1_score, average = None, labels = ['positive']),\n",
    "              'f1_neg': make_scorer(f1_score, average = None, labels = ['negative'])\n",
    "             }\n",
    "\n",
    "def cross_validation_report(clf, X=X_train, y=y_train):\n",
    "    results = cross_validate(clf, X_train, y_train, scoring=cv_scoring)\n",
    "    \n",
    "    def calc(arr):\n",
    "        mean = arr.mean()\n",
    "        dev= arr.std() * 2\n",
    "        \n",
    "        return \"%0.2f (+/- %0.2f)\" % (mean, dev)\n",
    "    \n",
    "    print(\"positive\")\n",
    "    print(\"\\tprecision:\\t{}\".format(calc(results['test_precision_pos'])))\n",
    "    print(\"\\trecall:\\t\\t{}\".format(calc(results['test_recall_pos'])))\n",
    "    print(\"\\tf1:\\t\\t{}\".format(calc(results['test_f1_pos'])))\n",
    "    print('')\n",
    "    print(\"negative\")\n",
    "    print(\"\\tprecision:\\t{}\".format(calc(results['test_precision_neg'])))\n",
    "    print(\"\\trecall:\\t\\t{}\".format(calc(results['test_recall_neg'])))\n",
    "    print(\"\\tf1:\\t\\t{}\".format(calc(results['test_f1_neg'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['я', 'любити', 'кіт', '!']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lemmatize(doc):\n",
    "    return [w.lemma for sent in doc.sentences for w in sent.words]\n",
    "\n",
    "lemmatize(nlp('Я люблю котів!'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive\n",
      "\tprecision:\t0.85 (+/- 0.01)\n",
      "\trecall:\t\t0.95 (+/- 0.01)\n",
      "\tf1:\t\t0.90 (+/- 0.01)\n",
      "\n",
      "negative\n",
      "\tprecision:\t0.75 (+/- 0.04)\n",
      "\trecall:\t\t0.45 (+/- 0.04)\n",
      "\tf1:\t\t0.56 (+/- 0.04)\n"
     ]
    }
   ],
   "source": [
    "lem_classifier = make_classifier({'vect__tokenizer': lemmatize})\n",
    "cross_validation_report(lem_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['не_рекомендувати',\n",
       " 'цей',\n",
       " 'кіт',\n",
       " '.',\n",
       " 'без_він',\n",
       " 'життя',\n",
       " 'бути',\n",
       " 'набагато',\n",
       " 'краще',\n",
       " '.']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negatives_to_glue = [\n",
    "    'без',\n",
    "    'не',\n",
    "    'ні',\n",
    "    'ані'\n",
    "]\n",
    "\n",
    "def lemmatize_and_glue_negatives(doc):\n",
    "    glued = []\n",
    "    \n",
    "    for sent in doc.sentences:\n",
    "        i = 0\n",
    "        words = sent.words\n",
    "        while i < len(words):\n",
    "            if ((words[i].lemma in negatives_to_glue) and\n",
    "                    not i == len(words) - 1 and\n",
    "                    not words[i + 1].upos == 'PUNCT'):\n",
    "                new_word = words[i].lemma + '_' + words[i + 1].lemma\n",
    "                glued.append(new_word)\n",
    "                i += 1\n",
    "            else:\n",
    "                glued.append(words[i].lemma)\n",
    "            i += 1\n",
    "\n",
    "    return glued\n",
    "\n",
    "lemmatize_and_glue_negatives(nlp('не рекомендую цього кота. без нього життя було набагато краще.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive\n",
      "\tprecision:\t0.86 (+/- 0.00)\n",
      "\trecall:\t\t0.96 (+/- 0.01)\n",
      "\tf1:\t\t0.91 (+/- 0.00)\n",
      "\n",
      "negative\n",
      "\tprecision:\t0.79 (+/- 0.03)\n",
      "\trecall:\t\t0.49 (+/- 0.01)\n",
      "\tf1:\t\t0.61 (+/- 0.01)\n"
     ]
    }
   ],
   "source": [
    "gluing_classifier = make_classifier({'vect__tokenizer': lemmatize_and_glue_negatives})\n",
    "cross_validation_report(gluing_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CountVectorizerOov:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.vectorizer = CountVectorizer(token_pattern=None)\n",
    "        self.set_params(**kwargs)\n",
    "        \n",
    "    def set_params(self, **kwargs):\n",
    "        self.tokenizer = kwargs.get('tokenizer')\n",
    "        kwargs.update({'tokenizer': lambda x: x})\n",
    "        self.vectorizer.set_params(**kwargs)\n",
    "        return self\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        X_tokenized = [self.tokenizer(x) for x in X]\n",
    "        self.vectorizer.fit(X_tokenized)\n",
    "        self.vectorizer.vocabulary_['<<<OOV>>>'] = len(self.vectorizer.vocabulary_)\n",
    "        \n",
    "    def fit_transform(self, X, y=None):\n",
    "        X_tokenized = [self.tokenizer(x) for x in X]\n",
    "        self.vectorizer.fit(X_tokenized)\n",
    "        self.vectorizer.vocabulary_['<<<OOV>>>'] = len(self.vectorizer.vocabulary_)\n",
    "        return self.vectorizer.transform(X_tokenized)\n",
    "    \n",
    "    def get_feature_names(self):\n",
    "        return self.vectorizer.get_feature_names()\n",
    "    \n",
    "    def transform(self, X):\n",
    "        feats = set(self.vectorizer.get_feature_names())\n",
    "        \n",
    "        new_X = []\n",
    "        for x in X:\n",
    "            new_x = []\n",
    "            for tok in self.tokenizer(x):\n",
    "                if not tok in feats:\n",
    "                    new_x.append('<<<OOV>>>')\n",
    "                else:\n",
    "                    new_x.append(tok)\n",
    "            new_X.append(new_x)\n",
    "        \n",
    "        return self.vectorizer.transform(new_X)           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 0]]\n",
      "['кіт', 'любити', 'я', '<<<OOV>>>']\n",
      "[[0 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "vect_oov = CountVectorizerOov(tokenizer=lemmatize, lowercase=False)\n",
    "print(vect_oov.fit_transform([nlp('я люблю котів')]).toarray())\n",
    "print(vect_oov.get_feature_names())\n",
    "print(vect_oov.transform([nlp('я люблю мишей')]).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive\n",
      "\tprecision:\t0.88 (+/- 0.01)\n",
      "\trecall:\t\t0.94 (+/- 0.01)\n",
      "\tf1:\t\t0.91 (+/- 0.00)\n",
      "\n",
      "negative\n",
      "\tprecision:\t0.75 (+/- 0.02)\n",
      "\trecall:\t\t0.59 (+/- 0.04)\n",
      "\tf1:\t\t0.66 (+/- 0.02)\n"
     ]
    }
   ],
   "source": [
    "gluing_classifier_oov = make_classifier({'vect__tokenizer': lemmatize_and_glue_negatives}, vect=CountVectorizerOov())\n",
    "cross_validation_report(gluing_classifier_oov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive\n",
      "\tprecision:\t0.94 (+/- 0.01)\n",
      "\trecall:\t\t0.90 (+/- 0.03)\n",
      "\tf1:\t\t0.92 (+/- 0.01)\n",
      "\n",
      "negative\n",
      "\tprecision:\t0.72 (+/- 0.05)\n",
      "\trecall:\t\t0.80 (+/- 0.05)\n",
      "\tf1:\t\t0.76 (+/- 0.03)\n"
     ]
    }
   ],
   "source": [
    "gluing_classifier_oov_tuned = make_classifier({'vect__tokenizer': lemmatize_and_glue_negatives, \n",
    "                                               'nb__alpha': 0.5, \n",
    "                                               'nb__fit_prior': False,\n",
    "                                               }, \n",
    "                                              vect=CountVectorizerOov())\n",
    "cross_validation_report(gluing_classifier_oov_tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.79      0.75       455\n",
      "    positive       0.93      0.90      0.91      1408\n",
      "\n",
      "    accuracy                           0.87      1863\n",
      "   macro avg       0.82      0.84      0.83      1863\n",
      "weighted avg       0.88      0.87      0.87      1863\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gluing_classifier_oov_tuned.fit(X_train, y_train)\n",
    "print(classification_report(y_test, gluing_classifier_oov_tuned.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things that I also tried:\n",
    "* bigrams - better precision, but much lower recall - f1 score is worse;\n",
    "* tonal dict:\n",
    "  * appending tone markers to the tokenized sentence, so sentence like this \"мені подобається бити котів\" will be tokenized into \"я подобатися бити кіт <<positive\\>\\> <<very negative\\>\\>\", because \"подобається\" and \"бити\" have tone score 1 and -2 respectively. result - no improvement, f1 score remained the same.\n",
    "  * replacing words with their tone markers: \"мені подобається бити котів\" will be tokenized into \"я <<positive\\>\\> <<very negative\\>\\> кіт\". result - worse precision and recall."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
