{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    },
    "colab": {
      "name": "seq2seq_chars-n.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OHVq8QdIXfN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnwSK2EmIXfU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense\n",
        "\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leoUDDBxIXfY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 64  # Batch size for training.\n",
        "epochs = 100  # Number of epochs to train for.\n",
        "latent_dim = 256  # Latent dimensionality of the encoding space.\n",
        "num_samples = 25000  # Number of samples to train on.\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_mw74NAIXfc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_data(filename, is_train=True, score_filter=3, limit=None):\n",
        "    usecols = [1, 2, 5] if is_train else [1, 2, 3]\n",
        "    \n",
        "    df = pd.read_csv(filename, sep='\\t', usecols=usecols, names=['source', 'target', 'score'])[:limit]\n",
        "    df = df[df['score'] >= score_filter]\n",
        "    \n",
        "    source = df['source']\n",
        "    target = df['target']\n",
        "    \n",
        "    source = '\\t ' + source + '\\n'\n",
        "    target = '\\t ' + target + '\\n'\n",
        "    \n",
        "    source_chars = {char for string in source.values for char in string}\n",
        "    target_chars = {char for string in target.values for char in string}\n",
        "    \n",
        "    return source.values, target.values, source_chars, target_chars"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RE_XuqqnIXfe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_input_texts, train_target_texts, train_input_chars, train_target_chars = prepare_data('en-train-100K.txt', limit=num_samples)\n",
        "# dev_input_texts, dev_target_texts, dev_input_chars, dev_target_chars = prepare_data('en-dev.txt', False)\n",
        "# test_input_texts, test_targset_texts, test_input_chars, test_target_chars = prepare_data('en-test.txt', False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPejT307IXfh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "dcb8f110-a42d-4080-e418-dae4ed165b12"
      },
      "source": [
        "print(train_input_chars)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'ó', 'g', '♪', '7', ' ', '|', 'Z', ')', '/', 'm', '\\u200b', 'Q', '$', '(', 'j', '0', 'ο', 'é', '6', 'S', 'c', 'f', 's', 'u', ':', '3', 'í', 'W', 'p', 'e', 'ï', 'v', 'V', '8', 'J', 'C', 'h', 'x', '9', ',', 'X', 'B', 'l', 'F', 'i', 'z', '\\x9d', '!', 'G', 'O', \"'\", 'á', 'K', '@', 'M', 'd', '\"', 'I', 'Y', 'H', '?', 'T', '1', 'N', 'ν', 'a', 'L', '5', 'R', 'o', 'n', 'P', 'U', '4', 'b', '%', '-', '2', 'E', 'r', '\\n', 'y', '.', '\\t', 't', 'w', 'k', 'D', 'A', 'q'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bq3x6ynIXfo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "fa496a3e-9438-4eed-db0f-1389639e8384"
      },
      "source": [
        "train_input_texts[:4]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['\\t Jumby now wants to be born .\\n',\n",
              "       '\\t It was a difficult and long delivery .\\n',\n",
              "       '\\t I like to be beautiful everyday .\\n',\n",
              "       '\\t Bernadette wants a prenup .\\n'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAlXAKI1IXfw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "cbcaf0ad-1887-45f2-abb5-99544a912183"
      },
      "source": [
        "train_target_texts[:4]"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['\\t Jumby want birth .\\n',\n",
              "       '\\t The delivery was difficult and long .\\n',\n",
              "       '\\t I like to be pretty everyday .\\n',\n",
              "       '\\t Bernadette wants to get a prenup .\\n'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVqmTr9IIXfz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "fdcae8e2-01e7-4738-ca51-b6859f595aa4"
      },
      "source": [
        "input_characters = sorted(list(train_input_chars))\n",
        "target_characters = sorted(list(train_target_chars))\n",
        "num_encoder_tokens = len(train_input_chars) + 1\n",
        "num_decoder_tokens = len(train_target_chars) + 1\n",
        "max_encoder_seq_length = max([len(txt) for txt in train_input_texts])\n",
        "max_decoder_seq_length = max([len(txt) for txt in train_target_texts])\n",
        "\n",
        "print('Number of samples:', len(train_input_texts))\n",
        "print('Number of unique input tokens:', num_encoder_tokens)\n",
        "print('Number of unique output tokens:', num_decoder_tokens)\n",
        "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
        "print('Max sequence length for outputs:', max_decoder_seq_length)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of samples: 25000\n",
            "Number of unique input tokens: 91\n",
            "Number of unique output tokens: 112\n",
            "Max sequence length for inputs: 212\n",
            "Max sequence length for outputs: 127\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wk4UX0ipIXf2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_enc_dec(input_texts, target_texts, input_characters, target_characters):\n",
        "    input_token_index = dict(\n",
        "        [(char, i) for i, char in enumerate(input_characters)])\n",
        "    target_token_index = dict(\n",
        "        [(char, i) for i, char in enumerate(target_characters)])\n",
        "\n",
        "    encoder_input_data = np.zeros(\n",
        "        (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
        "        dtype='float32')\n",
        "    decoder_input_data = np.zeros(\n",
        "        (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
        "        dtype='float32')\n",
        "    decoder_target_data = np.zeros(\n",
        "        (len(target_texts), max_decoder_seq_length, num_decoder_tokens),\n",
        "        dtype='float32')\n",
        "\n",
        "    for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
        "        for t, char in enumerate(input_text):\n",
        "            encoder_input_data[i, t, input_token_index[char]] = 1.\n",
        "        encoder_input_data[i, t + 1:, input_token_index['\\n']] = 1.\n",
        "        for t, char in enumerate(target_text):\n",
        "            decoder_input_data[i, t, target_token_index[char]] = 1.\n",
        "            if t > 0:\n",
        "                decoder_target_data[i, t - 1, target_token_index[char]] = 1.\n",
        "        decoder_input_data[i, t + 1:, target_token_index['\\n']] = 1.\n",
        "        decoder_target_data[i, t:, target_token_index['\\n']] = 1.\n",
        "    return input_token_index, target_token_index, encoder_input_data, decoder_input_data, decoder_target_data\n",
        "\n",
        "\n",
        "input_token_index, target_token_index, encoder_input_data, decoder_input_data, decoder_target_data = prepare_enc_dec(train_input_texts, train_target_texts, input_characters, target_characters)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JM6YUBY6IXf5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate = 0.005"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMCofTmbIXf8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def scheduler(epoch, lr):\n",
        "    if epoch:\n",
        "        if epoch % 10 == 0:\n",
        "            return learning_rate / 2\n",
        "        return lr*0.8\n",
        "    return lr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dBreuyzIXf_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "171f03c9-7a3d-403c-e89d-d145570f1910"
      },
      "source": [
        "# Define an input sequence and process it.\n",
        "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
        "# encoder = LSTM(latent_dim, return_state=True, dropout=0.4, recurrent_dropout=0.4)\n",
        "encoder = LSTM(latent_dim, return_state=True, dropout=0.3)\n",
        "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
        "# We discard `encoder_outputs` and only keep the states.\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
        "# We set up our decoder to return full output sequences,\n",
        "# and to return internal states as well. We don't use the\n",
        "# return states in the training model, but we will use them in inference.\n",
        "# decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.4)\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True, dropout=0.3)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
        "                                     initial_state=encoder_states)\n",
        "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Define the model that will turn\n",
        "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "opt = keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
        "\n",
        "\n",
        "# Run training\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "model.fit(\n",
        "    [encoder_input_data, decoder_input_data], \n",
        "    decoder_target_data,\n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[\n",
        "        keras.callbacks.LearningRateScheduler(scheduler, verbose=1),\n",
        "        keras.callbacks.EarlyStopping(\n",
        "          monitor='val_loss',\n",
        "          min_delta=0,\n",
        "          patience=5,\n",
        "          verbose=1,\n",
        "          mode='auto',\n",
        "        )\n",
        "    ],\n",
        ")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00001: LearningRateScheduler reducing learning rate to 0.004999999888241291.\n",
            "Epoch 1/100\n",
            "313/313 [==============================] - 14s 45ms/step - loss: 0.4575 - accuracy: 0.8786 - val_loss: 0.2852 - val_accuracy: 0.9186 - lr: 0.0050\n",
            "\n",
            "Epoch 00002: LearningRateScheduler reducing learning rate to 0.003999999910593033.\n",
            "Epoch 2/100\n",
            "313/313 [==============================] - 13s 41ms/step - loss: 0.3147 - accuracy: 0.9081 - val_loss: 0.2423 - val_accuracy: 0.9298 - lr: 0.0040\n",
            "\n",
            "Epoch 00003: LearningRateScheduler reducing learning rate to 0.0031999997794628144.\n",
            "Epoch 3/100\n",
            "313/313 [==============================] - 13s 41ms/step - loss: 0.2875 - accuracy: 0.9154 - val_loss: 0.2203 - val_accuracy: 0.9360 - lr: 0.0032\n",
            "\n",
            "Epoch 00004: LearningRateScheduler reducing learning rate to 0.0025599997490644458.\n",
            "Epoch 4/100\n",
            "313/313 [==============================] - 13s 41ms/step - loss: 0.2744 - accuracy: 0.9190 - val_loss: 0.2081 - val_accuracy: 0.9390 - lr: 0.0026\n",
            "\n",
            "Epoch 00005: LearningRateScheduler reducing learning rate to 0.0020479997619986534.\n",
            "Epoch 5/100\n",
            "313/313 [==============================] - 13s 41ms/step - loss: 0.2614 - accuracy: 0.9224 - val_loss: 0.1999 - val_accuracy: 0.9413 - lr: 0.0020\n",
            "\n",
            "Epoch 00006: LearningRateScheduler reducing learning rate to 0.0016383998095989229.\n",
            "Epoch 6/100\n",
            "313/313 [==============================] - 13s 41ms/step - loss: 0.2509 - accuracy: 0.9260 - val_loss: 0.1912 - val_accuracy: 0.9443 - lr: 0.0016\n",
            "\n",
            "Epoch 00007: LearningRateScheduler reducing learning rate to 0.0013107198290526869.\n",
            "Epoch 7/100\n",
            "313/313 [==============================] - 13s 41ms/step - loss: 0.2432 - accuracy: 0.9283 - val_loss: 0.1861 - val_accuracy: 0.9461 - lr: 0.0013\n",
            "\n",
            "Epoch 00008: LearningRateScheduler reducing learning rate to 0.0010485759004950524.\n",
            "Epoch 8/100\n",
            "313/313 [==============================] - 13s 41ms/step - loss: 0.2366 - accuracy: 0.9304 - val_loss: 0.1829 - val_accuracy: 0.9472 - lr: 0.0010\n",
            "\n",
            "Epoch 00009: LearningRateScheduler reducing learning rate to 0.0008388606831431389.\n",
            "Epoch 9/100\n",
            "313/313 [==============================] - 13s 41ms/step - loss: 0.2324 - accuracy: 0.9315 - val_loss: 0.1805 - val_accuracy: 0.9476 - lr: 8.3886e-04\n",
            "\n",
            "Epoch 00010: LearningRateScheduler reducing learning rate to 0.0006710885558277369.\n",
            "Epoch 10/100\n",
            "313/313 [==============================] - 13s 41ms/step - loss: 0.2296 - accuracy: 0.9324 - val_loss: 0.1780 - val_accuracy: 0.9484 - lr: 6.7109e-04\n",
            "\n",
            "Epoch 00011: LearningRateScheduler reducing learning rate to 0.0025.\n",
            "Epoch 11/100\n",
            "313/313 [==============================] - 13s 41ms/step - loss: 0.2341 - accuracy: 0.9310 - val_loss: 0.1795 - val_accuracy: 0.9477 - lr: 0.0025\n",
            "\n",
            "Epoch 00012: LearningRateScheduler reducing learning rate to 0.0019999999552965165.\n",
            "Epoch 12/100\n",
            "313/313 [==============================] - 13s 41ms/step - loss: 0.2273 - accuracy: 0.9331 - val_loss: 0.1746 - val_accuracy: 0.9493 - lr: 0.0020\n",
            "\n",
            "Epoch 00013: LearningRateScheduler reducing learning rate to 0.0015999998897314072.\n",
            "Epoch 13/100\n",
            "313/313 [==============================] - 13s 41ms/step - loss: 0.2213 - accuracy: 0.9348 - val_loss: 0.1711 - val_accuracy: 0.9501 - lr: 0.0016\n",
            "\n",
            "Epoch 00014: LearningRateScheduler reducing learning rate to 0.0012799998745322229.\n",
            "Epoch 14/100\n",
            "313/313 [==============================] - 13s 41ms/step - loss: 0.2169 - accuracy: 0.9361 - val_loss: 0.1684 - val_accuracy: 0.9511 - lr: 0.0013\n",
            "\n",
            "Epoch 00015: LearningRateScheduler reducing learning rate to 0.0010239998809993267.\n",
            "Epoch 15/100\n",
            "313/313 [==============================] - 13s 41ms/step - loss: 0.2133 - accuracy: 0.9372 - val_loss: 0.1655 - val_accuracy: 0.9518 - lr: 0.0010\n",
            "\n",
            "Epoch 00016: LearningRateScheduler reducing learning rate to 0.0008191999047994614.\n",
            "Epoch 16/100\n",
            "313/313 [==============================] - 13s 41ms/step - loss: 0.2103 - accuracy: 0.9380 - val_loss: 0.1647 - val_accuracy: 0.9522 - lr: 8.1920e-04\n",
            "\n",
            "Epoch 00017: LearningRateScheduler reducing learning rate to 0.0006553599145263434.\n",
            "Epoch 17/100\n",
            "313/313 [==============================] - 13s 41ms/step - loss: 0.2079 - accuracy: 0.9386 - val_loss: 0.1627 - val_accuracy: 0.9528 - lr: 6.5536e-04\n",
            "\n",
            "Epoch 00018: LearningRateScheduler reducing learning rate to 0.0005242879502475262.\n",
            "Epoch 18/100\n",
            "313/313 [==============================] - 13s 41ms/step - loss: 0.2061 - accuracy: 0.9392 - val_loss: 0.1619 - val_accuracy: 0.9531 - lr: 5.2429e-04\n",
            "\n",
            "Epoch 00019: LearningRateScheduler reducing learning rate to 0.00041943034157156946.\n",
            "Epoch 19/100\n",
            "313/313 [==============================] - 13s 41ms/step - loss: 0.2039 - accuracy: 0.9398 - val_loss: 0.1607 - val_accuracy: 0.9536 - lr: 4.1943e-04\n",
            "\n",
            "Epoch 00020: LearningRateScheduler reducing learning rate to 0.00033554427791386847.\n",
            "Epoch 20/100\n",
            "313/313 [==============================] - 13s 41ms/step - loss: 0.2029 - accuracy: 0.9402 - val_loss: 0.1601 - val_accuracy: 0.9536 - lr: 3.3554e-04\n",
            "\n",
            "Epoch 00021: LearningRateScheduler reducing learning rate to 0.0025.\n",
            "Epoch 21/100\n",
            "313/313 [==============================] - 13s 41ms/step - loss: 0.2124 - accuracy: 0.9372 - val_loss: 0.1655 - val_accuracy: 0.9521 - lr: 0.0025\n",
            "\n",
            "Epoch 00022: LearningRateScheduler reducing learning rate to 0.0019999999552965165.\n",
            "Epoch 22/100\n",
            "313/313 [==============================] - 13s 41ms/step - loss: 0.2076 - accuracy: 0.9387 - val_loss: 0.1621 - val_accuracy: 0.9531 - lr: 0.0020\n",
            "\n",
            "Epoch 00023: LearningRateScheduler reducing learning rate to 0.0015999998897314072.\n",
            "Epoch 23/100\n",
            "313/313 [==============================] - 13s 41ms/step - loss: 0.2031 - accuracy: 0.9401 - val_loss: 0.1583 - val_accuracy: 0.9543 - lr: 0.0016\n",
            "\n",
            "Epoch 00024: LearningRateScheduler reducing learning rate to 0.0012799998745322229.\n",
            "Epoch 24/100\n",
            "313/313 [==============================] - 13s 41ms/step - loss: 0.1997 - accuracy: 0.9410 - val_loss: 0.1569 - val_accuracy: 0.9548 - lr: 0.0013\n",
            "\n",
            "Epoch 00025: LearningRateScheduler reducing learning rate to 0.0010239998809993267.\n",
            "Epoch 25/100\n",
            "313/313 [==============================] - 13s 41ms/step - loss: 0.1966 - accuracy: 0.9419 - val_loss: 0.1554 - val_accuracy: 0.9551 - lr: 0.0010\n",
            "\n",
            "Epoch 00026: LearningRateScheduler reducing learning rate to 0.0008191999047994614.\n",
            "Epoch 26/100\n",
            "313/313 [==============================] - 13s 41ms/step - loss: 0.1944 - accuracy: 0.9425 - val_loss: 0.1545 - val_accuracy: 0.9554 - lr: 8.1920e-04\n",
            "\n",
            "Epoch 00027: LearningRateScheduler reducing learning rate to 0.0006553599145263434.\n",
            "Epoch 27/100\n",
            "313/313 [==============================] - 13s 41ms/step - loss: 0.1926 - accuracy: 0.9431 - val_loss: 0.1540 - val_accuracy: 0.9553 - lr: 6.5536e-04\n",
            "\n",
            "Epoch 00028: LearningRateScheduler reducing learning rate to 0.0005242879502475262.\n",
            "Epoch 28/100\n",
            "313/313 [==============================] - 13s 41ms/step - loss: 0.1911 - accuracy: 0.9435 - val_loss: 0.1527 - val_accuracy: 0.9560 - lr: 5.2429e-04\n",
            "\n",
            "Epoch 00029: LearningRateScheduler reducing learning rate to 0.00041943034157156946.\n",
            "Epoch 29/100\n",
            "313/313 [==============================] - 13s 41ms/step - loss: 0.1889 - accuracy: 0.9441 - val_loss: 0.1523 - val_accuracy: 0.9560 - lr: 4.1943e-04\n",
            "\n",
            "Epoch 00030: LearningRateScheduler reducing learning rate to 0.00033554427791386847.\n",
            "Epoch 30/100\n",
            "313/313 [==============================] - 13s 41ms/step - loss: 0.1879 - accuracy: 0.9443 - val_loss: 0.1518 - val_accuracy: 0.9561 - lr: 3.3554e-04\n",
            "\n",
            "Epoch 00031: LearningRateScheduler reducing learning rate to 0.0025.\n",
            "Epoch 31/100\n",
            "313/313 [==============================] - 13s 41ms/step - loss: 0.1984 - accuracy: 0.9413 - val_loss: 0.1573 - val_accuracy: 0.9542 - lr: 0.0025\n",
            "\n",
            "Epoch 00032: LearningRateScheduler reducing learning rate to 0.0019999999552965165.\n",
            "Epoch 32/100\n",
            "313/313 [==============================] - 13s 41ms/step - loss: 0.1956 - accuracy: 0.9422 - val_loss: 0.1545 - val_accuracy: 0.9553 - lr: 0.0020\n",
            "\n",
            "Epoch 00033: LearningRateScheduler reducing learning rate to 0.0015999998897314072.\n",
            "Epoch 33/100\n",
            "313/313 [==============================] - 13s 41ms/step - loss: 0.1914 - accuracy: 0.9433 - val_loss: 0.1533 - val_accuracy: 0.9557 - lr: 0.0016\n",
            "\n",
            "Epoch 00034: LearningRateScheduler reducing learning rate to 0.0012799998745322229.\n",
            "Epoch 34/100\n",
            "313/313 [==============================] - 13s 41ms/step - loss: 0.1881 - accuracy: 0.9442 - val_loss: 0.1514 - val_accuracy: 0.9562 - lr: 0.0013\n",
            "\n",
            "Epoch 00035: LearningRateScheduler reducing learning rate to 0.0010239998809993267.\n",
            "Epoch 35/100\n",
            "313/313 [==============================] - 13s 41ms/step - loss: 0.1852 - accuracy: 0.9450 - val_loss: 0.1501 - val_accuracy: 0.9567 - lr: 0.0010\n",
            "\n",
            "Epoch 00036: LearningRateScheduler reducing learning rate to 0.0008191999047994614.\n",
            "Epoch 36/100\n",
            "313/313 [==============================] - 13s 41ms/step - loss: 0.1829 - accuracy: 0.9459 - val_loss: 0.1481 - val_accuracy: 0.9573 - lr: 8.1920e-04\n",
            "\n",
            "Epoch 00037: LearningRateScheduler reducing learning rate to 0.0006553599145263434.\n",
            "Epoch 37/100\n",
            "313/313 [==============================] - 13s 41ms/step - loss: 0.1816 - accuracy: 0.9462 - val_loss: 0.1476 - val_accuracy: 0.9574 - lr: 6.5536e-04\n",
            "\n",
            "Epoch 00038: LearningRateScheduler reducing learning rate to 0.0005242879502475262.\n",
            "Epoch 38/100\n",
            "313/313 [==============================] - 13s 41ms/step - loss: 0.1799 - accuracy: 0.9466 - val_loss: 0.1472 - val_accuracy: 0.9577 - lr: 5.2429e-04\n",
            "\n",
            "Epoch 00039: LearningRateScheduler reducing learning rate to 0.00041943034157156946.\n",
            "Epoch 39/100\n",
            "313/313 [==============================] - 13s 41ms/step - loss: 0.1785 - accuracy: 0.9471 - val_loss: 0.1465 - val_accuracy: 0.9575 - lr: 4.1943e-04\n",
            "\n",
            "Epoch 00040: LearningRateScheduler reducing learning rate to 0.00033554427791386847.\n",
            "Epoch 40/100\n",
            "313/313 [==============================] - 13s 41ms/step - loss: 0.1779 - accuracy: 0.9473 - val_loss: 0.1463 - val_accuracy: 0.9578 - lr: 3.3554e-04\n",
            "\n",
            "Epoch 00041: LearningRateScheduler reducing learning rate to 0.0025.\n",
            "Epoch 41/100\n",
            "313/313 [==============================] - 13s 41ms/step - loss: 0.1889 - accuracy: 0.9440 - val_loss: 0.1517 - val_accuracy: 0.9562 - lr: 0.0025\n",
            "\n",
            "Epoch 00042: LearningRateScheduler reducing learning rate to 0.0019999999552965165.\n",
            "Epoch 42/100\n",
            "313/313 [==============================] - 13s 41ms/step - loss: 0.1861 - accuracy: 0.9448 - val_loss: 0.1493 - val_accuracy: 0.9567 - lr: 0.0020\n",
            "\n",
            "Epoch 00043: LearningRateScheduler reducing learning rate to 0.0015999998897314072.\n",
            "Epoch 43/100\n",
            "313/313 [==============================] - 13s 41ms/step - loss: 0.1825 - accuracy: 0.9458 - val_loss: 0.1485 - val_accuracy: 0.9571 - lr: 0.0016\n",
            "\n",
            "Epoch 00044: LearningRateScheduler reducing learning rate to 0.0012799998745322229.\n",
            "Epoch 44/100\n",
            "313/313 [==============================] - 13s 41ms/step - loss: 0.1788 - accuracy: 0.9470 - val_loss: 0.1475 - val_accuracy: 0.9574 - lr: 0.0013\n",
            "\n",
            "Epoch 00045: LearningRateScheduler reducing learning rate to 0.0010239998809993267.\n",
            "Epoch 45/100\n",
            "313/313 [==============================] - 13s 41ms/step - loss: 0.1766 - accuracy: 0.9476 - val_loss: 0.1457 - val_accuracy: 0.9580 - lr: 0.0010\n",
            "\n",
            "Epoch 00046: LearningRateScheduler reducing learning rate to 0.0008191999047994614.\n",
            "Epoch 46/100\n",
            "313/313 [==============================] - 13s 41ms/step - loss: 0.1748 - accuracy: 0.9481 - val_loss: 0.1446 - val_accuracy: 0.9582 - lr: 8.1920e-04\n",
            "\n",
            "Epoch 00047: LearningRateScheduler reducing learning rate to 0.0006553599145263434.\n",
            "Epoch 47/100\n",
            "313/313 [==============================] - 13s 41ms/step - loss: 0.1733 - accuracy: 0.9485 - val_loss: 0.1442 - val_accuracy: 0.9585 - lr: 6.5536e-04\n",
            "\n",
            "Epoch 00048: LearningRateScheduler reducing learning rate to 0.0005242879502475262.\n",
            "Epoch 48/100\n",
            "313/313 [==============================] - 13s 41ms/step - loss: 0.1711 - accuracy: 0.9492 - val_loss: 0.1436 - val_accuracy: 0.9586 - lr: 5.2429e-04\n",
            "\n",
            "Epoch 00049: LearningRateScheduler reducing learning rate to 0.00041943034157156946.\n",
            "Epoch 49/100\n",
            "313/313 [==============================] - 13s 41ms/step - loss: 0.1705 - accuracy: 0.9493 - val_loss: 0.1433 - val_accuracy: 0.9586 - lr: 4.1943e-04\n",
            "\n",
            "Epoch 00050: LearningRateScheduler reducing learning rate to 0.00033554427791386847.\n",
            "Epoch 50/100\n",
            "313/313 [==============================] - 13s 41ms/step - loss: 0.1698 - accuracy: 0.9495 - val_loss: 0.1431 - val_accuracy: 0.9587 - lr: 3.3554e-04\n",
            "\n",
            "Epoch 00051: LearningRateScheduler reducing learning rate to 0.0025.\n",
            "Epoch 51/100\n",
            "313/313 [==============================] - 13s 41ms/step - loss: 0.1810 - accuracy: 0.9462 - val_loss: 0.1483 - val_accuracy: 0.9574 - lr: 0.0025\n",
            "\n",
            "Epoch 00052: LearningRateScheduler reducing learning rate to 0.0019999999552965165.\n",
            "Epoch 52/100\n",
            "313/313 [==============================] - 13s 41ms/step - loss: 0.1784 - accuracy: 0.9470 - val_loss: 0.1474 - val_accuracy: 0.9574 - lr: 0.0020\n",
            "\n",
            "Epoch 00053: LearningRateScheduler reducing learning rate to 0.0015999998897314072.\n",
            "Epoch 53/100\n",
            "313/313 [==============================] - 13s 41ms/step - loss: 0.1753 - accuracy: 0.9479 - val_loss: 0.1446 - val_accuracy: 0.9585 - lr: 0.0016\n",
            "\n",
            "Epoch 00054: LearningRateScheduler reducing learning rate to 0.0012799998745322229.\n",
            "Epoch 54/100\n",
            "313/313 [==============================] - 13s 41ms/step - loss: 0.1723 - accuracy: 0.9488 - val_loss: 0.1434 - val_accuracy: 0.9588 - lr: 0.0013\n",
            "\n",
            "Epoch 00055: LearningRateScheduler reducing learning rate to 0.0010239998809993267.\n",
            "Epoch 55/100\n",
            "313/313 [==============================] - 13s 41ms/step - loss: 0.1700 - accuracy: 0.9494 - val_loss: 0.1437 - val_accuracy: 0.9587 - lr: 0.0010\n",
            "Epoch 00055: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0de0061c50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEDNQRRNIXgP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# adam, cycle each 10th epoch, starting at 0.001\n",
        "# Epoch 00050: LearningRateScheduler reducing learning rate to 0.0032804996240884065.\n",
        "# Epoch 50/100\n",
        "# 300/300 [==============================] - 13s 44ms/step - loss: 0.1955 - accuracy: 0.9415 - val_loss: 0.1606 - val_accuracy: 0.9533 - lr: 0.0033\n",
        "# Epoch 00050: early stopping\n",
        "\n",
        "# rms, cycle each 10th epoch, starting at 0.001\n",
        "# Epoch 00035: LearningRateScheduler reducing learning rate to 0.0032804996240884065.\n",
        "# Epoch 35/100\n",
        "# 300/300 [==============================] - 13s 44ms/step - loss: 0.1837 - accuracy: 0.9454 - val_loss: 0.1561 - val_accuracy: 0.9552 - lr: 0.0033\n",
        "# Epoch 00035: early stopping\n",
        "\n",
        "# rms, cycle each 10th epoch, starting at 0.005\n",
        "# Epoch 00075: LearningRateScheduler reducing learning rate to 0.0010239998809993267.\n",
        "# Epoch 75/100\n",
        "# 300/300 [==============================] - 13s 45ms/step - loss: 0.1643 - accuracy: 0.9507 - val_loss: 0.1547 - val_accuracy: 0.9565 - lr: 0.0010\n",
        "# Epoch 00075: early stopping\n",
        "\n",
        "# rms, cycle each 15th epoch, starting at 0.005\n",
        "# Epoch 00064: LearningRateScheduler reducing learning rate to 0.0012799998745322229.\n",
        "# Epoch 64/100\n",
        "# 300/300 [==============================] - 12s 40ms/step - loss: 0.1877 - accuracy: 0.9440 - val_loss: 0.1623 - val_accuracy: 0.9533 - lr: 0.0013\n",
        "# Epoch 00064: early stopping\n",
        "\n",
        "# no decay\n",
        "# Epoch 46/100\n",
        "# 300/300 [==============================] - 12s 41ms/step - loss: 0.1739 - accuracy: 0.9479 - val_loss: 0.1529 - val_accuracy: 0.9566\n",
        "# Epoch 00046: early stopping"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DM-DpOwYIXgS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define sampling models\n",
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(\n",
        "    decoder_inputs, initial_state=decoder_states_inputs)\n",
        "decoder_states = [state_h, state_c]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,\n",
        "    [decoder_outputs] + decoder_states)\n",
        "\n",
        "# Reverse-lookup token index to decode sequences back to\n",
        "# something readable.\n",
        "reverse_input_char_index = dict(\n",
        "    (i, char) for char, i in input_token_index.items())\n",
        "reverse_target_char_index = dict(\n",
        "    (i, char) for char, i in target_token_index.items())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eelS_XT4IXgX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "    # Populate the first character of target sequence with the start character.\n",
        "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
        "\n",
        "    # Sampling loop for a batch of sequences\n",
        "    # (to simplify, here we assume a batch of size 1).\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict(\n",
        "            [target_seq] + states_value)\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "        decoded_sentence += sampled_char\n",
        "\n",
        "        # Exit condition: either hit max length\n",
        "        # or find stop character.\n",
        "        if (sampled_char == '\\n' or\n",
        "           len(decoded_sentence) > max_decoder_seq_length):\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "        target_seq[0, 0, sampled_token_index] = 1.\n",
        "\n",
        "        # Update states\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return decoded_sentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqXK5B34IXga",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e0eb59ca-a274-42e6-cbbc-df377f6668be"
      },
      "source": [
        "from rouge import Rouge \n",
        "\n",
        "rouge = Rouge()\n",
        "\n",
        "\n",
        "r1 = []\n",
        "\n",
        "for seq_index in range(100):\n",
        "    # Take one sequence (part of the training set)\n",
        "    # for trying out decoding.\n",
        "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
        "    decoded_sentence = decode_sequence(input_seq)\n",
        "    score = rouge.get_scores(decoded_sentence, train_input_texts[seq_index])[0]\n",
        "    r1.append(score[\"rouge-1\"][\"f\"])\n",
        "    print('-------')\n",
        "    print('Input sentence:', train_input_texts[seq_index])\n",
        "    print('Decoded sentence:', decoded_sentence)\n",
        "    print('Rouge-1:', (score[\"rouge-1\"][\"f\"]))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------\n",
            "Input sentence: \t Jumby now wants to be born .\n",
            "\n",
            "Decoded sentence:  But that 's not going to happen .\n",
            "\n",
            "Rouge-1: 0.266666661688889\n",
            "-------\n",
            "Input sentence: \t It was a difficult and long delivery .\n",
            "\n",
            "Decoded sentence:  It 's not that say .\n",
            "\n",
            "Rouge-1: 0.2857142808163266\n",
            "-------\n",
            "Input sentence: \t I like to be beautiful everyday .\n",
            "\n",
            "Decoded sentence:  I think I 'm gonna go the time .\n",
            "\n",
            "Rouge-1: 0.24999999507812506\n",
            "-------\n",
            "Input sentence: \t Bernadette wants a prenup .\n",
            "\n",
            "Decoded sentence:  I 'm not sure you 're all right .\n",
            "\n",
            "Rouge-1: 0.14285713826530627\n",
            "-------\n",
            "Input sentence: \t Don 't say you don 't remember me .\n",
            "\n",
            "Decoded sentence:  Don 't you forget that .\n",
            "\n",
            "Rouge-1: 0.5333333285333334\n",
            "-------\n",
            "Input sentence: \t Hyah ! Hmm .\n",
            "\n",
            "Decoded sentence:  The tool .\n",
            "\n",
            "Rouge-1: 0.2857142808163266\n",
            "-------\n",
            "Input sentence: \t He believes in you .\n",
            "\n",
            "Decoded sentence:  He 's not going to be okay .\n",
            "\n",
            "Rouge-1: 0.3076923029585799\n",
            "-------\n",
            "Input sentence: \t Sun 's going to come up soon .\n",
            "\n",
            "Decoded sentence:  She 's gonna be all right .\n",
            "\n",
            "Rouge-1: 0.266666661688889\n",
            "-------\n",
            "Input sentence: \t Mars-1 , Houston .\n",
            "\n",
            "Decoded sentence:  Sorry to interrupt .\n",
            "\n",
            "Rouge-1: 0.24999999500000009\n",
            "-------\n",
            "Input sentence: \t But we have no money .\n",
            "\n",
            "Decoded sentence:  But I 'm not gonna die .\n",
            "\n",
            "Rouge-1: 0.3076923027218935\n",
            "-------\n",
            "Input sentence: \t Do you want to go first ?\n",
            "\n",
            "Decoded sentence:  Would you like to come in ?\n",
            "\n",
            "Rouge-1: 0.4285714235714286\n",
            "-------\n",
            "Input sentence: \t I 'm not singing .\n",
            "\n",
            "Decoded sentence:  I don 't feel a lot .\n",
            "\n",
            "Rouge-1: 0.33333332847222225\n",
            "-------\n",
            "Input sentence: \t Eternal life .\n",
            "\n",
            "Decoded sentence:  That 's a full .\n",
            "\n",
            "Rouge-1: 0.24999999531250006\n",
            "-------\n",
            "Input sentence: \t Did he commit suicide ?\n",
            "\n",
            "Decoded sentence:  Is there anything I can do ?\n",
            "\n",
            "Rouge-1: 0.1666666618055557\n",
            "-------\n",
            "Input sentence: \t The war has begun .\n",
            "\n",
            "Decoded sentence:  She 's gonna be okay .\n",
            "\n",
            "Rouge-1: 0.18181817685950424\n",
            "-------\n",
            "Input sentence: \t I kept my word .\n",
            "\n",
            "Decoded sentence:  I think I 'm gonna do that .\n",
            "\n",
            "Rouge-1: 0.3076923029585799\n",
            "-------\n",
            "Input sentence: \t Good morning , Jack .\n",
            "\n",
            "Decoded sentence:  Good night , sweetheart .\n",
            "\n",
            "Rouge-1: 0.5999999950000001\n",
            "-------\n",
            "Input sentence: \t Are you a murderer ?\n",
            "\n",
            "Decoded sentence:  You 're sure you 're not thinking ?\n",
            "\n",
            "Rouge-1: 0.3076923029585799\n",
            "-------\n",
            "Input sentence: \t I 'm not sleeping well .\n",
            "\n",
            "Decoded sentence:  I won 't let you do now .\n",
            "\n",
            "Rouge-1: 0.2857142808163266\n",
            "-------\n",
            "Input sentence: \t You 're never gonna change .\n",
            "\n",
            "Decoded sentence:  You 're gonna be all right .\n",
            "\n",
            "Rouge-1: 0.6153846104142012\n",
            "-------\n",
            "Input sentence: \t Welcome to reality .\n",
            "\n",
            "Decoded sentence:  You 're gonna be okay .\n",
            "\n",
            "Rouge-1: 0.1999999952000001\n",
            "-------\n",
            "Input sentence: \t Do you wanna have kids ?\n",
            "\n",
            "Decoded sentence:  Would you like to come in ?\n",
            "\n",
            "Rouge-1: 0.3076923027218935\n",
            "-------\n",
            "Input sentence: \t You two are coming with me .\n",
            "\n",
            "Decoded sentence:  You scared the shit out of me .\n",
            "\n",
            "Rouge-1: 0.3999999950222222\n",
            "-------\n",
            "Input sentence: \t I 've been promoted .\n",
            "\n",
            "Decoded sentence:  I have a proposal .\n",
            "\n",
            "Rouge-1: 0.3999999950000001\n",
            "-------\n",
            "Input sentence: \t You 'll have to die .\n",
            "\n",
            "Decoded sentence:  You 're gonna be all right .\n",
            "\n",
            "Rouge-1: 0.3076923027218935\n",
            "-------\n",
            "Input sentence: \t What are you going to do with us ?\n",
            "\n",
            "Decoded sentence:  What would you like to drink ?\n",
            "\n",
            "Rouge-1: 0.4999999950781251\n",
            "-------\n",
            "Input sentence: \t I don 't have a brother .\n",
            "\n",
            "Decoded sentence:  I don 't want to hear it .\n",
            "\n",
            "Rouge-1: 0.5333333283555556\n",
            "-------\n",
            "Input sentence: \t I 'm not signing .\n",
            "\n",
            "Decoded sentence:  I don 't feel a lot .\n",
            "\n",
            "Rouge-1: 0.33333332847222225\n",
            "-------\n",
            "Input sentence: \t You 're not eating .\n",
            "\n",
            "Decoded sentence:  You 're not gonna believe it .\n",
            "\n",
            "Rouge-1: 0.6666666618055556\n",
            "-------\n",
            "Input sentence: \t I need evidence .\n",
            "\n",
            "Decoded sentence:  I need to get to the tailet .\n",
            "\n",
            "Rouge-1: 0.49999999555555563\n",
            "-------\n",
            "Input sentence: \t He 's got a fever .\n",
            "\n",
            "Decoded sentence:  He 's gonna be all right .\n",
            "\n",
            "Rouge-1: 0.4615384565680473\n",
            "-------\n",
            "Input sentence: \t I should get going , too .\n",
            "\n",
            "Decoded sentence:  I think I 'm gonna do that .\n",
            "\n",
            "Rouge-1: 0.266666661688889\n",
            "-------\n",
            "Input sentence: \t Want to switch ?\n",
            "\n",
            "Decoded sentence:  You wanna come in ?\n",
            "\n",
            "Rouge-1: 0.22222221728395072\n",
            "-------\n",
            "Input sentence: \t They didn 't find anything .\n",
            "\n",
            "Decoded sentence:  They 're gonna be all right .\n",
            "\n",
            "Rouge-1: 0.3076923027218935\n",
            "-------\n",
            "Input sentence: \t How could I be so blind ?\n",
            "\n",
            "Decoded sentence:  How do we do this ?\n",
            "\n",
            "Rouge-1: 0.3076923027218935\n",
            "-------\n",
            "Input sentence: \t She 'll kill you .\n",
            "\n",
            "Decoded sentence:  She 's gonna be all right .\n",
            "\n",
            "Rouge-1: 0.33333332847222225\n",
            "-------\n",
            "Input sentence: \t Jack , can you hear me ?\n",
            "\n",
            "Decoded sentence:  You want to come in ide ?\n",
            "\n",
            "Rouge-1: 0.14285713785714302\n",
            "-------\n",
            "Input sentence: \t This will not stand , this aggression against , uh , Kuwait .\n",
            "\n",
            "Decoded sentence:  This isn 't going to work about it .\n",
            "\n",
            "Rouge-1: 0.18181817698347122\n",
            "-------\n",
            "Input sentence: \t Do you have a tissue ?\n",
            "\n",
            "Decoded sentence:  You got a problem ?\n",
            "\n",
            "Rouge-1: 0.36363635867768596\n",
            "-------\n",
            "Input sentence: \t I 'll call a taxi .\n",
            "\n",
            "Decoded sentence:  I 'm gonna call you back .\n",
            "\n",
            "Rouge-1: 0.4615384565680473\n",
            "-------\n",
            "Input sentence: \t This is our last chance .\n",
            "\n",
            "Decoded sentence:  This is a good time .\n",
            "\n",
            "Rouge-1: 0.4999999950000001\n",
            "-------\n",
            "Input sentence: \t Am I beautiful ?\n",
            "\n",
            "Decoded sentence:  Is anybody here ?\n",
            "\n",
            "Rouge-1: 0.24999999500000009\n",
            "-------\n",
            "Input sentence: \t I 'm not working for you .\n",
            "\n",
            "Decoded sentence:  I won 't say anything .\n",
            "\n",
            "Rouge-1: 0.3076923027218935\n",
            "-------\n",
            "Input sentence: \t It 's breakfast time .\n",
            "\n",
            "Decoded sentence:  It 's a presty .\n",
            "\n",
            "Rouge-1: 0.5999999950000001\n",
            "-------\n",
            "Input sentence: \t I 've got two kids .\n",
            "\n",
            "Decoded sentence:  I have to get to the tailet .\n",
            "\n",
            "Rouge-1: 0.2857142808163266\n",
            "-------\n",
            "Input sentence: \t He 's choking .\n",
            "\n",
            "Decoded sentence:  He 's gonna be all right .\n",
            "\n",
            "Rouge-1: 0.5454545408264463\n",
            "-------\n",
            "Input sentence: \t We 're on holiday .\n",
            "\n",
            "Decoded sentence:  We 're gonna be all right .\n",
            "\n",
            "Rouge-1: 0.499999995138889\n",
            "-------\n",
            "Input sentence: \t Who am I gonna tell ?\n",
            "\n",
            "Decoded sentence:  Who would have thought ?\n",
            "\n",
            "Rouge-1: 0.36363635867768596\n",
            "-------\n",
            "Input sentence: \t How many children do you have ?\n",
            "\n",
            "Decoded sentence:  How long will that take ?\n",
            "\n",
            "Rouge-1: 0.3076923027218935\n",
            "-------\n",
            "Input sentence: \t But I 'll be back .\n",
            "\n",
            "Decoded sentence:  But I 'm not going to help you .\n",
            "\n",
            "Rouge-1: 0.39999999520000007\n",
            "-------\n",
            "Input sentence: \t Didn 't you get my message ?\n",
            "\n",
            "Decoded sentence:  You don 't know what to say ?\n",
            "\n",
            "Rouge-1: 0.266666661688889\n",
            "-------\n",
            "Input sentence: \t It 's three in the morning .\n",
            "\n",
            "Decoded sentence:  It 's not that say .\n",
            "\n",
            "Rouge-1: 0.4615384565680473\n",
            "-------\n",
            "Input sentence: \t How much do you have left ?\n",
            "\n",
            "Decoded sentence:  How long you been think of that ?\n",
            "\n",
            "Rouge-1: 0.3999999950222222\n",
            "-------\n",
            "Input sentence: \t You 're miserable .\n",
            "\n",
            "Decoded sentence:  You 're gonna be all right .\n",
            "\n",
            "Rouge-1: 0.5454545408264463\n",
            "-------\n",
            "Input sentence: \t He 's a lawyer .\n",
            "\n",
            "Decoded sentence:  He 's gonna be okay .\n",
            "\n",
            "Rouge-1: 0.5454545404958678\n",
            "-------\n",
            "Input sentence: \t Will you tell her ?\n",
            "\n",
            "Decoded sentence:  You 're not going to do that ?\n",
            "\n",
            "Rouge-1: 0.1538461491124262\n",
            "-------\n",
            "Input sentence: \t She 's fainted .\n",
            "\n",
            "Decoded sentence:  She 's gonna be all right .\n",
            "\n",
            "Rouge-1: 0.5454545408264463\n",
            "-------\n",
            "Input sentence: \t We know everything .\n",
            "\n",
            "Decoded sentence:  We have to get out of here .\n",
            "\n",
            "Rouge-1: 0.33333332888888895\n",
            "-------\n",
            "Input sentence: \t He 's a criminal .\n",
            "\n",
            "Decoded sentence:  He 's gonna be okay .\n",
            "\n",
            "Rouge-1: 0.5454545404958678\n",
            "-------\n",
            "Input sentence: \t The witness may step down .\n",
            "\n",
            "Decoded sentence:  The same is a fird .\n",
            "\n",
            "Rouge-1: 0.3333333283333334\n",
            "-------\n",
            "Input sentence: \t Anchors aweigh .\n",
            "\n",
            "Decoded sentence:  So it would seem .\n",
            "\n",
            "Rouge-1: 0.24999999531250006\n",
            "-------\n",
            "Input sentence: \t Nothing 's going to happen to me .\n",
            "\n",
            "Decoded sentence:  Nothing will happen .\n",
            "\n",
            "Rouge-1: 0.49999999555555563\n",
            "-------\n",
            "Input sentence: \t They 'll find you .\n",
            "\n",
            "Decoded sentence:  They 're gonna be okay .\n",
            "\n",
            "Rouge-1: 0.36363635867768596\n",
            "-------\n",
            "Input sentence: \t I 'll see you in a couple of days .\n",
            "\n",
            "Decoded sentence:  See you in a minute .\n",
            "\n",
            "Rouge-1: 0.49999999531250006\n",
            "-------\n",
            "Input sentence: \t She 's coming over here .\n",
            "\n",
            "Decoded sentence:  She 's gonna be all right .\n",
            "\n",
            "Rouge-1: 0.4615384565680473\n",
            "-------\n",
            "Input sentence: \t Since just before i started pretending i loved it .\n",
            "\n",
            "Decoded sentence:  The tool will be working that way .\n",
            "\n",
            "Rouge-1: 0.11111110617283973\n",
            "-------\n",
            "Input sentence: \t It 's nice being married , eh ?\n",
            "\n",
            "Decoded sentence:  It 's a presty name the same .\n",
            "\n",
            "Rouge-1: 0.24999999500000009\n",
            "-------\n",
            "Input sentence: \t He is not dead what can to sleep eternally .\n",
            "\n",
            "Decoded sentence:  He won 't be all right .\n",
            "\n",
            "Rouge-1: 0.23529411280276827\n",
            "-------\n",
            "Input sentence: \t I 'm a fast learner .\n",
            "\n",
            "Decoded sentence:  I 'm an accidint .\n",
            "\n",
            "Rouge-1: 0.5454545404958678\n",
            "-------\n",
            "Input sentence: \t Turn off the music .\n",
            "\n",
            "Decoded sentence:  Turn the light off .\n",
            "\n",
            "Rouge-1: 0.7999999950000002\n",
            "-------\n",
            "Input sentence: \t I 'll kill you both .\n",
            "\n",
            "Decoded sentence:  I 'm gonna call you back .\n",
            "\n",
            "Rouge-1: 0.4615384565680473\n",
            "-------\n",
            "Input sentence: \t I had everything under control .\n",
            "\n",
            "Decoded sentence:  I have to get to the tailet .\n",
            "\n",
            "Rouge-1: 0.2857142808163266\n",
            "-------\n",
            "Input sentence: \t They 'll find you .\n",
            "\n",
            "Decoded sentence:  They 're gonna be okay .\n",
            "\n",
            "Rouge-1: 0.36363635867768596\n",
            "-------\n",
            "Input sentence: \t I 'll sleep on the couch .\n",
            "\n",
            "Decoded sentence:  I 'll take care of thes .\n",
            "\n",
            "Rouge-1: 0.4285714235714286\n",
            "-------\n",
            "Input sentence: \t This doesn 't prove anything .\n",
            "\n",
            "Decoded sentence:  This isn 't going to wake .\n",
            "\n",
            "Rouge-1: 0.4615384565680473\n",
            "-------\n",
            "Input sentence: \t Godfreys , uh , get what they want .\n",
            "\n",
            "Decoded sentence:  Maybe I can do anything .\n",
            "\n",
            "Rouge-1: 0.1333333285333335\n",
            "-------\n",
            "Input sentence: \t BETH ON TAPE :\n",
            "\n",
            "Decoded sentence:  Somebody help me .\n",
            "\n",
            "Rouge-1: 0.0\n",
            "-------\n",
            "Input sentence: \t Who owns the car ?\n",
            "\n",
            "Decoded sentence:  You should get some coffee .\n",
            "\n",
            "Rouge-1: 0.0\n",
            "-------\n",
            "Input sentence: \t Don 't turn on the lights .\n",
            "\n",
            "Decoded sentence:  Don 't you forget that .\n",
            "\n",
            "Rouge-1: 0.4615384565680473\n",
            "-------\n",
            "Input sentence: \t How many kids do you have ?\n",
            "\n",
            "Decoded sentence:  How long will that take ?\n",
            "\n",
            "Rouge-1: 0.3076923027218935\n",
            "-------\n",
            "Input sentence: \t In theory , yes .\n",
            "\n",
            "Decoded sentence:  The tame as you .\n",
            "\n",
            "Rouge-1: 0.19999999500000015\n",
            "-------\n",
            "Input sentence: \t Been waiting long ?\n",
            "\n",
            "Decoded sentence:  You got a second ?\n",
            "\n",
            "Rouge-1: 0.22222221728395072\n",
            "-------\n",
            "Input sentence: \t I 'm going to be a dad .\n",
            "\n",
            "Decoded sentence:  I 'm gonna call you back .\n",
            "\n",
            "Rouge-1: 0.3999999950222222\n",
            "-------\n",
            "Input sentence: \t I am not leaving him .\n",
            "\n",
            "Decoded sentence:  I won 't let you do now .\n",
            "\n",
            "Rouge-1: 0.2857142808163266\n",
            "-------\n",
            "Input sentence: \t You hesitated .\n",
            "\n",
            "Decoded sentence:  You scared the shit out of me .\n",
            "\n",
            "Rouge-1: 0.3636363596694215\n",
            "-------\n",
            "Input sentence: \t I 'd rather stand .\n",
            "\n",
            "Decoded sentence:  I 'm so goid .\n",
            "\n",
            "Rouge-1: 0.3999999950000001\n",
            "-------\n",
            "Input sentence: \t It stopped raining .\n",
            "\n",
            "Decoded sentence:  That 's not going to happen .\n",
            "\n",
            "Rouge-1: 0.18181817719008275\n",
            "-------\n",
            "Input sentence: \t You want evidence ?\n",
            "\n",
            "Decoded sentence:  You want to come in ?\n",
            "\n",
            "Rouge-1: 0.5999999952\n",
            "-------\n",
            "Input sentence: \t Where 's the evidence ?\n",
            "\n",
            "Decoded sentence:  Where do you like ?\n",
            "\n",
            "Rouge-1: 0.3999999950000001\n",
            "-------\n",
            "Input sentence: \t After the war , there 'll be mother for each survivor .\n",
            "\n",
            "Decoded sentence:  But I am not surprised .\n",
            "\n",
            "Rouge-1: 0.11111110666666683\n",
            "-------\n",
            "Input sentence: \t You can be walking around lucky and not know it .\n",
            "\n",
            "Decoded sentence:  You 're gonna be all right .\n",
            "\n",
            "Rouge-1: 0.3333333285802469\n",
            "-------\n",
            "Input sentence: \t Recurrent spontaneous psychokinesis .\n",
            "\n",
            "Decoded sentence:  Sorry to interrupt .\n",
            "\n",
            "Rouge-1: 0.24999999500000009\n",
            "-------\n",
            "Input sentence: \t My older brother always says the nastiest shit .\n",
            "\n",
            "Decoded sentence:  I 'm sorry to hear that .\n",
            "\n",
            "Rouge-1: 0.12499999507812519\n",
            "-------\n",
            "Input sentence: \t I 'll give you an extra $ 20 for a blowjob .\n",
            "\n",
            "Decoded sentence:  I 'll take care of thes .\n",
            "\n",
            "Rouge-1: 0.31578946903047095\n",
            "-------\n",
            "Input sentence: \t I kept hoping he 'd make it back .\n",
            "\n",
            "Decoded sentence:  I think I 'm gonna go the wood .\n",
            "\n",
            "Rouge-1: 0.22222221722222232\n",
            "-------\n",
            "Input sentence: \t Get the fuck out and don 't come back .\n",
            "\n",
            "Decoded sentence:  Put your hands on the floor .\n",
            "\n",
            "Rouge-1: 0.23529411280276827\n",
            "-------\n",
            "Input sentence: \t Comanches call it Tahnimara .\n",
            "\n",
            "Decoded sentence:  Maybe I can 't take a look .\n",
            "\n",
            "Rouge-1: 0.1538461491124262\n",
            "-------\n",
            "Input sentence: \t A drop of dew and the clock struck two .\n",
            "\n",
            "Decoded sentence:  I think I 'm gonna kill me .\n",
            "\n",
            "Rouge-1: 0.11111110617283973\n",
            "-------\n",
            "Input sentence: \t We have evidence .\n",
            "\n",
            "Decoded sentence:  We have to get out of here .\n",
            "\n",
            "Rouge-1: 0.49999999555555563\n",
            "-------\n",
            "Input sentence: \t He 's in critical condition .\n",
            "\n",
            "Decoded sentence:  He 's gonna be all right .\n",
            "\n",
            "Rouge-1: 0.4615384565680473\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-ACyOM1N5_y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9ce568d8-4949-4c8d-bbd6-ee42f916e3d9"
      },
      "source": [
        "f'Rouge-1 average: {np.mean(np.array(r1))}'"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Rouge-1 average: 0.34554883725468355'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCfxpY8_RQ3m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}