Тема мого проекту: Визначення зв'язності та цілісності згенерованого тексту

Мета / Застосування:  Моделі побудовані на трансформерах, як-от GPT-2, BERT, RoBERTa, XLM, та ін., пропонують широкі можливості щодо автоматичної генерації текстів. Наприклад, вона може використовуватись для генерування writing prompts, які значно полегшують та прискорюють написання листів, статей, відгуків, тощо. 
Проте не всі зразки тексту, згенеровані таким чином, мають сенс або є однаково читабельними. Тому мій проект має на меті визначення цілісності (на рівні загальної тематики) та зв'язності (на локальному рівні, від речення до речення) текстів згенерованих за допомогою GPT-2 заради покращення якості writing prompts, визначення disfluencies в тексті та вилучення нерелевантних частин.

Дані: 
- зразки згенерованого тексту
- https://github.com/aylai/GCDC-corpus - проанотований корпус на основі датасету Yahoo! Answers Comprehensive Questions and Answers
- http://u.cs.biu.ac.il/~koppel/BlogCorpus.htm - The Blog Authorship Corpus 
- https://www.kaggle.com/c/asap-aes/data - Корпус студентських есе
- приклади незв'язного тесту (умовно, машинно перекладені тексти з іншомовного корпусу https://lindat.mff.cuni.cz/repository/xmlui/handle/11858/00-097C-0000-0023-1358-3)

З метою аналізу можна розглядати наступне:

   - coreference resolution
   - семантична цілісність (повторення ключових понять та іменованих сутностей в різних частинах тексту), використання анафори та синонімів з одного семантичного поля
   - використання сполучників та introductory phrases


Щось схоже бачу за посиланням: https://link.springer.com/article/10.3758/s13428-015-0651-7
