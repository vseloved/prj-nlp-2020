{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./official-2014.combined-withalt.m2.txt') as f:\n",
    "    corpus = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def parse_annotation(text):\n",
    "    parts = text.replace('A ', '').split('|||')\n",
    "    nums = parts[0].split(' ')\n",
    "    return {\n",
    "        'start': int(nums[0]),\n",
    "        'end': int(nums[1]),\n",
    "        'err_tag': parts[1],\n",
    "        'replacement': parts[2],\n",
    "        'ann_num': parts[5]\n",
    "    }\n",
    "\n",
    "\n",
    "def get_pairs(lst):\n",
    "    return list(zip(lst, lst[1:]))\n",
    "\n",
    "\n",
    "def get_annotation_blocks(corpus):\n",
    "    blocks = corpus.split('\\n\\n')\n",
    "    res = {}\n",
    "    for block in blocks:\n",
    "        group = block.split('\\n')\n",
    "\n",
    "        # skip sentences with one or zero annotations\n",
    "        if len(group) < 3:\n",
    "            continue\n",
    "        sent = group[0].replace('S ', '')\n",
    "        res[sent] = {}\n",
    "        for annot in group[1:]:\n",
    "            if annot:\n",
    "                parsed = parse_annotation(annot)\n",
    "                if not res[sent].get(parsed['ann_num']):\n",
    "                    res[sent][parsed['ann_num']] = []\n",
    "                res[sent][parsed['ann_num']].append(parsed)\n",
    "\n",
    "    return {sent: anns for sent, anns in res.items()}\n",
    "\n",
    "\n",
    "def find_correction(lst, predicate):\n",
    "    corrs_filtered = [x for x in lst if predicate(x)]\n",
    "    return corrs_filtered[0] if corrs_filtered else None\n",
    "\n",
    "\n",
    "def compare_annotator_pair(fst, snd):\n",
    "    matches_gen = 0\n",
    "    matches_by_err_tag = {}\n",
    "\n",
    "    for f in fst:\n",
    "        f_start = f['start']\n",
    "        f_end = f['end']\n",
    "        f_repl = f['replacement']\n",
    "        err_tag = f['err_tag']\n",
    "        is_noop = err_tag == 'noop'\n",
    "\n",
    "        for s in snd:\n",
    "            s_start = s['start']\n",
    "            s_end = s['end']\n",
    "            s_repl = s['replacement']\n",
    "            is_start_match = f_start == s_start\n",
    "            is_end_match = f_end == s_end\n",
    "\n",
    "            is_match = False\n",
    "\n",
    "            if is_start_match and is_end_match:\n",
    "                is_match = f_repl == s_repl\n",
    "\n",
    "            \"\"\"\n",
    "            Quite a naive an unoptimized logic\n",
    "            for finding intersecting annotations:\n",
    "\n",
    "            - if one of the boundary matches - look for another correction in the list\n",
    "            with a shorter range, and concat its replacement value to the currect value\n",
    "            - if the contatenated value equals to the one we compare with -\n",
    "            we may assume that those two corrections actually mean the same\n",
    "            \"\"\"\n",
    "            if is_start_match and not is_end_match:\n",
    "                if s_end > f_end:\n",
    "                    next_corr = find_correction(\n",
    "                        fst, lambda x: x['end'] == s_end)\n",
    "                    if next_corr:\n",
    "                        next_repl = next_corr['replacement']\n",
    "                        is_match = f_repl + next_repl == s_repl\n",
    "                else:\n",
    "                    next_corr = find_correction(\n",
    "                        snd, lambda x: x['end'] == f_end)\n",
    "                    if next_corr:\n",
    "                        next_repl = next_corr['replacement']\n",
    "                        is_match = f_repl + next_repl == s_repl\n",
    "            if not is_start_match and is_end_match:\n",
    "                if f_start > s_start:\n",
    "                    prev_corr = find_correction(\n",
    "                        fst, lambda x: x['start'] == s_start)\n",
    "                    if prev_corr:\n",
    "                        prev_repl = prev_corr['replacement']\n",
    "                        is_match = prev_repl + f_repl == s_repl\n",
    "                else:\n",
    "                    prev_corr = find_correction(\n",
    "                        snd, lambda x: x['start'] == f_start)\n",
    "                    if prev_corr:\n",
    "                        prev_repl = prev_corr['replacement']\n",
    "                        is_match = prev_repl + f_repl == s_repl\n",
    "\n",
    "            if is_match:\n",
    "                matches_gen += 1\n",
    "\n",
    "            if is_match and err_tag == s['err_tag'] and not is_noop:\n",
    "                if matches_by_err_tag.get(err_tag):\n",
    "                    matches_by_err_tag[err_tag] += 1\n",
    "                else:\n",
    "                    matches_by_err_tag[err_tag] = 1\n",
    "            else:\n",
    "                if not matches_by_err_tag.get(err_tag) and not is_noop:\n",
    "                    matches_by_err_tag[err_tag] = 0\n",
    "\n",
    "    return matches_gen, matches_by_err_tag\n",
    "\n",
    "\n",
    "def get_pair_agreement(fst, snd):\n",
    "    matches_gen, matches_by_err_type = compare_annotator_pair(fst, snd)\n",
    "\n",
    "    # Get unique corrections to not count matches twice\n",
    "    distinct_corrections = len(fst) + len(snd) - matches_gen\n",
    "    agr_gen = round(matches_gen/distinct_corrections, 2)\n",
    "    return agr_gen, matches_by_err_type\n",
    "\n",
    "\n",
    "def get_inter_ann_agr_pair(sentence, annotations, existing_pair_agrs):\n",
    "    pairwise_list = get_pairs(list(annotations.values()))\n",
    "\n",
    "    # In order to not mutate function arg\n",
    "    new_pair_agrs = existing_pair_agrs.copy()\n",
    "\n",
    "    for fst, snd in pairwise_list:\n",
    "        pair_num = int(fst[0]['ann_num'])\n",
    "        pair_agr_gen, pair_agr_err_type = get_pair_agreement(fst, snd)\n",
    "        new_pair_agrs[pair_num].append((pair_agr_gen, pair_agr_err_type))\n",
    "    return new_pair_agrs\n",
    "\n",
    "\n",
    "def get_all_inter_ann_agr(corpus):\n",
    "    annotation_blocks = get_annotation_blocks(corpus)\n",
    "    pair_agrs = [[] for _ in range(0, 4)]  # 4 possible pairs of 5 annonators\n",
    "\n",
    "    for sent, ann in annotation_blocks.items():\n",
    "        # skip sentences with a single annotator\n",
    "        if len(ann.keys()) > 1:\n",
    "            pair_agrs = get_inter_ann_agr_pair(sent, ann, pair_agrs)\n",
    "\n",
    "    pair_agrs_gen = [[x for x, _ in y] for y in pair_agrs]\n",
    "    agr_by_annot_pairs = [sum(x)/len(x) for x in pair_agrs_gen if x]\n",
    "\n",
    "    # General mean\n",
    "    avg_agr_by_annottators = round(sum(agr_by_annot_pairs)/4, 2)\n",
    "\n",
    "    pair_agrs_by_err = [[x for _, x in y if x] for y in pair_agrs]\n",
    "    pair_agrs_by_err_flattened = [\n",
    "        x for sublist in pair_agrs_by_err for x in sublist]\n",
    "\n",
    "    # Mean by error types\n",
    "    avg_agr_by_err_type = {}\n",
    "\n",
    "    # Group all errot tag means by error types\n",
    "    for x in pair_agrs_by_err_flattened:\n",
    "        for k, v in x.items():\n",
    "            if avg_agr_by_err_type.get(k):\n",
    "                prev = avg_agr_by_err_type[k]\n",
    "                # average between previous and current mean\n",
    "                avg_agr_by_err_type[k] = (v + prev)/2\n",
    "            else:\n",
    "                avg_agr_by_err_type[k] = v\n",
    "    for k, v in avg_agr_by_err_type.items():\n",
    "        # Multiply by the generic mean since it should be reltive to it\n",
    "        avg_agr_by_err_type[k] = round(v * avg_agr_by_annottators, 2)\n",
    "\n",
    "    return avg_agr_by_annottators, avg_agr_by_err_type\n",
    "\n",
    "\n",
    "all_inter_ann_agr = get_all_inter_ann_agr(corpus)\n",
    "print(all_inter_ann_agr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
