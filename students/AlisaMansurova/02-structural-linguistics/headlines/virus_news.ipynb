{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_core_web_md\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk import word_tokenize, pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = en_core_web_md.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../../../tasks/02-structural-linguistics/data/examiner-headlines.txt', 'r') as f:\n",
    "    corpus = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_entities(doc):\n",
    "    entities = ['ORG', 'PERSON', 'GPE', 'TIME', 'MONEY', 'PRODUCT']\n",
    "    ents = [x.label_ in entities for x in doc.ents]\n",
    "    return any(ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_syns_tag(univ_tag):\n",
    "    if univ_tag == 'ADJ':\n",
    "        return 'a'\n",
    "    if univ_tag == 'NOUN':\n",
    "        return 'n'\n",
    "    if univ_tag == 'VERB':\n",
    "        return 'v'\n",
    "    if univ_tag == 'ADV':\n",
    "        return 'r'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME: debug case with mom abuse\n",
    "def get_sentiment(doc):\n",
    "    pos_sum = 0.0\n",
    "    neg_sum = 0.0\n",
    "\n",
    "    for token in doc:\n",
    "#         print(token)\n",
    "        pos = get_syns_tag(token.pos_)\n",
    "        \n",
    "        if pos:\n",
    "            synsets = list(swn.senti_synsets(token.text, pos))\n",
    "#             print(synsets)\n",
    "            pos_score = [x.pos_score() for x in synsets]\n",
    "            neg_score = [x.neg_score() for x in synsets]\n",
    "            if pos_score:\n",
    "                pos_agv = sum(pos_score)/len(pos_score)\n",
    "                if pos_agv > 0.5:\n",
    "                    pos_sum += pos_agv\n",
    "            if neg_score:\n",
    "                neg_agv = sum(neg_score)/len(neg_score)\n",
    "                if neg_agv > 0.5:\n",
    "                    neg_sum += neg_agv\n",
    "    \n",
    "    if pos_sum or neg_sum:\n",
    "        return pos_sum > neg_sum\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_adj_or_adv_comp_sup(doc):\n",
    "    return any((x.pos_ == 'ADJ' or x.pos_ == 'ADV') and x.text.lower() != x.lemma_.lower() for x in doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug(corpus, s, e):\n",
    "    all_ents = 0\n",
    "    all_sents = 0\n",
    "    all_super_ad = 0\n",
    "\n",
    "    for sample in corpus[s:e]:\n",
    "        doc = nlp(sample)\n",
    "#         print(sample)\n",
    "\n",
    "        has_ents = has_entities(doc)\n",
    "        sents = get_sentiment(doc)\n",
    "        is_super_ad = is_adj_or_adv_comp_sup(doc)\n",
    "        \n",
    "        if has_ents:\n",
    "            all_ents += 1\n",
    "        if sents:\n",
    "            all_sents += 1\n",
    "        if is_super_ad:\n",
    "            all_super_ad += 1\n",
    "    res = {\n",
    "        'entities': all_ents/len(corpus[s:e]),\n",
    "        'sentiment': all_sents/len(corpus[s:e]),\n",
    "        'is_super_ad': all_super_ad/len(corpus[s:e])\n",
    "    }\n",
    "    \n",
    "    return res\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'entities': 32.89, 'sentiment': 2.34, 'is_super_ad': 1.21}\n"
     ]
    }
   ],
   "source": [
    "print(debug(corpus, 0, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SentiSynset('happy.a.01'),\n",
       " SentiSynset('felicitous.s.02'),\n",
       " SentiSynset('glad.s.02'),\n",
       " SentiSynset('happy.s.04')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(swn.senti_synsets('happy', 'a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
