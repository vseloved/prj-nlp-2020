{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import json\n",
    "import string\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smart_capitalize(word):\n",
    "    if word.isupper():\n",
    "        return word\n",
    "    elif any([letter.isupper() for letter in word]):\n",
    "        return word\n",
    "    elif word[0] in string.punctuation:\n",
    "        return word[0] + word[1:].capitalize()\n",
    "    else:\n",
    "        return word.capitalize()\n",
    "\n",
    "def capitalize_title(s):\n",
    "    doc = nlp(s)\n",
    "    pos_tags = ['NOUN', 'PRON', 'VERB', 'ADJ', 'ADV', 'AUX', 'PROPN', 'NUM']\n",
    "    capitalized_string = \"\"\n",
    "    word = \"\"\n",
    "    num_tokens = len(doc)\n",
    "    \n",
    "    for i, token in enumerate(doc):\n",
    "        word += token.text\n",
    "            \n",
    "        if (\n",
    "            i == 0 or \n",
    "            i == num_tokens - 1 or\n",
    "            token.pos_ in pos_tags or\n",
    "            ((token.pos_ == 'ADP' or token.pos_ == 'SCONJ') and token.dep_ == 'mark') or\n",
    "            (token.pos_ == 'PART' and token.dep_ == 'neg' and word == token.text) or # to handle separate Not word\n",
    "            token.dep_ == 'poss'\n",
    "        ):\n",
    "            word = smart_capitalize(word)\n",
    "        \n",
    "        # if token is not a whole word, we will go to next\n",
    "        if not token.whitespace_ and i != num_tokens - 1:\n",
    "            #print(2)\n",
    "            continue\n",
    "          \n",
    "        \n",
    "        if '-' in word and len(word) > 1:\n",
    "            word = '-'.join([smart_capitalize(part) for part in word.split('-')])\n",
    "            capitalized_string += word + token.whitespace_\n",
    "            word = \"\"\n",
    "        elif len(word) > 3:\n",
    "            capitalized_string += smart_capitalize(word) + token.whitespace_\n",
    "            word = \"\"\n",
    "        else:\n",
    "            capitalized_string += word + token.whitespace_\n",
    "            word = \"\"\n",
    "            \n",
    "    return capitalized_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Working with data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_examiner():\n",
    "    path = '/home/yevhen/prj/prj-nlp-2020/tasks/02-structural-linguistics/data/examiner-headlines.txt'\n",
    "    with open(path, 'r') as f:\n",
    "        corpus = f.read().splitlines()\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "examiner = read_examiner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The phantoms of St. Mary's\""
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j = 1\n",
    "examiner[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The Phantoms of St. Mary's\""
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "capitalize_title(nlp(examiner[j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy_on_corpus(corpus, validate=False):\n",
    "    corpus_len = len(corpus)\n",
    "    correct = 0\n",
    "    for item in corpus:\n",
    "        if validate:\n",
    "            capitalized_title = capitalize_title(item[0])\n",
    "            if capitalized_title == item[1]:\n",
    "                correct += 1\n",
    "            else:\n",
    "                # Here we print correct and our version to see, where we did not succeed \n",
    "                print(item[0], '---', capitalized_title, '---', item[1], '\\n')\n",
    "        else:\n",
    "            try:\n",
    "                # I did not catch all edge cases, so added this try-except\n",
    "                capitalized_title = capitalize_title(item)\n",
    "            except:\n",
    "                continue\n",
    "            if capitalized_title == item:\n",
    "                correct += 1\n",
    "    return correct / corpus_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1472"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_accuracy_on_corpus(examiner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_test_set():\n",
    "    path = '/home/yevhen/prj/prj-nlp-2020/tasks/02-structural-linguistics/data/headlines-test-set.json'\n",
    "    with open(path, 'r') as f:\n",
    "        test_set = json.load(f)\n",
    "    return test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = read_test_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How To Design A College Curriculum to Help You in Life --- How To Design A College Curriculum to Help You in Life --- How to Design a College Curriculum to Help You in Life \n",
      "\n",
      "Brazilian & bikini waxing how to choose an sf bay area hair removal salon or spa --- Brazilian & Bikini Waxing How to Choose an Sf Bay Area Hair Removal Salon or Spa --- Brazilian & Bikini Waxing How to Choose an SF Bay Area Hair Removal Salon or Spa \n",
      "\n",
      "How it all plays out on Church Street --- How It all Plays out on Church Street --- How It All Plays out on Church Street \n",
      "\n",
      "How to Rock at Marketing (and Still Like Yourself in the Morning) --- How to Rock at Marketing (And Still Like Yourself in the Morning) --- How to Rock at Marketing (and Still Like Yourself in the Morning) \n",
      "\n",
      "'Jackass 3D' trailer explodes right in your face so don't try this at home (video) --- 'Jackass 3D' Trailer Explodes Right in Your Face So Don't Try This at Home (Video) --- 'Jackass 3D' Trailer Explodes Right in Your Face so Don't Try This at Home (Video) \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.95"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_accuracy_on_corpus(test_set, validate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import sentiwordnet as swn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "def are_there_named_entities(doc):\n",
    "    selected_entity_types = ['PERCENT', 'PRODUCT', 'WORK_OF_ART', 'MONEY', 'QUANTITY']\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in selected_entity_types:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def is_there_non_neutral_score(doc):\n",
    "    pos_to_senti_mapping = {\n",
    "    'NOUN': 'n',\n",
    "    'VERB': 'v',\n",
    "    'ADJ': 'a',\n",
    "    'ADV': 'r',\n",
    "    }\n",
    "    for token in doc:\n",
    "        if token.pos_ in ('NOUN', 'VERB', 'ADJ', 'ADV'):\n",
    "            sentis = list(swn.senti_synsets(token.text, pos_to_senti_mapping[token.pos_]))\n",
    "            positive_scores = sum([senti.pos_score() for senti in sentis[:5]])\n",
    "            negative_scores = sum([senti.neg_score() for senti in sentis[:5]])\n",
    "            # Avoids dividing by zero\n",
    "            if negative_scores:\n",
    "                score_ratio = np.divide(positive_scores, negative_scores)\n",
    "                if score_ratio > 0.5:\n",
    "                    return True\n",
    "    return False\n",
    "\n",
    "def are_there_degrees(doc):\n",
    "    # If any word has degree, degrees will be non empty\n",
    "    degrees = [w.morph.degree_ for w in doc if w.morph.degree_ != '']\n",
    "    return bool(degrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_viral_score(corpus):\n",
    "    corpus_len = len(corpus)\n",
    "    named_ents = 0\n",
    "    sentiments = 0\n",
    "    degrees = 0\n",
    "    for item in corpus:\n",
    "        doc = nlp(item)\n",
    "        named_ents += are_there_named_entities(doc)\n",
    "        sentiments += is_there_non_neutral_score(doc)\n",
    "        degrees += are_there_degrees(doc)\n",
    "        \n",
    "    print(f'Percent of sentences with named entities is {named_ents / corpus_len}')\n",
    "    print(f'Percent of sentences with sentiments is {sentiments / corpus_len}')\n",
    "    print(f'Percent of sentences with degrees is {degrees / corpus_len}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of sentences with named entities is 0.0728\n",
      "Percent of sentences with sentiments is 0.3704\n",
      "Percent of sentences with degrees is 0.4984\n"
     ]
    }
   ],
   "source": [
    "get_viral_score(examiner)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
