{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2577,
     "status": "ok",
     "timestamp": 1591629870725,
     "user": {
      "displayName": "Евгений Колодько",
      "photoUrl": "",
      "userId": "06474573143067682315"
     },
     "user_tz": -180
    },
    "id": "nGjS472rSieC",
    "outputId": "18e9de5b-b473-4698-cb84-5361f1f7047a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense, Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Імплементація мережі базується на матеріалах цбого посту:\n",
    "https://medium.com/@dev.elect.iitd/neural-machine-translation-using-word-level-seq2seq-model-47538cba8cd7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A3DcLxTjT8AL"
   },
   "outputs": [],
   "source": [
    "path = '/content/drive/My Drive/opusparcus_v2/en-train-100K.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pga3omAtUDKW"
   },
   "outputs": [],
   "source": [
    "dataset = []\n",
    "with open(path, 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        line = line[:-1]\n",
    "        dataset.append(line.split('\\t'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RvV58PHRUT24"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dataset, columns=['id', 'first', 'second', 'metric_1', 'metric_2', 'metric_3', 'metric_4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 898,
     "status": "ok",
     "timestamp": 1591630022387,
     "user": {
      "displayName": "Евгений Колодько",
      "photoUrl": "",
      "userId": "06474573143067682315"
     },
     "user_tz": -180
    },
    "id": "gUtKOWI6UVpS",
    "outputId": "7c308505-615b-4fe3-fc53-3b245b940fce"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>first</th>\n",
       "      <th>second</th>\n",
       "      <th>metric_1</th>\n",
       "      <th>metric_2</th>\n",
       "      <th>metric_3</th>\n",
       "      <th>metric_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>en-N7</td>\n",
       "      <td>Jumby now wants to be born .</td>\n",
       "      <td>Jumby want birth .</td>\n",
       "      <td>77.5163</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>en-N8</td>\n",
       "      <td>It was a difficult and long delivery .</td>\n",
       "      <td>The delivery was difficult and long .</td>\n",
       "      <td>77.5163</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>en-N12</td>\n",
       "      <td>I like to be beautiful everyday .</td>\n",
       "      <td>I like to be pretty everyday .</td>\n",
       "      <td>77.5163</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>en-N22</td>\n",
       "      <td>Bernadette wants a prenup .</td>\n",
       "      <td>Bernadette wants to get a prenup .</td>\n",
       "      <td>77.5163</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>en-N45</td>\n",
       "      <td>Don 't say you don 't remember me .</td>\n",
       "      <td>Don 't tell me you don 't remember me .</td>\n",
       "      <td>74.3904</td>\n",
       "      <td>3.33333</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                   first  ... metric_3 metric_4\n",
       "0   en-N7            Jumby now wants to be born .  ...        5        9\n",
       "1   en-N8  It was a difficult and long delivery .  ...        5       14\n",
       "2  en-N12       I like to be beautiful everyday .  ...        5        8\n",
       "3  en-N22             Bernadette wants a prenup .  ...        5        7\n",
       "4  en-N45     Don 't say you don 't remember me .  ...        5        7\n",
       "\n",
       "[5 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мабуть, краще було б мати один словник і для декодера, і для енкодера, але було концептуально простіше лишити так"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pCvleuGkXiUp"
   },
   "outputs": [],
   "source": [
    "# Lowercase all characters\n",
    "df['first'] = df['first'].apply(lambda x: x.lower())\n",
    "df['second'] = df['second'].apply(lambda x: x.lower())\n",
    "\n",
    "df['second'] = df['second'].apply(lambda x : 'START_ '+ x + ' _END')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SddseiiEm6k7"
   },
   "outputs": [],
   "source": [
    "# Vocabulary of encoder\n",
    "all_encoder_words=set()\n",
    "for sent in df['first']:\n",
    "    for word in sent.split():\n",
    "        if word not in all_encoder_words:\n",
    "            all_encoder_words.add(word)\n",
    "\n",
    "# Vocabulary of decoder\n",
    "all_decoder_words=set()\n",
    "for sent in df['second']:\n",
    "    for word in sent.split():\n",
    "        if word not in all_decoder_words:\n",
    "            all_decoder_words.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Avoy_ZKHn8Y0"
   },
   "outputs": [],
   "source": [
    "# Max Length of source sequence\n",
    "lenght_list=[]\n",
    "for l in df['first']:\n",
    "    lenght_list.append(len(l.split(' ')))\n",
    "max_length_src = np.max(lenght_list)\n",
    "\n",
    "# Max Length of target sequence\n",
    "lenght_list=[]\n",
    "for l in df['second']:\n",
    "    lenght_list.append(len(l.split(' ')))\n",
    "max_length_tar = np.max(lenght_list)\n",
    "\n",
    "input_words = sorted(list(all_encoder_words))\n",
    "target_words = sorted(list(all_decoder_words))\n",
    "\n",
    "# Calculate Vocab size for both source and target\n",
    "num_encoder_tokens = len(all_encoder_words)\n",
    "num_decoder_tokens = len(all_decoder_words)\n",
    "num_decoder_tokens += 1 # For zero padding\n",
    "\n",
    "# Create word to token dictionary for both source and target\n",
    "input_token_index = dict([(word, i+1) for i, word in enumerate(input_words)])\n",
    "target_token_index = dict([(word, i+1) for i, word in enumerate(target_words)])\n",
    "\n",
    "# Create token to word dictionary for both source and target\n",
    "reverse_input_char_index = dict((i, word) for word, i in input_token_index.items())\n",
    "reverse_target_char_index = dict((i, word) for word, i in target_token_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 981,
     "status": "ok",
     "timestamp": 1591630053170,
     "user": {
      "displayName": "Евгений Колодько",
      "photoUrl": "",
      "userId": "06474573143067682315"
     },
     "user_tz": -180
    },
    "id": "dTFulEhMp_Eu",
    "outputId": "0c90a808-2f54-4f32-9286-d1966051f8a3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['!', '\"', '#', '$', '%', \"'\", \"'a\", \"'aime\", \"'all\", \"'am\"]"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 576,
     "status": "ok",
     "timestamp": 1591630054437,
     "user": {
      "displayName": "Евгений Колодько",
      "photoUrl": "",
      "userId": "06474573143067682315"
     },
     "user_tz": -180
    },
    "id": "Y3Y-474XtTFQ",
    "outputId": "efa76af5-8389-4b4e-8ce0-019eb7d5f311"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>first</th>\n",
       "      <th>second</th>\n",
       "      <th>metric_1</th>\n",
       "      <th>metric_2</th>\n",
       "      <th>metric_3</th>\n",
       "      <th>metric_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>en-N7</td>\n",
       "      <td>jumby now wants to be born .</td>\n",
       "      <td>START_ jumby want birth . _END</td>\n",
       "      <td>77.5163</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>en-N8</td>\n",
       "      <td>it was a difficult and long delivery .</td>\n",
       "      <td>START_ the delivery was difficult and long . _END</td>\n",
       "      <td>77.5163</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>en-N12</td>\n",
       "      <td>i like to be beautiful everyday .</td>\n",
       "      <td>START_ i like to be pretty everyday . _END</td>\n",
       "      <td>77.5163</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>en-N22</td>\n",
       "      <td>bernadette wants a prenup .</td>\n",
       "      <td>START_ bernadette wants to get a prenup . _END</td>\n",
       "      <td>77.5163</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>en-N45</td>\n",
       "      <td>don 't say you don 't remember me .</td>\n",
       "      <td>START_ don 't tell me you don 't remember me ....</td>\n",
       "      <td>74.3904</td>\n",
       "      <td>3.33333</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                   first  ... metric_3 metric_4\n",
       "0   en-N7            jumby now wants to be born .  ...        5        9\n",
       "1   en-N8  it was a difficult and long delivery .  ...        5       14\n",
       "2  en-N12       i like to be beautiful everyday .  ...        5        8\n",
       "3  en-N22             bernadette wants a prenup .  ...        5        7\n",
       "4  en-N45     don 't say you don 't remember me .  ...        5        7\n",
       "\n",
       "[5 rows x 7 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T6JfWb5YtlE3"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1226,
     "status": "ok",
     "timestamp": 1591630062839,
     "user": {
      "displayName": "Евгений Колодько",
      "photoUrl": "",
      "userId": "06474573143067682315"
     },
     "user_tz": -180
    },
    "id": "dEZj1BPqtPuk",
    "outputId": "4396e754-11eb-4333-8f21-9e4ca4f19330"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((90000,), (10000,))"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = df['first'], df['second']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state=42)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1px1QPkOqI99"
   },
   "outputs": [],
   "source": [
    "def generate_batch(X = X_train, y = y_train, batch_size = 128):\n",
    "    ''' Generate a batch of data '''\n",
    "    while True:\n",
    "        for j in range(0, len(X), batch_size):\n",
    "            encoder_input_data = np.zeros((batch_size, max_length_src),dtype='float32')\n",
    "            decoder_input_data = np.zeros((batch_size, max_length_tar),dtype='float32')\n",
    "            decoder_target_data = np.zeros((batch_size, max_length_tar, num_decoder_tokens),dtype='float32')\n",
    "            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n",
    "                for t, word in enumerate(input_text.split()):\n",
    "                    encoder_input_data[i, t] = input_token_index[word] # encoder input seq\n",
    "                for t, word in enumerate(target_text.split()):\n",
    "                    if t<len(target_text.split())-1:\n",
    "                        decoder_input_data[i, t] = target_token_index[word] # decoder input seq\n",
    "                    if t>0:\n",
    "                        # decoder target sequence (one hot encoded)\n",
    "                        # does not include the START_ token\n",
    "                        # Offset by one timestep\n",
    "                        decoder_target_data[i, t - 1, target_token_index[word]] = 1.\n",
    "            yield([encoder_input_data, decoder_input_data], decoder_target_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TOwzRSn9rGeS"
   },
   "outputs": [],
   "source": [
    "latent_dim = 100\n",
    "\n",
    "# Encoder\n",
    "encoder_inputs = Input(shape=(None,))\n",
    "enc_emb =  Embedding(num_encoder_tokens, latent_dim, mask_zero = True)(encoder_inputs)\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
    "\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "dec_emb_layer = Embedding(num_decoder_tokens, latent_dim, mask_zero = True)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=encoder_states)\n",
    "\n",
    "# Use a softmax to generate a probability distribution over the target vocabulary for each time step\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wV84uwo3rqs7"
   },
   "outputs": [],
   "source": [
    "train_samples = len(X_train)\n",
    "val_samples = len(X_test)\n",
    "batch_size = 128\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 901,
     "status": "ok",
     "timestamp": 1591549724629,
     "user": {
      "displayName": "Евгений Колодько",
      "photoUrl": "",
      "userId": "06474573143067682315"
     },
     "user_tz": -180
    },
    "id": "v-iyj7jguikf",
    "outputId": "318e2082-68fc-4a28-a23f-ee19b68457d9"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5699704,
     "status": "ok",
     "timestamp": 1591556214733,
     "user": {
      "displayName": "Евгений Колодько",
      "photoUrl": "",
      "userId": "06474573143067682315"
     },
     "user_tz": -180
    },
    "id": "jFtI9RquuC_P",
    "outputId": "2831d15c-bec9-413b-d464-c94fbb6a807b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "703/703 [==============================] - 194s 276ms/step - loss: 0.6514 - acc: 0.3444 - val_loss: 0.5518 - val_acc: 0.4527\n",
      "Epoch 2/30\n",
      "703/703 [==============================] - 193s 274ms/step - loss: 0.4736 - acc: 0.4956 - val_loss: 0.4355 - val_acc: 0.5255\n",
      "Epoch 3/30\n",
      "703/703 [==============================] - 193s 274ms/step - loss: 0.4076 - acc: 0.5482 - val_loss: 0.3568 - val_acc: 0.5624\n",
      "Epoch 4/30\n",
      "703/703 [==============================] - 192s 273ms/step - loss: 0.3699 - acc: 0.5800 - val_loss: 0.3882 - val_acc: 0.5872\n",
      "Epoch 5/30\n",
      "703/703 [==============================] - 190s 271ms/step - loss: 0.3435 - acc: 0.6048 - val_loss: 0.2998 - val_acc: 0.6072\n",
      "Epoch 6/30\n",
      "703/703 [==============================] - 190s 270ms/step - loss: 0.3238 - acc: 0.6237 - val_loss: 0.3462 - val_acc: 0.6208\n",
      "Epoch 7/30\n",
      "703/703 [==============================] - 189s 269ms/step - loss: 0.3084 - acc: 0.6385 - val_loss: 0.3581 - val_acc: 0.6315\n",
      "Epoch 8/30\n",
      "703/703 [==============================] - 189s 269ms/step - loss: 0.2959 - acc: 0.6502 - val_loss: 0.3127 - val_acc: 0.6400\n",
      "Epoch 9/30\n",
      "703/703 [==============================] - 190s 270ms/step - loss: 0.2859 - acc: 0.6600 - val_loss: 0.2947 - val_acc: 0.6447\n",
      "Epoch 10/30\n",
      "703/703 [==============================] - 190s 270ms/step - loss: 0.2776 - acc: 0.6682 - val_loss: 0.3041 - val_acc: 0.6505\n",
      "Epoch 11/30\n",
      "703/703 [==============================] - 189s 269ms/step - loss: 0.2705 - acc: 0.6754 - val_loss: 0.2563 - val_acc: 0.6547\n",
      "Epoch 12/30\n",
      "703/703 [==============================] - 189s 269ms/step - loss: 0.2642 - acc: 0.6819 - val_loss: 0.2829 - val_acc: 0.6578\n",
      "Epoch 13/30\n",
      "703/703 [==============================] - 189s 269ms/step - loss: 0.2588 - acc: 0.6877 - val_loss: 0.3010 - val_acc: 0.6615\n",
      "Epoch 14/30\n",
      "703/703 [==============================] - 189s 269ms/step - loss: 0.2540 - acc: 0.6931 - val_loss: 0.3122 - val_acc: 0.6627\n",
      "Epoch 15/30\n",
      "703/703 [==============================] - 189s 269ms/step - loss: 0.2495 - acc: 0.6980 - val_loss: 0.2546 - val_acc: 0.6654\n",
      "Epoch 16/30\n",
      "703/703 [==============================] - 189s 269ms/step - loss: 0.2455 - acc: 0.7023 - val_loss: 0.2728 - val_acc: 0.6658\n",
      "Epoch 17/30\n",
      "703/703 [==============================] - 189s 269ms/step - loss: 0.2417 - acc: 0.7065 - val_loss: 0.2981 - val_acc: 0.6682\n",
      "Epoch 18/30\n",
      "703/703 [==============================] - 190s 270ms/step - loss: 0.2380 - acc: 0.7102 - val_loss: 0.2790 - val_acc: 0.6700\n",
      "Epoch 19/30\n",
      "703/703 [==============================] - 189s 269ms/step - loss: 0.2345 - acc: 0.7143 - val_loss: 0.2681 - val_acc: 0.6705\n",
      "Epoch 20/30\n",
      "703/703 [==============================] - 189s 269ms/step - loss: 0.2312 - acc: 0.7179 - val_loss: 0.2441 - val_acc: 0.6713\n",
      "Epoch 21/30\n",
      "703/703 [==============================] - 189s 269ms/step - loss: 0.2281 - acc: 0.7211 - val_loss: 0.3579 - val_acc: 0.6722\n",
      "Epoch 22/30\n",
      "703/703 [==============================] - 188s 268ms/step - loss: 0.2251 - acc: 0.7241 - val_loss: 0.3085 - val_acc: 0.6732\n",
      "Epoch 23/30\n",
      "703/703 [==============================] - 189s 268ms/step - loss: 0.2222 - acc: 0.7272 - val_loss: 0.2555 - val_acc: 0.6743\n",
      "Epoch 24/30\n",
      "703/703 [==============================] - 189s 269ms/step - loss: 0.2194 - acc: 0.7299 - val_loss: 0.3398 - val_acc: 0.6738\n",
      "Epoch 25/30\n",
      "703/703 [==============================] - 189s 269ms/step - loss: 0.2169 - acc: 0.7324 - val_loss: 0.2684 - val_acc: 0.6750\n",
      "Epoch 26/30\n",
      "703/703 [==============================] - 193s 275ms/step - loss: 0.2144 - acc: 0.7351 - val_loss: 0.2731 - val_acc: 0.6755\n",
      "Epoch 27/30\n",
      "703/703 [==============================] - 191s 271ms/step - loss: 0.2120 - acc: 0.7373 - val_loss: 0.2887 - val_acc: 0.6750\n",
      "Epoch 28/30\n",
      "703/703 [==============================] - 189s 269ms/step - loss: 0.2098 - acc: 0.7399 - val_loss: 0.2703 - val_acc: 0.6758\n",
      "Epoch 29/30\n",
      "703/703 [==============================] - 189s 269ms/step - loss: 0.2078 - acc: 0.7421 - val_loss: 0.3299 - val_acc: 0.6753\n",
      "Epoch 30/30\n",
      "703/703 [==============================] - 188s 268ms/step - loss: 0.2058 - acc: 0.7439 - val_loss: 0.2492 - val_acc: 0.6761\n"
     ]
    }
   ],
   "source": [
    "model.fit_generator(generator = generate_batch(X_train, y_train, batch_size = batch_size),\n",
    "                    steps_per_epoch = train_samples//batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_data = generate_batch(X_test, y_test, batch_size = batch_size),\n",
    "                    validation_steps = val_samples//batch_size)\n",
    "model.save_weights('/content/drive/My Drive/opusparcus_v2/model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xhR5zqPui7Mu"
   },
   "outputs": [],
   "source": [
    "model.load_weights('/content/drive/My Drive/opusparcus_v2/model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4-MDJzEmu5Pk"
   },
   "outputs": [],
   "source": [
    "# Encode the input sequence to get the \"thought vectors\"\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "# Decoder setup\n",
    "# Below tensors will hold the states of the previous time step\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "dec_emb2= dec_emb_layer(decoder_inputs) # Get the embeddings of the decoder sequence\n",
    "\n",
    "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
    "decoder_states2 = [state_h2, state_c2]\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2) # A dense softmax layer to generate prob dist. over the target vocabulary\n",
    "\n",
    "# Final decoder model\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs2] + decoder_states2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uMlrSUBSyG6Y"
   },
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0] = target_token_index['START_']\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += ' '+sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '_END' or\n",
    "           len(decoded_sentence) > 50):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kkOWCeUXyY-K"
   },
   "outputs": [],
   "source": [
    "dev_path = '/content/drive/My Drive/opusparcus_v2/en-dev.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OBZazZyZlj1N"
   },
   "outputs": [],
   "source": [
    "dataset = []\n",
    "with open(dev_path, 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        line = line[:-1]\n",
    "        dataset.append(line.split('\\t'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JVgLKAQOm9-5"
   },
   "outputs": [],
   "source": [
    "df_dev = pd.DataFrame(dataset, columns=['id', 'first', 'second', 'score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 889,
     "status": "ok",
     "timestamp": 1591631256217,
     "user": {
      "displayName": "Евгений Колодько",
      "photoUrl": "",
      "userId": "06474573143067682315"
     },
     "user_tz": -180
    },
    "id": "D6muKSflnEX2",
    "outputId": "12dde628-4deb-442f-921a-46440656e9a9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>first</th>\n",
       "      <th>second</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>en-D69</td>\n",
       "      <td>300 heavy horse ?</td>\n",
       "      <td>We have no chance .</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>en-D76</td>\n",
       "      <td>When 'd you last see him ?</td>\n",
       "      <td>When was the last time you saw him ?</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>en-D119</td>\n",
       "      <td>Anyone who can verify that ?</td>\n",
       "      <td>Can anyone corroborate that ?</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>en-D168</td>\n",
       "      <td>I 'm not promising anything .</td>\n",
       "      <td>No promises , okay ?</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>en-D242</td>\n",
       "      <td>Nothing 's changed .</td>\n",
       "      <td>Things ain 't no different .</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  ... score\n",
       "0   en-D69  ...   1.5\n",
       "1   en-D76  ...   4.0\n",
       "2  en-D119  ...   3.5\n",
       "3  en-D168  ...   3.0\n",
       "4  en-D242  ...   3.5\n",
       "\n",
       "[5 rows x 4 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 159
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 882,
     "status": "ok",
     "timestamp": 1591631384529,
     "user": {
      "displayName": "Евгений Колодько",
      "photoUrl": "",
      "userId": "06474573143067682315"
     },
     "user_tz": -180
    },
    "id": "zhYtuGXqn2MB",
    "outputId": "d28ead2d-3664-476a-c666-3d7754d6cfa3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0    409\n",
       "3.5    319\n",
       "3.0    287\n",
       "1.0    213\n",
       "2.5    105\n",
       "2.0     74\n",
       "1.5     48\n",
       "Name: score, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev['score'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yZsX3ixenHtU"
   },
   "outputs": [],
   "source": [
    "df_dev['first'] = df_dev['first'].apply(lambda x: x.lower())\n",
    "df_dev['second'] = df_dev['second'].apply(lambda x: x.lower())\n",
    "\n",
    "df_dev['second'] = df_dev['second'].apply(lambda x : 'START_ '+ x + ' _END')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1043,
     "status": "ok",
     "timestamp": 1591631470028,
     "user": {
      "displayName": "Евгений Колодько",
      "photoUrl": "",
      "userId": "06474573143067682315"
     },
     "user_tz": -180
    },
    "id": "SivYJDaJnxUU",
    "outputId": "9293fea1-cd0c-4aa0-c71d-314199f99ca6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1015, 4)"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev['score'] = df_dev['score'].astype('float')\n",
    "df_dev_good_score = df_dev[df_dev['score']>=3]\n",
    "df_dev_good_score.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FbiJGx_enjCR"
   },
   "outputs": [],
   "source": [
    "X_dev, y_dev = df_dev_good_score['first'], df_dev_good_score['second']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 126
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6893,
     "status": "ok",
     "timestamp": 1591631662041,
     "user": {
      "displayName": "Евгений Колодько",
      "photoUrl": "",
      "userId": "06474573143067682315"
     },
     "user_tz": -180
    },
    "id": "btm1BmTYoTWJ",
    "outputId": "8ecf5dee-88d7-4e8c-e791-9ffdf55acbf3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting py-rouge\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/1d/0bdbaf559fb7afe32308ebc84a2028600988212d7eb7fb9f69c4e829e4a0/py_rouge-1.1-py3-none-any.whl (56kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 1.8MB/s eta 0:00:011\n",
      "\u001b[?25hInstalling collected packages: py-rouge\n",
      "Successfully installed py-rouge-1.1\n"
     ]
    }
   ],
   "source": [
    "! pip install py-rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1NLw49nIobPI"
   },
   "outputs": [],
   "source": [
    "import rouge\n",
    "\n",
    "evaluator = rouge.Rouge(['rouge-l'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eKh6Zj2PqUCd"
   },
   "outputs": [],
   "source": [
    "dev_gen = generate_batch(X_dev, y_dev, batch_size = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аж на цьому етапі я виявив велике упущення: архітектура мережі не була розрахована на невідомі слова) Спочатку я просто ігнорував такі випадки, їх було десь 130 із 1015 у тренувальній вибірці. Потім спробував невідоме слово заміняти просто на перше слово у словнику, це був знак оклику. Ясно, що такий підхід поганий з точки зору моделювання мови, але виявилось таке: я окремо перевіряв, як цей підхід працює на реченнях з невідомими словами і модель все одно генерувала перефразування, іноді навіть влучні. Остаточна якість моделі погіршилась трохи (бо раніше ми погані приклади просто викидали, а зараз генеруємо для них не завжди вдалі перефразування), але я вирішив уже не перенавчати сітку. Я ж правильно розумію, що не вийшло би просто змінити виміри моделі, якось додавши на вхід ще одне слово? Тоді у моделі не було би вивчених вагів для цього слова."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i1-BIbra3B2E"
   },
   "outputs": [],
   "source": [
    "def generate_data_to_inference(X, y, j):\n",
    "    encoder_input_data = np.zeros((1, max_length_src),dtype='float32')\n",
    "    decoder_input_data = np.zeros((1, max_length_tar),dtype='float32')\n",
    "    decoder_target_data = np.zeros((1, max_length_tar, num_decoder_tokens),dtype='float32')\n",
    "    for i, (input_text, target_text) in enumerate(zip(X[j:j+1], y[j:j+1])):\n",
    "        for t, word in enumerate(input_text.split()):\n",
    "            encoder_input_data[i, t] = input_token_index.get(word, 0) # encoder input seq\n",
    "        for t, word in enumerate(target_text.split()):\n",
    "            if t<len(target_text.split())-1:\n",
    "                decoder_input_data[i, t] = target_token_index.get(word,0) # decoder input seq\n",
    "            if t>0:\n",
    "                decoder_target_data[i, t - 1, target_token_index.get(word,0)] = 1.\n",
    "    return(encoder_input_data, decoder_input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7hZO7FijrRzD"
   },
   "outputs": [],
   "source": [
    "k = 128\n",
    "input_seq, actual_output = generate_data_to_inference(X_dev, y_dev, k)\n",
    "decoded_sentence = decode_sequence(input_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 564,
     "status": "ok",
     "timestamp": 1591641154824,
     "user": {
      "displayName": "Евгений Колодько",
      "photoUrl": "",
      "userId": "06474573143067682315"
     },
     "user_tz": -180
    },
    "id": "Yah-omnRrYVB",
    "outputId": "39f5658b-f4cc-4d02-d245-af74a54e75e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input phrase: actually , hum .\n",
      "Actual paraphrase:  as a matter of fact . \n",
      "Predicted parafrase:  in fact , please . \n"
     ]
    }
   ],
   "source": [
    "print('Input phrase:', X_dev[k:k+1].values[0])\n",
    "print('Actual paraphrase:', y_dev[k:k+1].values[0][6:-4])\n",
    "print('Predicted parafrase:', decoded_sentence[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 18930,
     "status": "ok",
     "timestamp": 1591641212138,
     "user": {
      "displayName": "Евгений Колодько",
      "photoUrl": "",
      "userId": "06474573143067682315"
     },
     "user_tz": -180
    },
    "id": "FbVHk605rbOD",
    "outputId": "4ee30ce2-b310-400d-d714-dc323764952e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1015/1015 [00:18<00:00, 55.71it/s]\n"
     ]
    }
   ],
   "source": [
    "paraphrases = []\n",
    "for k in tqdm.tqdm(range(len(X_dev))):\n",
    "    try:\n",
    "        p = {}\n",
    "        input_seq, actual_output = generate_data_to_inference(X_dev, y_dev, k)\n",
    "        decoded_sentence = decode_sequence(input_seq)\n",
    "        p['input_phrase'] = X_dev[k:k+1].values[0]\n",
    "        p['actual_output'] = y_dev[k:k+1].values[0][6:-4]\n",
    "        p['predicted_output'] = decoded_sentence[:-4]\n",
    "        paraphrases.append(p)\n",
    "    except:\n",
    "        print(k)\n",
    "\n",
    "predicted_df = pd.DataFrame(paraphrases)\n",
    "predicted_df.to_csv('/content/drive/My Drive/opusparcus_v2/predicted_df2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i4pwd24-rfNd"
   },
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 918,
     "status": "ok",
     "timestamp": 1591641272662,
     "user": {
      "displayName": "Евгений Колодько",
      "photoUrl": "",
      "userId": "06474573143067682315"
     },
     "user_tz": -180
    },
    "id": "6s-Gnp4QyIwN",
    "outputId": "519d145d-baac-4e1e-c621-6c10c3470d4f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1015, 3)"
      ]
     },
     "execution_count": 136,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1870,
     "status": "ok",
     "timestamp": 1591636151232,
     "user": {
      "displayName": "Евгений Колодько",
      "photoUrl": "",
      "userId": "06474573143067682315"
     },
     "user_tz": -180
    },
    "id": "IwmKt-3c6Aeu",
    "outputId": "c255c14f-3a1d-477d-c4b0-1da115448f4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 106,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Це метрика порахована по 885 реченнях, де використовувались тільки відомі слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1037,
     "status": "ok",
     "timestamp": 1591636157238,
     "user": {
      "displayName": "Евгений Колодько",
      "photoUrl": "",
      "userId": "06474573143067682315"
     },
     "user_tz": -180
    },
    "id": "tv_7NRcCtXqj",
    "outputId": "c1b1230d-f543-41f3-c838-cbb4af1b1e74"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge-l': {'f': 0.43117841243448507,\n",
       "  'p': 0.42363882378837475,\n",
       "  'r': 0.45709475395916044}}"
      ]
     },
     "execution_count": 107,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.get_scores(predicted_df['input_phrase'], predicted_df['predicted_output'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Це вже більш чесна метрика, де так чи інакше оцінюються всі 1015 перефразувань"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1224,
     "status": "ok",
     "timestamp": 1591641303028,
     "user": {
      "displayName": "Евгений Колодько",
      "photoUrl": "",
      "userId": "06474573143067682315"
     },
     "user_tz": -180
    },
    "id": "N84AtIpJNpDP",
    "outputId": "b4091dd6-6118-471e-ad33-2f1a0370df0b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge-l': {'f': 0.4285871993508369,\n",
       "  'p': 0.4211491534962989,\n",
       "  'r': 0.45425614888669064}}"
      ]
     },
     "execution_count": 137,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.get_scores(predicted_df['input_phrase'], predicted_df['predicted_output'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далі ручне анотування перефразувань"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7Ja9djKp5xuK"
   },
   "outputs": [],
   "source": [
    "pred_sample = predicted_df.sample(50, random_state=42).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EfgbKSXn6aUT"
   },
   "outputs": [],
   "source": [
    "pred_sample.to_csv('/content/drive/My Drive/opusparcus_v2/predicted_sample2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2159,
     "status": "ok",
     "timestamp": 1591642164287,
     "user": {
      "displayName": "Евгений Колодько",
      "photoUrl": "",
      "userId": "06474573143067682315"
     },
     "user_tz": -180
    },
    "id": "Yf5udrpZGGmL",
    "outputId": "f1fb0d53-0422-4f07-feaa-2db81f42af71"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48"
      ]
     },
     "execution_count": 141,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_sample_annotated2 = pd.read_csv('/content/drive/My Drive/opusparcus_v2/predicted_sample_annotated2.csv')\n",
    "pred_sample_annotated2['is_good'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 834,
     "status": "ok",
     "timestamp": 1591642249691,
     "user": {
      "displayName": "Евгений Колодько",
      "photoUrl": "",
      "userId": "06474573143067682315"
     },
     "user_tz": -180
    },
    "id": "F8fJLPQtQ-rL",
    "outputId": "2b1031cc-7dbe-4721-e372-317ebd55a044"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_phrase</th>\n",
       "      <th>predicted_output</th>\n",
       "      <th>is_good</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>get on the motherfucking ground .</td>\n",
       "      <td>get the fuck down .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>do you want to give it another shot ?</td>\n",
       "      <td>would you like to try it ?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>everything is about money .</td>\n",
       "      <td>it 's all about money .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>do you want company ?</td>\n",
       "      <td>do you want me to have a seat ?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>shut off that engine .</td>\n",
       "      <td>turn off the engine .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>you 're a scam artist .</td>\n",
       "      <td>you 're a listen to .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>what 's happening over here ?</td>\n",
       "      <td>what 's going on here ?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>you 'll be working over here .</td>\n",
       "      <td>you 're gonna work out here .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>no one should have to die alone .</td>\n",
       "      <td>you can 't die .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>he approached me .</td>\n",
       "      <td>he 's my own .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>eh , life goes on .</td>\n",
       "      <td>'m not long , take .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>and i want a refund .</td>\n",
       "      <td>i want a word .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>if it were only that simple .</td>\n",
       "      <td>if you think you were it gonna be just fine .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>they have to be stopped .</td>\n",
       "      <td>they must have come on .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>hey , wait a minute .</td>\n",
       "      <td>wait a minute , wait .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>the virus ... where is it ?</td>\n",
       "      <td>where is it coming ?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>i ain 't gonna lie , man .</td>\n",
       "      <td>i won 't lie to you .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>and in return ?</td>\n",
       "      <td>how about ?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>i 've got phone calls to make .</td>\n",
       "      <td>i have to make a call .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>come , sweetie .</td>\n",
       "      <td>come on , darling .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>is this some sort of joke ?</td>\n",
       "      <td>what 's this , some kind of joke ?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>coming through .</td>\n",
       "      <td>make it .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>back off , back off .</td>\n",
       "      <td>back right back .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>meaning no disrespect , of course .</td>\n",
       "      <td>no , i 'm not afraid so .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>keep going .</td>\n",
       "      <td>keep your eyes .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>that 's your decision .</td>\n",
       "      <td>you 're up to me .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>none of your business .</td>\n",
       "      <td>that 's none of your business .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>no , i don 't think you understand</td>\n",
       "      <td>you don 't understand .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>and don 't disturb me</td>\n",
       "      <td>i 'm not .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>are you listening ?</td>\n",
       "      <td>you hear me ?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>understand ?</td>\n",
       "      <td>you got that ?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>something i can do for you ?</td>\n",
       "      <td>what can i do for you ?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>now , who was next ?</td>\n",
       "      <td>who 's next ?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>he 's not ... my father .</td>\n",
       "      <td>he 's my father .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>i thought you would have come home sooner .</td>\n",
       "      <td>i 've been looking for you .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>thanks for the warning .</td>\n",
       "      <td>well , thanks for the same .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>hey you where 's your house ?</td>\n",
       "      <td>you 're my house ?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>you ever , uh , do any time ?</td>\n",
       "      <td>you got the time , huh ?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>take good care , sweetheart .</td>\n",
       "      <td>oh , take a good look for you .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>oh , thank god .</td>\n",
       "      <td>thank you , god .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>i 'll see you inside .</td>\n",
       "      <td>see you in the house .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>i return before too long .</td>\n",
       "      <td>i just like you to go in a few days .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>it 's like i 'm not heard .</td>\n",
       "      <td>that 's not my question .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>he gives me the creeps .</td>\n",
       "      <td>he makes me heard of the he would heard of him .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>i need to take my mind off things .</td>\n",
       "      <td>i should get my .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>did you sleep well ?</td>\n",
       "      <td>you sleep okay ?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>i 'm not gonna leave you .</td>\n",
       "      <td>i 'm not leaving you .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>are you in need of anything ?</td>\n",
       "      <td>you need something ?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>do you need any help ?</td>\n",
       "      <td>do you need some help ?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>but you just got here .</td>\n",
       "      <td>but you did it .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   input_phrase  ... is_good\n",
       "0             get on the motherfucking ground .  ...       1\n",
       "1         do you want to give it another shot ?  ...       1\n",
       "2                   everything is about money .  ...       1\n",
       "3                         do you want company ?  ...       1\n",
       "4                        shut off that engine .  ...       0\n",
       "5                       you 're a scam artist .  ...       0\n",
       "6                 what 's happening over here ?  ...       1\n",
       "7                you 'll be working over here .  ...       1\n",
       "8             no one should have to die alone .  ...       0\n",
       "9                            he approached me .  ...       0\n",
       "10                          eh , life goes on .  ...       0\n",
       "11                        and i want a refund .  ...       0\n",
       "12                if it were only that simple .  ...       0\n",
       "13                    they have to be stopped .  ...       0\n",
       "14                        hey , wait a minute .  ...       1\n",
       "15                  the virus ... where is it ?  ...       0\n",
       "16                   i ain 't gonna lie , man .  ...       1\n",
       "17                              and in return ?  ...       0\n",
       "18              i 've got phone calls to make .  ...       1\n",
       "19                             come , sweetie .  ...       1\n",
       "20                  is this some sort of joke ?  ...       1\n",
       "21                             coming through .  ...       0\n",
       "22                        back off , back off .  ...       0\n",
       "23          meaning no disrespect , of course .  ...       0\n",
       "24                                 keep going .  ...       0\n",
       "25                      that 's your decision .  ...       0\n",
       "26                      none of your business .  ...       1\n",
       "27           no , i don 't think you understand  ...       1\n",
       "28                        and don 't disturb me  ...       0\n",
       "29                          are you listening ?  ...       1\n",
       "30                                 understand ?  ...       1\n",
       "31                 something i can do for you ?  ...       1\n",
       "32                         now , who was next ?  ...       1\n",
       "33                    he 's not ... my father .  ...       0\n",
       "34  i thought you would have come home sooner .  ...       0\n",
       "35                     thanks for the warning .  ...       0\n",
       "36                hey you where 's your house ?  ...       0\n",
       "37                you ever , uh , do any time ?  ...       0\n",
       "38                take good care , sweetheart .  ...       0\n",
       "39                             oh , thank god .  ...       1\n",
       "40                       i 'll see you inside .  ...       1\n",
       "41                   i return before too long .  ...       0\n",
       "42                  it 's like i 'm not heard .  ...       0\n",
       "43                     he gives me the creeps .  ...       0\n",
       "44          i need to take my mind off things .  ...       0\n",
       "45                         did you sleep well ?  ...       1\n",
       "46                   i 'm not gonna leave you .  ...       1\n",
       "47                are you in need of anything ?  ...       1\n",
       "48                       do you need any help ?  ...       1\n",
       "49                      but you just got here .  ...       1\n",
       "\n",
       "[50 rows x 3 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_sample_annotated2[['input_phrase', 'predicted_output', 'is_good']].head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RL7EoFymRVYV"
   },
   "source": [
    "По анотованих прикладах такі коментарі:\n",
    "* Мережа пристойно впоралась на недовгих реченнях. Ті, що були довші (на око) перефразувались гірше\n",
    "* Здалось, що мережа гарно вивчила прямі синоніми слів, а також якісь ідеоматичні синоніми або фразові дієслова\n",
    "* іноді мережа гарно перефразовує, але губить заперечення, що змінює весь сенс речення\n",
    "* Хоча начебто схема роботи такої мережі більш-менш зрозуміла, все одно іноді не міг позбутись відчуття \"Чому це взагалі працює і як їй вдається навіть такі перефразування робити?\")\n",
    "* Хоча фреймворки все навчання беруть на себе, треба вміти робити специфічну підготовку даних, якби я зараз сів повторити все з нуля, то точно щось пішло би не по плану"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO16rbYh4d2oHejMx/ya80G",
   "collapsed_sections": [],
   "mount_file_id": "1_e-h4aQk9f5J3mIVQrI5fv42xnyeZyrM",
   "name": "Untitled1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
