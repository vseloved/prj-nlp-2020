{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_json('analyzed_comments.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_rate(r):\n",
    "    if r == 5:\n",
    "        return 1\n",
    "    elif r == 4:\n",
    "        return 0\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "def build_corpus(comments):\n",
    "    X, y = [], []\n",
    "\n",
    "    for _i, comment in comments.iterrows():\n",
    "        if comment['text']:\n",
    "            X.append(comment['text'])\n",
    "            y.append(normalize_rate(comment['rate']))\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = build_corpus(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive:  1051\n",
      "Neutral:  407\n",
      "Negative:  371\n",
      "Total:  1829\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "stats = Counter(y)\n",
    "\n",
    "print('Positive: ', stats[1])\n",
    "print('Neutral: ', stats[0])\n",
    "print('Negative: ', stats[-1])\n",
    "print('Total: ', len(X))\n",
    "\n",
    "len(X) == len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Базове рішення"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def top_features(vectorizer, clf, n):\n",
    "    \"\"\"Prints features with the highest coefficient values, per class\"\"\"\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    for i, class_label in enumerate(clf.classes_):\n",
    "        top = np.argsort(clf.coef_[i])\n",
    "        reversed_top = top[::-1]\n",
    "        print(\"%s: %s\\n\" % (class_label,\n",
    "              ', '.join(feature_names[j] for j in reversed_top[:n])))        \n",
    "\n",
    "def cross_val_report(clf, x, y):\n",
    "    scores = cross_val_score(clf, x, y, cv=5, scoring='f1_macro')\n",
    "    print('Scores: ', scores)\n",
    "    print('Mean: ', scores.mean())\n",
    "\n",
    "def class_report(y_test, y_pred): \n",
    "    target_names = ['Negative', 'Neutral', 'Positive']\n",
    "    print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 779, 0: 306, -1: 286}) Counter({1: 272, 0: 101, -1: 85})\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1789)\n",
    "print(Counter(y_train), Counter(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores:  [0.52360465 0.52999074 0.47845898 0.51672058 0.42563423]\n",
      "Mean:  0.4948818347519178\n"
     ]
    }
   ],
   "source": [
    "vec = CountVectorizer()\n",
    "vec.fit_transform(X_train)\n",
    "X_features = vec.transform(X_train)\n",
    "\n",
    "clf = MultinomialNB()\n",
    "\n",
    "cross_val_report(clf, X_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(X_features, y_train)\n",
    "\n",
    "X_features_test = vec.transform(X_test)\n",
    "y_pred = clf.predict(X_features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 39,   4,  42],\n",
       "       [  8,   5,  88],\n",
       "       [  9,   5, 258]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.70      0.46      0.55        85\n",
      "     Neutral       0.36      0.05      0.09       101\n",
      "    Positive       0.66      0.95      0.78       272\n",
      "\n",
      "    accuracy                           0.66       458\n",
      "   macro avg       0.57      0.49      0.47       458\n",
      "weighted avg       0.60      0.66      0.59       458\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1: не, на, що, але, за, як, це, до, при, так, для, він, працює, по, після, бойлер, та, все, через, дуже\n",
      "\n",
      "0: не, на, що, за, але, для, працює, до, як, та, при, це, добре, все, якщо, дуже, води, так, він, повітря\n",
      "\n",
      "1: на, не, що, дуже, за, працює, для, все, як, та, але, це, швидко, до, повітря, вже, бойлер, зволожувач, води, без\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_features(vec, clf, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Спостереження\n",
    "- Багато false-positive щодо позитивності відгука. Це може відбуватися через те що: 1) в даних є нерівномірний розподіл оцінок (позитивних відгуків набаго більше ніж усіх інших); 2) я визначив, що відугки з оцінкою 4 — нейтральні, та 3 — негативні. Але відгуки з такими оцінками доволі змішані за своїм сентиментом; 3) замала кількість негативних відгуків (286)\n",
    "- Модель погано роспізнає нейтральні відгуки. Категорію нейтрального відгука було важко визначити. Тому очікувано такі нізьки результати"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Балансування классів"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_df = df.sample(frac=1,random_state=4)\n",
    "less_than_five_df = shuffled_df.loc[shuffled_df['rate'] != 5]\n",
    "rate_five_df = shuffled_df.loc[shuffled_df['rate'] == 5].sample(n=500,random_state=1089)\n",
    "normalized_df = pd.concat([rate_five_df, less_than_five_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = build_corpus(normalized_df)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1789)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 353, 0: 309, -1: 273}) Counter({1: 116, -1: 98, 0: 98})\n"
     ]
    }
   ],
   "source": [
    "print(Counter(y_train), Counter(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores:  [0.57327582 0.57043221 0.5688628  0.59140831 0.49135836]\n",
      "Mean:  0.5590674999057608\n"
     ]
    }
   ],
   "source": [
    "vec = CountVectorizer()\n",
    "vec.fit_transform(X_train)\n",
    "X_features = vec.transform(X_train)\n",
    "\n",
    "clf = MultinomialNB()\n",
    "\n",
    "cross_val_report(clf, X_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(vec.transform(X_train), y_train)\n",
    "\n",
    "X_features_test = vec.transform(X_test)\n",
    "y_pred = clf.predict(X_features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[55, 22, 21],\n",
       "       [11, 46, 41],\n",
       "       [11, 38, 67]])"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.71      0.56      0.63        98\n",
      "     Neutral       0.43      0.47      0.45        98\n",
      "    Positive       0.52      0.58      0.55       116\n",
      "\n",
      "    accuracy                           0.54       312\n",
      "   macro avg       0.56      0.54      0.54       312\n",
      "weighted avg       0.55      0.54      0.54       312\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1: не, на, що, як, але, за, це, до, так, при, через, працює, по, він, бойлер, для, після, та, його, все\n",
      "\n",
      "0: не, на, що, за, але, для, до, працює, як, при, це, дуже, та, все, води, добре, вже, коли, по, тому\n",
      "\n",
      "1: на, не, що, дуже, за, працює, для, як, та, це, повітря, все, швидко, бойлер, але, при, до, зволожувач, коли, рекомендую\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_features(vec, clf, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Спостереження\n",
    "- Ситуація дещо покращилась\n",
    "- Близько половини нейтральних відгуків роспізнається як позитивні\n",
    "- Також багато негативних відгуків роспізнається як нейтральні та позитивні (можливо через включення оцінки 3 до негативного классу)\n",
    "- Якщо розподілити відгуки з оцінками 3 і 4 більш точно, то ситуація може покращитись"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Додаткова обробка даних"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 357, 0: 317, -1: 261}) Counter({1: 118, 0: 102, -1: 92})\n"
     ]
    }
   ],
   "source": [
    "def has_positive_tone(text):\n",
    "    if re.search('\\добре|гарний|хороший|чудовий|тихий\\b', text, re.I):\n",
    "        # print('- ' + text)\n",
    "        return True\n",
    "\n",
    "def has_negative_tone(text):\n",
    "    if re.search('не (рекомендую|приємний|гарантійний|раджу|сподобалось)', text, re.I) or \\\n",
    "       re.search('\\bпоганий|bпогана|жахливий|на жаль\\b', text, re.I):\n",
    "        # print('- ' + text)\n",
    "        return True\n",
    "\n",
    "def normalize_rate_v2(comment):\n",
    "    if comment['rate'] == 5:\n",
    "        return 1\n",
    "    elif comment['rate'] == 3 or comment['rate'] == 4:\n",
    "        if has_negative_tone(comment['text']):\n",
    "            return 1\n",
    "        elif has_positive_tone(comment['text']):\n",
    "            return -1\n",
    "        else:\n",
    "            return 0\n",
    "    else:\n",
    "        return -1\n",
    "        \n",
    "X, y = [], []\n",
    "\n",
    "for _i, comment in normalized_df.iterrows():\n",
    "    if comment['text']:\n",
    "        X.append(comment['text'])\n",
    "        y.append(normalize_rate_v2(comment))\n",
    "        \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1789)\n",
    "\n",
    "print(Counter(y_train), Counter(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores:  [0.52288186 0.52702742 0.54819728 0.5314509  0.50912945]\n",
      "Mean:  0.527737382709492\n"
     ]
    }
   ],
   "source": [
    "vec = CountVectorizer()\n",
    "vec.fit_transform(X_train)\n",
    "X_features = vec.transform(X_train)\n",
    "\n",
    "clf = MultinomialNB()\n",
    "\n",
    "cross_val_report(clf, X_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(vec.transform(X_train), y_train)\n",
    "\n",
    "X_features_test = vec.transform(X_test)\n",
    "y_pred = clf.predict(X_features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[45, 16, 31],\n",
       "       [24, 40, 38],\n",
       "       [16, 30, 72]])"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.53      0.49      0.51        92\n",
      "     Neutral       0.47      0.39      0.43       102\n",
      "    Positive       0.51      0.61      0.56       118\n",
      "\n",
      "    accuracy                           0.50       312\n",
      "   macro avg       0.50      0.50      0.50       312\n",
      "weighted avg       0.50      0.50      0.50       312\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Спостереження\n",
    "\n",
    "- Розподілення неоднозначних відгуків за правилами спрацювало гірше ніж я очікував.\n",
    "- Негативні відгуки стали гірше розпізнаватись, та збільшилсь їх false-positive частка. Мабуть бо їх стало менше.\n",
    "- Нейтальні відгуки стали рідше відзначатися (бо їх стало меньше)\n",
    "- Позитивні відгуки стали розпізнаватись краще.\n",
    "- За f_macro зміни погіршили точність моделі"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Біграми"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores:  [0.55390983 0.5292769  0.49184329 0.5067558  0.44769504]\n",
      "Mean:  0.5058961702852095\n"
     ]
    }
   ],
   "source": [
    "X, y = build_corpus(normalized_df)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1789)\n",
    "\n",
    "vec = CountVectorizer(ngram_range=(2, 2))\n",
    "vec.fit_transform(X_train)\n",
    "X_features = vec.transform(X_train)\n",
    "\n",
    "clf = MultinomialNB()\n",
    "\n",
    "cross_val_report(clf, X_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(vec.transform(X_train), y_train)\n",
    "\n",
    "X_features_test = vec.transform(X_test)\n",
    "y_pred = clf.predict(X_features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[51, 27, 20],\n",
       "       [15, 39, 44],\n",
       "       [ 7, 34, 75]])"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.70      0.52      0.60        98\n",
      "     Neutral       0.39      0.40      0.39        98\n",
      "    Positive       0.54      0.65      0.59       116\n",
      "\n",
      "    accuracy                           0.53       312\n",
      "   macro avg       0.54      0.52      0.53       312\n",
      "weighted avg       0.54      0.53      0.53       312\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1: не рекомендую, не працює, так як, він не, це не, тому що, те що, не знаю, не раджу, сказав що, до цього, так що, нічого не, не було, його не, як на, пів року, не так, будь ласка, гарантійний талон\n",
      "\n",
      "0: так як, поки що, за таку, не було, таку ціну, він не, працює тихо, не дуже, те що, тому що, але це, працює добре, на стіну, ціна якість, свою ціну, гарантійний талон, працює вже, це не, що не, даний момент\n",
      "\n",
      "1: те що, під час, досить швидко, так як, за таку, поки що, дуже зручно, сказати що, хороший бойлер, гарячої води, все працює, працює на, працює тихо, не було, свої гроші, що це, таку ціну, дуже задоволена, своїх грошей, працює добре\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_features(vec, clf, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Спостереження\n",
    "\n",
    "Використання біграм зменшило якість розпізнавання нейтральни та негативних відгуків"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Леми"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stanza\n",
    "nlp = stanza.Pipeline(lang='uk', processors='tokenize,mwt,pos,lemma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemma_tokenizer(text):\n",
    "    doc = nlp(text)\n",
    "    return [w.lemma for s in doc.sentences for w in s.words]\n",
    "\n",
    "vec = CountVectorizer(tokenizer=lemma_tokenizer)\n",
    "vec.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stanza виявилась дуууже повільною"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tokenize_uk\n",
    "import pymorphy2\n",
    "import re\n",
    "\n",
    "morph = pymorphy2.MorphAnalyzer(lang='uk')\n",
    "\n",
    "\n",
    "def lemma_tokenizer_v2(text):\n",
    "    tokens = tokenize_uk.tokenize_uk.tokenize_words(text)\n",
    "    return [morph.parse(t)[0].normal_form for t in tokens if t.isalpha()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores:  [0.56140285 0.56368788 0.54405514 0.5791593  0.50381395]\n",
      "Mean:  0.5504238240015236\n"
     ]
    }
   ],
   "source": [
    "vec = CountVectorizer(tokenizer=lemma_tokenizer_v2)\n",
    "vec.fit_transform(X_train)\n",
    "\n",
    "X_features = vec.transform(X_train)\n",
    "\n",
    "clf = MultinomialNB()\n",
    "\n",
    "cross_val_report(clf, X_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = CountVectorizer(tokenizer=lemma_tokenizer_v2)\n",
    "vec.fit_transform(X_train)\n",
    "\n",
    "X_features = vec.transform(X_train)\n",
    "\n",
    "clf.fit(vec.transform(X_train), y_train)\n",
    "\n",
    "X_features_test = vec.transform(X_test)\n",
    "y_pred = clf.predict(X_features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[58, 23, 17],\n",
       "       [14, 43, 41],\n",
       "       [ 9, 30, 77]])"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.72      0.59      0.65        98\n",
      "     Neutral       0.45      0.44      0.44        98\n",
      "    Positive       0.57      0.66      0.61       116\n",
      "\n",
      "    accuracy                           0.57       312\n",
      "   macro avg       0.58      0.56      0.57       312\n",
      "weighted avg       0.58      0.57      0.57       312\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1: не, на, в, і, що, вода, бути, з, він, як, але, працювати, за, а, у, цей, бойлер, це, до, так\n",
      "\n",
      "0: не, на, і, в, що, бути, з, за, але, вода, для, працювати, до, у, а, весь, температура, кімната, як, перти\n",
      "\n",
      "1: і, в, на, не, бути, що, з, дуже, працювати, за, вода, у, весь, бойлер, як, задоволений, для, та, це, повітря\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_features(vec, clf, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Спостереження\n",
    "\n",
    "- Використання лем трохи зменшило кільксть false-positive для усіх классів"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Леми + біграми"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores:  [0.49977632 0.56007659 0.53709075 0.52988215 0.43768312]\n",
      "Mean:  0.5129017880732315\n"
     ]
    }
   ],
   "source": [
    "vec = CountVectorizer(ngram_range=(2, 2), tokenizer=lemma_tokenizer_v2)\n",
    "vec.fit_transform(X_train)\n",
    "\n",
    "X_features = vec.transform(X_train)\n",
    "\n",
    "clf = MultinomialNB()\n",
    "\n",
    "cross_val_report(clf, X_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = CountVectorizer(ngram_range=(2, 2), tokenizer=lemma_tokenizer_v2)\n",
    "vec.fit_transform(X_train)\n",
    "\n",
    "X_features = vec.transform(X_train)\n",
    "\n",
    "clf.fit(vec.transform(X_train), y_train)\n",
    "\n",
    "X_features_test = vec.transform(X_test)\n",
    "y_pred = clf.predict(X_features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[51, 26, 21],\n",
       "       [19, 32, 47],\n",
       "       [10, 35, 71]])"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.64      0.52      0.57        98\n",
      "     Neutral       0.34      0.33      0.34        98\n",
      "    Positive       0.51      0.61      0.56       116\n",
      "\n",
      "    accuracy                           0.49       312\n",
      "   macro avg       0.50      0.49      0.49       312\n",
      "weighted avg       0.50      0.49      0.49       312\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1: не рекомендувати, не працювати, в кімната, що в, так як, він не, той що, і не, сказати що, кв м, в мен, в цей, так і, я не, том що, не знати, гарантійний талон, це не, гарячий вода, сервісний центр\n",
      "\n",
      "0: за такий, так як, в кімната, і не, поки що, не бути, за свій, такий ціна, він не, кв м, той що, працювати тихо, що бути, в комплект, не дуже, на стіна, вода в, працювати добре, том що, в інший\n",
      "\n",
      "1: той що, в кімната, кв м, дуже задоволений, під час, гарячий вода, за такий, сказати що, у ми, досить швидко, не бути, і не, в квартира, так як, поки що, у мен, дуже сподобатися, задоволений покупка, дуже зручно, не мати\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_features(vec, clf, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Спостереження\n",
    "\n",
    "- Використання біграм + лем зменшило якість розпізнавання негативних та нейтральних классів"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
