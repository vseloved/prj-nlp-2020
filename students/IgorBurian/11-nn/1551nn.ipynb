{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plan\n",
    "# [x] load doc vectors\n",
    "# [x] create FFNN\n",
    "# [x] load word vectors\n",
    "# [x] create LSTM\n",
    "# [ ] write report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data\n",
    "\n",
    "import pickle\n",
    "\n",
    "def load_data(name):\n",
    "    with open('{}.pickle'.format(name), 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "    \n",
    "dataset = load_data('cleaned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset.data, dataset.target, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit_transform(y_train)\n",
    "\n",
    "y_train_enc = le.transform(y_train)\n",
    "y_test_enc = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "VEC_SIZE = 300\n",
    "NUM_CLASS = len(le.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FFNN + doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get doc vectors\n",
    "\n",
    "from gensim.models.doc2vec import TaggedDocument, Doc2Vec\n",
    "\n",
    "X_doc_train = [TaggedDocument(words=words, tags=[str(i)])\n",
    "               for i, words in enumerate(X_train)]\n",
    "\n",
    "X_doc_test = [TaggedDocument(words=words, tags=[str(i)])\n",
    "              for i, words in enumerate(X_test)]\n",
    "\n",
    "model = Doc2Vec(dm=1, vector_size=VEC_SIZE, min_count=5, window=10, workers=4, epochs=100)\n",
    "model.build_vocab(X_doc_train)\n",
    "model.train(X_doc_train, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "\n",
    "X_train_vec = np.array([model.infer_vector(doc.words) for doc in X_doc_train])\n",
    "X_test_vec = np.array([model.infer_vector(doc.words) for doc in X_doc_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x112b162d0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.nn.functional import relu\n",
    "\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loss, train_data, train_target, epochs = 1):    \n",
    "    for n in range(1, epochs + 1, 1):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        train_output = model(train_data)\n",
    "        \n",
    "        train_error = loss(train_output, train_target)\n",
    "        train_error.backward()\n",
    "        \n",
    "        if n % 50 == 0 or n == 1 or n == epochs:\n",
    "            print(\"Step = {}/{} Error = {}\".format(n, epochs, train_error.item()))\n",
    "        \n",
    "        optimizer.step()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model\n",
    "\n",
    "class FFNN(nn.Module):\n",
    "    def __init__(self, input_size, num_class):\n",
    "        super(FFNN, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, 128)\n",
    "        self.linear2 = nn.Linear(128, 64)\n",
    "        self.linear3 = nn.Linear(64, num_class)\n",
    "        \n",
    "        nn.init.xavier_normal_(self.linear1.weight)\n",
    "        nn.init.xavier_normal_(self.linear2.weight)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm1d(128, track_running_stats=False)\n",
    "        self.bn2 = nn.BatchNorm1d(64, track_running_stats=False)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = relu(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = relu(x)\n",
    "        x = self.linear3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data\n",
    "\n",
    "train_data = torch.from_numpy(X_train_vec)\n",
    "train_target = torch.from_numpy(y_train_enc)\n",
    "test_data = torch.from_numpy(X_test_vec)\n",
    "test_target = torch.from_numpy(y_test_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step = 1/100 Error = 5.4134063720703125\n",
      "Step = 50/100 Error = 1.8324609994888306\n",
      "Step = 100/100 Error = 1.0295368432998657\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "\n",
    "model = FFNN(VEC_SIZE, NUM_CLASS)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.2, momentum=0.9)\n",
    "lr = 0.01 # 3e-4\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "model = train(model, loss, train_data, train_target, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "      <th>200</th>\n",
       "      <th>201</th>\n",
       "      <th>202</th>\n",
       "      <th>203</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.154472</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.377049</td>\n",
       "      <td>0.108911</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.186047</td>\n",
       "      <td>0.418269</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.197802</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.361506</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>0.346951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.159664</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.305310</td>\n",
       "      <td>0.139241</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.426471</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.236364</td>\n",
       "      <td>0.080645</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.361506</td>\n",
       "      <td>0.190774</td>\n",
       "      <td>0.361506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.157025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.337408</td>\n",
       "      <td>0.122222</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.150943</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.213333</td>\n",
       "      <td>0.422330</td>\n",
       "      <td>...</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>0.205714</td>\n",
       "      <td>0.247619</td>\n",
       "      <td>0.101010</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.097561</td>\n",
       "      <td>0.361506</td>\n",
       "      <td>0.199573</td>\n",
       "      <td>0.347858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>119.000000</td>\n",
       "      <td>14.0</td>\n",
       "      <td>226.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>204.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.361506</td>\n",
       "      <td>20824.000000</td>\n",
       "      <td>20824.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 207 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0     1           2          3          4          5  \\\n",
       "precision    0.154472   0.0    0.377049   0.108911   0.181818   0.178571   \n",
       "recall       0.159664   0.0    0.305310   0.139241   0.166667   0.227273   \n",
       "f1-score     0.157025   0.0    0.337408   0.122222   0.173913   0.200000   \n",
       "support    119.000000  14.0  226.000000  79.000000  24.000000  22.000000   \n",
       "\n",
       "                   6          7          8           9  ...        197  \\\n",
       "precision   0.190476   0.250000   0.186047    0.418269  ...   0.100000   \n",
       "recall      0.125000   0.111111   0.250000    0.426471  ...   0.034483   \n",
       "f1-score    0.150943   0.153846   0.213333    0.422330  ...   0.051282   \n",
       "support    32.000000  18.000000  32.000000  204.000000  ...  29.000000   \n",
       "\n",
       "                 198        199         200        201        202        203  \\\n",
       "precision   0.076923   0.197802    0.260000   0.135135   0.263158   0.105263   \n",
       "recall      0.045455   0.214286    0.236364   0.080645   0.238095   0.090909   \n",
       "f1-score    0.057143   0.205714    0.247619   0.101010   0.250000   0.097561   \n",
       "support    22.000000  84.000000  220.000000  62.000000  21.000000  22.000000   \n",
       "\n",
       "           accuracy     macro avg  weighted avg  \n",
       "precision  0.361506      0.227509      0.346951  \n",
       "recall     0.361506      0.190774      0.361506  \n",
       "f1-score   0.361506      0.199573      0.347858  \n",
       "support    0.361506  20824.000000  20824.000000  \n",
       "\n",
       "[4 rows x 207 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print report\n",
    "\n",
    "y_pred = model(test_data)\n",
    "y_pred = torch.max(y_pred, 1).indices\n",
    "\n",
    "pd.DataFrame(classification_report(test_target, y_pred, output_dict=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM + word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('/tmp/uk_vectors')\n",
    "\n",
    "def vec(text):\n",
    "    return nlp(text)[0].vector\n",
    "\n",
    "def vectorize(tokens):\n",
    "    v = vec('unk')\n",
    "    \n",
    "    for t in tokens:        \n",
    "        v += vec(t)\n",
    "            \n",
    "    v /= len(tokens)\n",
    "\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get word vectors\n",
    "\n",
    "X_train_vec = np.vstack(X_train.apply(vectorize))\n",
    "X_test_vec = np.vstack(X_test.apply(vectorize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build lstm model\n",
    "\n",
    "class LSTM(torch.nn.Module) :\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, vec_weights, classes) :\n",
    "        super().__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.embeddings.weight.data.copy_(vec_weights)\n",
    "        self.embeddings.weight.requires_grad = False ## freeze embeddings\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_dim, classes)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embeddings(x)\n",
    "        x = self.dropout(x)\n",
    "        lstm_out, (ht, ct) = self.lstm(x)\n",
    "        return self.linear(ht[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data\n",
    "\n",
    "train_data = torch.from_numpy(X_train_vec)\n",
    "train_target = torch.from_numpy(y_train_enc)\n",
    "test_data = torch.from_numpy(X_test_vec)\n",
    "test_target = torch.from_numpy(y_test_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "\n",
    "n_vocab, vocab_dim = nlp.vocab.vectors.shape\n",
    "weights = torch.from_numpy(nlp.vocab.vectors.data)\n",
    "\n",
    "model = LSTM(n_vocab, vocab_dim, 256, weights, NUM_CLASS)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.2, momentum=0.9)\n",
    "lr = 0.01 # 3e-4\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "model = train(model, loss, train_data, train_target, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "      <th>200</th>\n",
       "      <th>201</th>\n",
       "      <th>202</th>\n",
       "      <th>203</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.154472</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.377049</td>\n",
       "      <td>0.108911</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.186047</td>\n",
       "      <td>0.418269</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.197802</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.361506</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>0.346951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.159664</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.305310</td>\n",
       "      <td>0.139241</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.426471</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.236364</td>\n",
       "      <td>0.080645</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.361506</td>\n",
       "      <td>0.190774</td>\n",
       "      <td>0.361506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.157025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.337408</td>\n",
       "      <td>0.122222</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.150943</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.213333</td>\n",
       "      <td>0.422330</td>\n",
       "      <td>...</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>0.205714</td>\n",
       "      <td>0.247619</td>\n",
       "      <td>0.101010</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.097561</td>\n",
       "      <td>0.361506</td>\n",
       "      <td>0.199573</td>\n",
       "      <td>0.347858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>119.000000</td>\n",
       "      <td>14.0</td>\n",
       "      <td>226.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>204.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.361506</td>\n",
       "      <td>20824.000000</td>\n",
       "      <td>20824.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 207 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0     1           2          3          4          5  \\\n",
       "precision    0.154472   0.0    0.377049   0.108911   0.181818   0.178571   \n",
       "recall       0.159664   0.0    0.305310   0.139241   0.166667   0.227273   \n",
       "f1-score     0.157025   0.0    0.337408   0.122222   0.173913   0.200000   \n",
       "support    119.000000  14.0  226.000000  79.000000  24.000000  22.000000   \n",
       "\n",
       "                   6          7          8           9  ...        197  \\\n",
       "precision   0.190476   0.250000   0.186047    0.418269  ...   0.100000   \n",
       "recall      0.125000   0.111111   0.250000    0.426471  ...   0.034483   \n",
       "f1-score    0.150943   0.153846   0.213333    0.422330  ...   0.051282   \n",
       "support    32.000000  18.000000  32.000000  204.000000  ...  29.000000   \n",
       "\n",
       "                 198        199         200        201        202        203  \\\n",
       "precision   0.076923   0.197802    0.260000   0.135135   0.263158   0.105263   \n",
       "recall      0.045455   0.214286    0.236364   0.080645   0.238095   0.090909   \n",
       "f1-score    0.057143   0.205714    0.247619   0.101010   0.250000   0.097561   \n",
       "support    22.000000  84.000000  220.000000  62.000000  21.000000  22.000000   \n",
       "\n",
       "           accuracy     macro avg  weighted avg  \n",
       "precision  0.361506      0.227509      0.346951  \n",
       "recall     0.361506      0.190774      0.361506  \n",
       "f1-score   0.361506      0.199573      0.347858  \n",
       "support    0.361506  20824.000000  20824.000000  \n",
       "\n",
       "[4 rows x 207 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print report\n",
    "\n",
    "y_pred = model(test_data)\n",
    "y_pred = torch.max(y_pred, 1).indices\n",
    "\n",
    "pd.DataFrame(classification_report(test_target, y_pred, output_dict=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
