{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import ast\n",
    "import spacy\n",
    "import wikipedia\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SPARQLWrapper import SPARQLWrapper, JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(array):\n",
    "    for item in array:\n",
    "        if isinstance(item, list):\n",
    "            yield from flatten(item)\n",
    "        else:\n",
    "            yield item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparql data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "query1 = \"\"\"\n",
    "PREFIX dbo: <http://dbpedia.org/ontology/>\n",
    "\n",
    "SELECT ?film ?year ?budget\n",
    "WHERE {\n",
    "?film rdf:type dbo:Film .\n",
    "?film dbo:director dbr:Christopher_Nolan .\n",
    "OPTIONAL {?film dct:subject ?year FILTER (regex (?year, \"\\\\d+_films\"))} .\n",
    "OPTIONAL {?film dbo:budget ?budget .}\n",
    "}\n",
    "\"\"\"\n",
    "# query2 = \"\"\"\n",
    "# PREFIX dbo: <http://dbpedia.org/ontology/>\n",
    "\n",
    "# SELECT ?film\n",
    "# WHERE {\n",
    "# ?film rdf:type dbo:Film .\n",
    "# ?film dbo:director dbr:Christopher_Nolan .\n",
    "# }\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "query works in sparql, but fails here, so I extracted data to xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sparql = SPARQLWrapper(\"http://dbpedia.org/sparql\")\n",
    "# sparql.setQuery(query)\n",
    "# sparql.setReturnFormat(JSON)\n",
    "# results = sparql.query().convert()\n",
    "\n",
    "# sparql_data = pd.DataFrame(\n",
    "#     [item[\"film\"][\"value\"].rsplit(\"/\", 1)[1] for item in results[\"results\"][\"bindings\"]], columns=[\"Films\"]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparql_data = pd.read_excel('sparql_data.xlsx')\n",
    "sparql_data['film'] = sparql_data['film'].map(lambda x: re.sub(\"[(].*[)]\", \" \", x.rsplit(\"/\", 1)[1]).replace(\"_\", \" \").strip())\n",
    "sparql_data['year'] = sparql_data['year'].fillna(\" \").map(lambda x: list(reversed(x.rsplit(\":\", 1)))[0].replace(\"_films\", \"\"))\n",
    "sparql_data['budget'] = sparql_data['budget'].fillna(\"0\").map(lambda x: ast.literal_eval(x.split(\"^\")[0].replace('\"', '')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>film</th>\n",
       "      <th>year</th>\n",
       "      <th>budget</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Prestige</td>\n",
       "      <td>2006</td>\n",
       "      <td>40000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Doodlebug</td>\n",
       "      <td>1997</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Insomnia</td>\n",
       "      <td>2002</td>\n",
       "      <td>46000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Interstellar</td>\n",
       "      <td>2014</td>\n",
       "      <td>165000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>2008</td>\n",
       "      <td>185000000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              film  year       budget\n",
       "0     The Prestige  2006   40000000.0\n",
       "1        Doodlebug  1997       1000.0\n",
       "2         Insomnia  2002   46000000.0\n",
       "3     Interstellar  2014  165000000.0\n",
       "4  The Dark Knight  2008  185000000.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparql_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wiki data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikipedia.set_lang(\"en\")\n",
    "wiki_page = wikipedia.page(\"Christopher_Nolan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cut the list of filmography to make sure it will not appear in plain text\n",
    "content = wiki_page.content.split('== Filmography and awards ==')\n",
    "wiki_text = content[0]\n",
    "# wiki_data = content[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraphs = [re.sub(r\"[=]+.+?[=]+\", \" \", paragraph).replace(\"\\n\", \" \").strip()\n",
    "              for paragraph in wiki_text.split(\"\\n\\n\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraphs = list(filter(None, paragraphs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(paragraphs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_budget(page):\n",
    "    try:\n",
    "        wiki_page = wikipedia.page(page)\n",
    "    except wikipedia.DisambiguationError as e:\n",
    "        page = list(filter(lambda x: \"film\" in x, e.options))\n",
    "        if len(page) > 0:\n",
    "            page = page[0]\n",
    "            wiki_page = wikipedia.page(page)\n",
    "        else:\n",
    "            return ''\n",
    "    except wikipedia.PageError:\n",
    "        return ''\n",
    "        \n",
    "    res = 0\n",
    "    for sentence in nlp(wiki_page.content).sents:\n",
    "        if re.search('budget', str(sentence)):\n",
    "            res = \" \".join([token.text for token in sentence if token.pos_ == 'NUM'])\n",
    "            break\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "core_verbs = ['release', 'work', 'premiere', 'direct', 'film', 'produce', 'announce']\n",
    "filter_words = ['Nolan', 'Warner Bros.', 'English', \n",
    "                'January', 'February', 'March', 'April', 'May',\n",
    "                'June', 'July', 'August', 'September', 'October', 'November', 'December']\n",
    "res = []\n",
    "\n",
    "for paragraph in paragraphs:\n",
    "#     paragraph = paragraph.lower()\n",
    "    doc = nlp(paragraph)\n",
    "    for sentence in doc.sents:\n",
    "        verbs = [(token.lemma_, [word for word in token.children \n",
    "                                 if str(word).strip()[0].isupper() and nlp(str(word))[0].pos_ == 'NOUN']) \n",
    "                 for token in sentence \n",
    "                 if token.pos_ == \"VERB\" and token.lemma_ in core_verbs]\n",
    "        nums = [(token.text, [word.lemma_ for word in token.ancestors]) \n",
    "                 for token in sentence \n",
    "                 if token.pos_ == \"NUM\" and str(token.text).isdigit() and len(str(token.text)) == 4]\n",
    "        if len(verbs) > 0 and len(nums) == 1:\n",
    "            nums = list(nums[0])\n",
    "            nums[1] = list(flatten([dict(verbs).get(item, item) for item in nums[1]])) + sentence.ents\n",
    "            nums[1] = [str(word) for word in nums[1] if str(word).strip()[0].isupper()]\n",
    "            nums[1] = [word for word in nums[1] if nlp(str(word).lower())[0].pos_ in ('NOUN', 'PROPN')]\n",
    "            nums[1] = set(filter(lambda x: not any([word in x for word in filter_words]), nums[1]))\n",
    "            # TODO: filter whether it is a person name or not\n",
    "#             nums = {nums[0]: list(nums[1])}\n",
    "            if len(nums[1]) > 0:\n",
    "                for item in nums[1]:\n",
    "                    res.append({\"year\": nums[0], \"film\": item})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_films = pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dima/anaconda3/envs/p36/lib/python3.6/site-packages/wikipedia/wikipedia.py:389: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file /home/dima/anaconda3/envs/p36/lib/python3.6/site-packages/wikipedia/wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 32 s, sys: 2.8 s, total: 34.8 s\n",
      "Wall time: 1min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "parsed_films['budget'] = parsed_films['film'].map(get_budget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = set(sparql_data.film.unique())\n",
    "preds = set(parsed_films.film.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = set(target).intersection(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "FN = target - preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "FP = preds - TP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13333333333333333"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision = len(TP) / (len(TP) + len(FP))\n",
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46153846153846156"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recal = len(TP) / (len(TP) + len(FN))\n",
    "recal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20689655172413796"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_score = 2*precision*recal /(precision + recal)\n",
    "f_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:p36] *",
   "language": "python",
   "name": "conda-env-p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
