{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from IPython.display import display, Markdown, Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPO_PATH = os.path.dirname(os.path.dirname(os.path.dirname(os.getcwd())))\n",
    "TASK_PATH = os.path.join(REPO_PATH, \"tasks\", \"09-textual-entailment.md\")\n",
    "DATA_PATH = '/home/dima/Projects/snli_1.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_markdown(path):\n",
    "    with open(path, 'r') as fh:\n",
    "        content = fh.read()\n",
    "    display(Markdown(content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Логічне слідування\n",
       "\n",
       "## Завдання\n",
       "\n",
       "Розробіть класифікатор, який приймає на вхід текст та гіпотезу і визначає зв'язок між ними за трьома класами:\n",
       "- entailment (гіпотеза логічно слідує з тексту)\n",
       "- contradiction (гіпотеза суперечить тексту)\n",
       "- neutral (гіпотеза і текст не пов'язані)\n",
       "\n",
       "Побудуйте базове рішення та ітеративно покращуйте його, додаючи ознаки. Обов'язково випробуйте ознаки лексичної, граматичної та семантичної схожості:\n",
       "* До ознак *лексичної схожості* належить частка сутностей, слів, енграмів, іменників, дієслів, числівників тощо, які перетинаються в тексті та гіпотезі. Спробуйте лематизацію чи стемінг, опрацюйте заперечення, нормалізуйте дані.\n",
       "* До ознак *граматичної схожості* належить частка синтаксичних структур чи залежностей, які перетинаються в тексті та гіпотезі. Спробуйте або дерева складників, або дерева залежностей, або і те, і друге.\n",
       "* До ознак *семантичної схожості* належить:\n",
       "  1. Наявність лексико-семантичних зв'язків між словами в тексті та в гіпотезі. Спробуйте виявити наявність синонімів, антонімів, гіперонімів, гіпонімів, пов'язаних слів, логічного слідування тощо. Ви можете використати будь-яку онтологію ([WordNet](https://wordnet.princeton.edu/), [ConceptNet](http://conceptnet.io/), [BabelNet](https://babelnet.org/) тощо) та будь-яку бібліотеку для роботи з нею.\n",
       "  2. *[Опційно]* Схожість семантичних ролей в тексті та гіпотезі. Спробуйте готові рішення для маркування семантичних ролей у тексті та гіпотезі (наприклад, [AllenNLP SRL](https://github.com/masrb/allenNLP-SRL) чи [AMR Eager](https://cohort.inf.ed.ac.uk/amreager.html)).\n",
       "\n",
       "Корисні статті, у яких можна підглянути ознаки:\n",
       "- [Feature Analysis for Paraphrase Recognition and Textual Entailment](https://pdfs.semanticscholar.org/2d7d/f0b5ac15cdaa50928031f5bb2fc63a0a1f68.pdf), 2013\n",
       "- [Machine Learning Experiments for Textual Entailment](http://u.cs.biu.ac.il/~nlp/RTE2/Proceedings/02.pdf), 2006\n",
       "- [A large annotated corpus for learning natural language inference](https://nlp.stanford.edu/pubs/snli_paper.pdf), 2015\n",
       "- [Learning to recognize features of valid textual entailments](https://nlp.stanford.edu/pubs/rte-naacl06.pdf), 2006\n",
       "- [Textual entailment](http://www.lsi.upc.edu/~ageno/anlp/textualEntailment.pdf), 2014\n",
       "\n",
       "Для тренування та тестування використайте **train** та **dev** частини з [The Stanford Natural Language Inference (SNLI) Corpus](https://nlp.stanford.edu/projects/snli/). Протестуйте фінальне рішення на **test**-частині корпусу.\n",
       "\n",
       "Запишіть ваші спостереження та результати в окремий файл.\n",
       "\n",
       "## Оцінювання\n",
       "\n",
       "100% за завдання.\n",
       "\n",
       "## Крайній термін\n",
       "\n",
       "09.05.2020\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_markdown(TASK_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(549367, 3) (9842, 3) (9824, 3)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(os.path.join(DATA_PATH, \"snli_1.0_train.txt\"), sep='\\t')\n",
    "dev = pd.read_csv(os.path.join(DATA_PATH, \"snli_1.0_dev.txt\"), sep='\\t')\n",
    "test = pd.read_csv(os.path.join(DATA_PATH, \"snli_1.0_test.txt\"), sep='\\t')\n",
    "\n",
    "columns_old = ['sentence1', 'sentence2', 'gold_label']\n",
    "columns_new = ['premise', 'hypothesis', 'target']\n",
    "name_mapping = dict(zip(columns_old, columns_new))\n",
    "\n",
    "train = train.loc[train.gold_label != '-'][columns_old].rename(columns=name_mapping)\n",
    "dev = dev.loc[dev.gold_label != '-'][columns_old].rename(columns=name_mapping)\n",
    "test = test.loc[test.gold_label != '-'][columns_old].rename(columns=name_mapping)\n",
    "\n",
    "\n",
    "print(train.shape, dev.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A person on a horse jumps over a broken down a...</td>\n",
       "      <td>A person is training his horse for a competition.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A person on a horse jumps over a broken down a...</td>\n",
       "      <td>A person is at a diner, ordering an omelette.</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A person on a horse jumps over a broken down a...</td>\n",
       "      <td>A person is outdoors, on a horse.</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Children smiling and waving at camera</td>\n",
       "      <td>They are smiling at their parents</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Children smiling and waving at camera</td>\n",
       "      <td>There are children present</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             premise  \\\n",
       "0  A person on a horse jumps over a broken down a...   \n",
       "1  A person on a horse jumps over a broken down a...   \n",
       "2  A person on a horse jumps over a broken down a...   \n",
       "3              Children smiling and waving at camera   \n",
       "4              Children smiling and waving at camera   \n",
       "\n",
       "                                          hypothesis         target  \n",
       "0  A person is training his horse for a competition.        neutral  \n",
       "1      A person is at a diner, ordering an omelette.  contradiction  \n",
       "2                  A person is outdoors, on a horse.     entailment  \n",
       "3                  They are smiling at their parents        neutral  \n",
       "4                         There are children present     entailment  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "entailment       0.333868\n",
       "contradiction    0.333451\n",
       "neutral          0.332681\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.target.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "entailment       0.338244\n",
       "contradiction    0.333062\n",
       "neutral          0.328693\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev.target.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "entailment       0.342834\n",
       "contradiction    0.329499\n",
       "neutral          0.327667\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.target.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pickle\n",
    "\n",
    "from multiprocessing import cpu_count\n",
    "from sklearn.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = train.sample()\n",
    "trgt = sample.target.values[0]\n",
    "prem = sample.premise.values[0]\n",
    "hyp = sample.hypothesis.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contradiction\n",
      "Woman in red shirt walking back from bowling lane.\n",
      "A woman is walking in the right-turn-only lane.\n"
     ]
    }
   ],
   "source": [
    "print(trgt)\n",
    "print(prem)\n",
    "print(hyp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacy_pipe(df, save_pkl=None, batch_size=4096):\n",
    "    \n",
    "    prems = nlp.pipe(df[\"premise\"].values, n_threads=4, batch_size=batch_size)\n",
    "    hyps = nlp.pipe(df[\"hypothesis\"].values, n_threads=4, batch_size=batch_size)\n",
    "    res = zip(prems, hyps, df[\"target\"].values)\n",
    "    res = pd.DataFrame(res, columns=columns_new)\n",
    "    \n",
    "    if save_pkl:\n",
    "        res.to_pickle(save_pkl)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling:\n",
      "0.25.3\n",
      "2.2.4\n"
     ]
    }
   ],
   "source": [
    "print(\"Pickling:\", pd.__version__, spacy.__version__, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(549361, 3)\n",
      "CPU times: user 3min 23s, sys: 7.18 s, total: 3min 30s\n",
      "Wall time: 3min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "try:\n",
    "    train = pd.read_pickle(\"train.pkl\")\n",
    "except FileNotFoundError:\n",
    "    train = spacy_pipe(train, save_pkl=\"train.pkl\")\n",
    "    train.to_pickle('train.pkl')\n",
    "\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9842, 3)\n",
      "CPU times: user 11.5 s, sys: 491 ms, total: 12 s\n",
      "Wall time: 12.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "try:\n",
    "    dev = pd.read_pickle(\"dev.pkl\")\n",
    "except FileNotFoundError:\n",
    "    dev = spacy_pipe(train, save_pkl=\"dev.pkl\")\n",
    "    dev.to_pickle('dev.pkl')\n",
    "\n",
    "print(dev.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9824, 3)\n",
      "CPU times: user 11.8 s, sys: 492 ms, total: 12.3 s\n",
      "Wall time: 12.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "try:\n",
    "    test = pd.read_pickle(\"test.pkl\")\n",
    "except FileNotFoundError:\n",
    "    test = spacy_pipe(test)\n",
    "    test.to_pickle('test.pkl')\n",
    "\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10k sample for testing hypothesises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "entailment       183414\n",
       "contradiction    183185\n",
       "neutral          182762\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data = train.sample(10000)\n",
    "# dev_sample = dev.sample(1000)\n",
    "# test_sample = test.sample(1000)\n",
    "\n",
    "data = train#.sample(100000)\n",
    "dev_sample = dev\n",
    "test_sample = test\n",
    "\n",
    "data.target.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>premise</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>&lt;lambda&gt;</th>\n",
       "      <th>&lt;lambda&gt;</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>contradiction</th>\n",
       "      <td>8.226279</td>\n",
       "      <td>14.144821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entailment</th>\n",
       "      <td>7.470973</td>\n",
       "      <td>14.143626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>9.131039</td>\n",
       "      <td>14.144067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              hypothesis    premise\n",
       "                <lambda>   <lambda>\n",
       "target                             \n",
       "contradiction   8.226279  14.144821\n",
       "entailment      7.470973  14.143626\n",
       "neutral         9.131039  14.144067"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('target')['hypothesis', 'premise'].agg([lambda x: x.apply(len).mean()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tkn_num_baseline(prem, hyp):\n",
    "    prem_len = len(prem)\n",
    "    hyp_len = len(hyp)\n",
    "    if prem_len - hyp_len < 5:\n",
    "        return 'neutral'\n",
    "    if prem_len - hyp_len < 7:\n",
    "        return 'contradiction'\n",
    "    else:\n",
    "        return 'entailment'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "contradiction       0.31      0.12      0.18      3237\n",
      "   entailment       0.37      0.49      0.42      3368\n",
      "      neutral       0.37      0.48      0.42      3219\n",
      "\n",
      "    micro avg       0.37      0.37      0.37      9824\n",
      "    macro avg       0.35      0.36      0.34      9824\n",
      " weighted avg       0.35      0.37      0.34      9824\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = test.apply(lambda x: tkn_num_baseline(x.premise, x.hypothesis), 1)\n",
    "\n",
    "print(classification_report(test['target'], pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "\n",
    "from nltk import bigrams\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.meteor_score import single_meteor_score\n",
    "\n",
    "from rouge import Rouge\n",
    "from jiwer import wer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def syn_overlap(prem_tokens, hyp_tokens):\n",
    "    pos_map = {'NOUN': wn.NOUN, 'VERB': wn.VERB,\n",
    "               'ADJ': wn.ADJ, 'ADV': wn.ADV}\n",
    "    \n",
    "    common_tokens = token_pos_intersect(prem_tokens, hyp_tokens)\n",
    "    overlap_count = 0\n",
    "    for pair in common_tokens:\n",
    "        synsets = wn.synsets(pair[0][0], pos = pos_map.get(pair[0][1], None))\n",
    "        if len(synsets) == 0:\n",
    "            continue\n",
    "        synonyms = sum([item.lemma_names()for item in synsets], [])\n",
    "        if pair[1][0] in synonyms:\n",
    "            overlap_count += 1\n",
    "    return overlap_count, overlap_count/len(prem_tokens)\n",
    "\n",
    "\n",
    "def token_pos_intersect(prem_tokens, hyp_tokens):\n",
    "    res = []\n",
    "    for i in prem_tokens:\n",
    "        for j in hyp_tokens:\n",
    "            if i[1] == j[1]:\n",
    "                res.append((i, j))\n",
    "    return list(set(res))\n",
    "\n",
    "\n",
    "def token_pos_filter(tokens, pos):\n",
    "    if pos == 'NOUN':\n",
    "        return [token[0] for token in tokens if token[1] in ('PROPN', 'NOUN')]\n",
    "    else:\n",
    "        return [token[0] for token in tokens if token[1] == pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge = Rouge()\n",
    "\n",
    "def get_features(prem, hyp):   \n",
    "    if isinstance(prem, str):\n",
    "        prem = nlp(prem)\n",
    "    if isinstance(hyp, str):\n",
    "        hyp = nlp(hyp)\n",
    "        \n",
    "    prem_lem_pos = [(t.lemma_, t.pos_) for t in prem if not t.is_punct]\n",
    "    hyp_lem_pos = [(t.lemma_, t.pos_) for t in hyp if not t.is_punct]\n",
    "    \n",
    "    prem_lem = [t.lemma_ for t in prem if not t.is_punct]\n",
    "    hyp_lem = [t.lemma_ for t in hyp if not t.is_punct]\n",
    "    bi_prem_lem = list(bigrams(prem_lem))\n",
    "    bi_hyp_lem = list(bigrams(hyp_lem))\n",
    "    \n",
    "    prem_lemma_txt = \" \".join(prem_lem)\n",
    "    hyp_lemma_txt = \" \".join(hyp_lem)\n",
    "    \n",
    "    lemma_overlap = list(set(prem_lem).intersection(set(hyp_lem)))\n",
    "    lemma_overlap_count = len(lemma_overlap)\n",
    "    lemma_overlap_ratio = lemma_overlap_count/len(set(prem_lem))\n",
    "    bigram_overlap = list(set(list(bi_prem_lem)).intersection(set(list(bi_hyp_lem))))\n",
    "    \n",
    "    syn_overlap_count, syn_overlap_ratio = syn_overlap(prem_lem_pos, hyp_lem_pos)\n",
    "            \n",
    "    prem_nouns = set(token_pos_filter(prem_lem_pos, 'NOUN'))\n",
    "    noun_overlap = prem_nouns.intersection(set(token_pos_filter(hyp_lem_pos, 'NOUN')))\n",
    "    noun_overlap_count = len(noun_overlap)\n",
    "    noun_overlap_ratio = noun_overlap_count / len(prem_nouns) if len(prem_nouns) > 0 else 0\n",
    "    \n",
    "    prem_verbs = set(token_pos_filter(prem_lem_pos, 'VERB'))\n",
    "    verb_overlap = prem_verbs.intersection(set(token_pos_filter(hyp_lem_pos, 'VERB')))\n",
    "    verb_overlap_count = len(verb_overlap)\n",
    "    verb_overlap_ratio = verb_overlap_count / len(prem_verbs) if len(prem_verbs) > 0 else 0\n",
    "    \n",
    "    prem_adjs = set(token_pos_filter(prem_lem_pos, 'ADJ'))\n",
    "    adj_overlap = prem_adjs.intersection(set(token_pos_filter(hyp_lem_pos, 'ADJ')))\n",
    "    adj_overlap_count = len(adj_overlap)\n",
    "    adj_overlap_ratio = adj_overlap_count / len(prem_adjs) if len(prem_adjs) > 0 else 0\n",
    "    \n",
    "    prem_advs = set(token_pos_filter(prem_lem_pos, 'ADV'))\n",
    "    adv_overlap = prem_advs.intersection(set(token_pos_filter(hyp_lem_pos, 'ADV')))\n",
    "    adv_overlap_count = len(adv_overlap)\n",
    "    adv_overlap_ratio = adv_overlap_count / len(prem_advs) if len(prem_advs) > 0 else 0\n",
    "    \n",
    "    rouge_scores = rouge.get_scores(hyps=hyp_lemma_txt, refs=prem_lemma_txt)[0]\n",
    "\n",
    "    features = {\n",
    "        # base features\n",
    "        'prem_lem_len': len(prem_lem),\n",
    "        'hyp_lem_len': len(hyp_lem),\n",
    "        # overlap features\n",
    "        'lemma_overlap_count': lemma_overlap_count,\n",
    "        'lemma_overlap_ratio': lemma_overlap_ratio,\n",
    "        'noun_overlap_count': noun_overlap_count,\n",
    "        'noun_overlap_ratio': noun_overlap_ratio,\n",
    "        'verb_overlap_count': verb_overlap_count,\n",
    "        'verb_overlap_ratio': verb_overlap_ratio,\n",
    "        'adj_overlap_count': adj_overlap_count,\n",
    "        'adj_overlap_ratio': adj_overlap_ratio,\n",
    "        'adv_overlap_count': adv_overlap_count,\n",
    "        'adv_overlap_ratio': adv_overlap_ratio,\n",
    "        # WordNet synonyms intersection\n",
    "        'syn_overlap_count': syn_overlap_count,\n",
    "        'syn_overlap_ratio': syn_overlap_ratio,\n",
    "        # BLEU\n",
    "        'bleu1': sentence_bleu([prem_lem], hyp_lem, weights=(1, 0, 0, 0)),\n",
    "        'bleu2': sentence_bleu([prem_lem], hyp_lem, weights=(0, 1, 0, 0)),\n",
    "        'bleu3': sentence_bleu([prem_lem], hyp_lem, weights=(0, 0, 1, 0)),\n",
    "        'bleu4': sentence_bleu([prem_lem], hyp_lem, weights=(0, 0, 0, 1)),\n",
    "        'bleu_cum': sentence_bleu([prem_lem], hyp_lem, weights=(0.25, 0.25, 0.25, 0.25)),\n",
    "        # Rouge\n",
    "        \"rouge-1-f\": rouge_scores.get('rouge-1', {}).get('f', 0),\n",
    "        \"rouge-2-f\": rouge_scores.get('rouge-2', {}).get('f', 0),\n",
    "        \"rouge-l-f\": rouge_scores.get('rouge-l', {}).get('f', 0),\n",
    "        # Word accuracy\n",
    "        \"wacc\": 1 - wer(prem_lemma_txt, hyp_lemma_txt),\n",
    "        # METEOR\n",
    "        \"meteor\": single_meteor_score(reference=prem_lemma_txt, hypothesis=hyp_lemma_txt),\n",
    "    }\n",
    "    # unigrams and bigrams for premise\n",
    "    for gram in prem_lem:\n",
    "        features[f'prem_{gram}'] = features.get(f'prem_{gram}', 0) + 1\n",
    "    for gram in bi_prem_lem:\n",
    "        features[f'prem_{gram[0]}_{gram[1]}'] = features.get(f'prem_{gram[0]}_{gram[1]}', 0) + 1\n",
    "    # unigrams and bigrams for hypothesis\n",
    "    for gram in hyp_lem:\n",
    "        features[f'hyp_{gram}'] = features.get(f'hyp_{gram}', 0) + 1\n",
    "    for gram in bi_hyp_lem:\n",
    "        features[f'hyp_{gram[0]}_{gram[1]}'] = features.get(f'hyp_{gram[0]}_{gram[1]}', 0) + 1\n",
    "    # unigrams and bigrams for overlaping\n",
    "    for gram in lemma_overlap:\n",
    "        features[f'common_{gram}'] = features.get(f'common_{gram}', 0) + 1\n",
    "    for gram in bigram_overlap:\n",
    "        features[f'common_{gram[0]}_{gram[1]}'] = features.get(f'common_{gram[0]}_{gram[1]}', 0) + 1\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Woman in red shirt walking back from bowling lane.\n",
      "A woman is walking in the right-turn-only lane.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'prem_lem_len': 9,\n",
       " 'hyp_lem_len': 10,\n",
       " 'lemma_overlap_count': 4,\n",
       " 'lemma_overlap_ratio': 0.4444444444444444,\n",
       " 'noun_overlap_count': 2,\n",
       " 'noun_overlap_ratio': 0.5,\n",
       " 'verb_overlap_count': 1,\n",
       " 'verb_overlap_ratio': 1.0,\n",
       " 'adj_overlap_count': 0,\n",
       " 'adj_overlap_ratio': 0.0,\n",
       " 'adv_overlap_count': 0,\n",
       " 'adv_overlap_ratio': 0.0,\n",
       " 'syn_overlap_count': 4,\n",
       " 'syn_overlap_ratio': 0.4444444444444444,\n",
       " 'bleu1': 0.4,\n",
       " 'bleu2': 2.2250738585072626e-308,\n",
       " 'bleu3': 2.2250738585072626e-308,\n",
       " 'bleu4': 2.2250738585072626e-308,\n",
       " 'bleu_cum': 1.4488496539373276e-231,\n",
       " 'rouge-1-f': 0.42105262659279785,\n",
       " 'rouge-2-f': 0.0,\n",
       " 'rouge-l-f': 0.31578946869806096,\n",
       " 'wacc': 0.11111111111111116,\n",
       " 'meteor': 0.21978021978021975,\n",
       " 'prem_woman': 1,\n",
       " 'prem_in': 1,\n",
       " 'prem_red': 1,\n",
       " 'prem_shirt': 1,\n",
       " 'prem_walk': 1,\n",
       " 'prem_back': 1,\n",
       " 'prem_from': 1,\n",
       " 'prem_bowling': 1,\n",
       " 'prem_lane': 1,\n",
       " 'prem_woman_in': 1,\n",
       " 'prem_in_red': 1,\n",
       " 'prem_red_shirt': 1,\n",
       " 'prem_shirt_walk': 1,\n",
       " 'prem_walk_back': 1,\n",
       " 'prem_back_from': 1,\n",
       " 'prem_from_bowling': 1,\n",
       " 'prem_bowling_lane': 1,\n",
       " 'hyp_a': 1,\n",
       " 'hyp_woman': 1,\n",
       " 'hyp_be': 1,\n",
       " 'hyp_walk': 1,\n",
       " 'hyp_in': 1,\n",
       " 'hyp_the': 1,\n",
       " 'hyp_right': 1,\n",
       " 'hyp_turn': 1,\n",
       " 'hyp_only': 1,\n",
       " 'hyp_lane': 1,\n",
       " 'hyp_a_woman': 1,\n",
       " 'hyp_woman_be': 1,\n",
       " 'hyp_be_walk': 1,\n",
       " 'hyp_walk_in': 1,\n",
       " 'hyp_in_the': 1,\n",
       " 'hyp_the_right': 1,\n",
       " 'hyp_right_turn': 1,\n",
       " 'hyp_turn_only': 1,\n",
       " 'hyp_only_lane': 1,\n",
       " 'common_woman': 1,\n",
       " 'common_lane': 1,\n",
       " 'common_walk': 1,\n",
       " 'common_in': 1}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(prem)\n",
    "print(hyp)\n",
    "\n",
    "get_features(prem, hyp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "549361it [17:03, 536.89it/s]\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels = [], []\n",
    "\n",
    "for i, row in tqdm(data.iterrows()):\n",
    "    train_features.append(get_features(row['premise'], row['hypothesis']))\n",
    "    train_labels.append(row['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9842it [00:19, 515.81it/s]\n"
     ]
    }
   ],
   "source": [
    "dev_features, dev_labels = [], []\n",
    "\n",
    "for i, row in tqdm(dev_sample.iterrows()):\n",
    "    dev_features.append(get_features(row['premise'], row['hypothesis']))\n",
    "    dev_labels.append(row['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9824it [00:18, 523.99it/s]\n"
     ]
    }
   ],
   "source": [
    "test_features, test_labels = [], []\n",
    "\n",
    "for i, row in tqdm(test_sample.iterrows()):\n",
    "    test_features.append(get_features(row['premise'], row['hypothesis']))\n",
    "    test_labels.append(row['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = DictVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 564659\n",
      "CPU times: user 20 s, sys: 586 ms, total: 20.6 s\n",
      "Wall time: 20.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_vec = vec.fit_transform(train_features)\n",
    "dev_vec = vec.transform(dev_features)\n",
    "test_vec = vec.transform(test_features)\n",
    "\n",
    "print(f\"Number of features: {len(vec.vocabulary_)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dima/anaconda3/envs/p36/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/dima/anaconda3/envs/p36/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:459: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l1', random_state=0, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf = LogisticRegression(penalty='l1', random_state=RANDOM_STATE)\n",
    "\n",
    "lr_clf.fit(train_vec, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "contradiction       0.78      0.77      0.78      3303\n",
      "   entailment       0.85      0.80      0.82      3555\n",
      "      neutral       0.69      0.75      0.72      2984\n",
      "\n",
      "    micro avg       0.78      0.78      0.78      9842\n",
      "    macro avg       0.77      0.77      0.77      9842\n",
      " weighted avg       0.78      0.78      0.78      9842\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = lr_clf.predict(dev_vec)\n",
    "\n",
    "print(classification_report(pred, dev_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "contradiction       0.76      0.77      0.77      3217\n",
      "   entailment       0.84      0.78      0.81      3616\n",
      "      neutral       0.69      0.75      0.72      2991\n",
      "\n",
      "    micro avg       0.77      0.77      0.77      9824\n",
      "    macro avg       0.77      0.77      0.77      9824\n",
      " weighted avg       0.77      0.77      0.77      9824\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = lr_clf.predict(test_vec)\n",
    "\n",
    "print(classification_report(pred, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "    \n",
       "        <table class=\"eli5-weights-wrapper\" style=\"border-collapse: collapse; border: none; margin-bottom: 1.5em;\">\n",
       "            <tr>\n",
       "                \n",
       "                    <td style=\"padding: 0.5em; border: 1px solid black; text-align: center;\">\n",
       "                        <b>\n",
       "    \n",
       "        y=contradiction\n",
       "    \n",
       "</b>\n",
       "\n",
       "top features\n",
       "                    </td>\n",
       "                \n",
       "                    <td style=\"padding: 0.5em; border: 1px solid black; text-align: center;\">\n",
       "                        <b>\n",
       "    \n",
       "        y=entailment\n",
       "    \n",
       "</b>\n",
       "\n",
       "top features\n",
       "                    </td>\n",
       "                \n",
       "                    <td style=\"padding: 0.5em; border: 1px solid black; text-align: center;\">\n",
       "                        <b>\n",
       "    \n",
       "        y=neutral\n",
       "    \n",
       "</b>\n",
       "\n",
       "top features\n",
       "                    </td>\n",
       "                \n",
       "            </tr>\n",
       "            <tr>\n",
       "                \n",
       "                    \n",
       "                        <td style=\"padding: 0px; border: 1px solid black; vertical-align: top;\">\n",
       "                            \n",
       "                                \n",
       "                                    \n",
       "                                    \n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; width: 100%;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature weights. Note that weights do not account for feature value scales, so if feature values have different scales, features with highest weights might not be the most important.\">\n",
       "                    Weight<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 83.81%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +6.845\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        hyp_nobody\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 85.69%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +5.737\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        hyp_noone\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 86.94%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +5.037\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        hyp_xbox\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 87.09%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +4.952\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        hyp_family_lose\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 87.24%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +4.869\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        hyp_a_career\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 87.25%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +4.868\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        hyp_Hitler\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 87.45%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +4.754\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        hyp_duet_to\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 87.45%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 26095 more positive &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 87.35%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 24087 more negative &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 87.35%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -4.810\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        hyp_be_ther\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 87.16%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -4.914\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        common_dart\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 87.10%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -4.948\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        common_frown\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 86.87%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -5.074\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        hyp_not_bald\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 86.86%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -5.079\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        hyp_no_cloud\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 86.34%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -5.367\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        hyp_not_indoor\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 86.29%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -5.395\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        common_unicycle\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 86.28%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -5.401\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        hyp_not_dry\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 86.09%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -5.509\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        hyp_not_all\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 85.49%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -5.853\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        hyp_not_alone\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 85.13%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -6.059\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        hyp_not_naked\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 84.51%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -6.426\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        hyp_not_currently\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 83.33%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -7.137\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        hyp_not_empty\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "                                \n",
       "                            \n",
       "                        </td>\n",
       "                    \n",
       "                        <td style=\"padding: 0px; border: 1px solid black; vertical-align: top;\">\n",
       "                            \n",
       "                                \n",
       "                                    \n",
       "                                    \n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; width: 100%;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature weights. Note that weights do not account for feature value scales, so if feature values have different scales, features with highest weights might not be the most important.\">\n",
       "                    Weight<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +9.257\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        hyp_coat_-PRON-\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 80.45%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +8.963\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        hyp_red_white\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 81.61%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +8.213\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        hyp_not_empty\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 82.62%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +7.573\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        hyp_proximity\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 82.67%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +7.546\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        hyp_turn_red\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 82.70%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +7.522\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        hyp_not_naked\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 82.91%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +7.391\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        hyp_collar_worker\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 83.98%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +6.742\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        hyp_not_all\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 84.52%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +6.421\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        hyp_after_bike\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 85.40%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +5.907\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        hyp_not_alone\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 85.48%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +5.856\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        hyp_har\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 85.57%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +5.805\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        hyp_Beth\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 85.61%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +5.786\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        hyp_not_blue\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 85.69%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +5.735\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        common_-PRON-_guest\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 86.07%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +5.519\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        hyp_be_ther\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 86.08%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +5.517\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        hyp_car_run\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 86.08%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 22258 more positive &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 85.79%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 23274 more negative &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 85.79%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -5.683\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        hyp_joyously\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 85.30%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -5.965\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        hyp_tall_human\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 82.37%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -7.729\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        hyp_nobody\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 80.71%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -8.790\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        common_red_white\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "                                \n",
       "                            \n",
       "                        </td>\n",
       "                    \n",
       "                        <td style=\"padding: 0px; border: 1px solid black; vertical-align: top;\">\n",
       "                            \n",
       "                                \n",
       "                                    \n",
       "                                    \n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; width: 100%;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature weights. Note that weights do not account for feature value scales, so if feature values have different scales, features with highest weights might not be the most important.\">\n",
       "                    Weight<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 82.75%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +7.495\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        hyp_joyously\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 85.71%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +5.726\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        hyp_tall_human\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 86.88%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +5.066\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        hyp_slim_human\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 87.34%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +4.816\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        hyp_huge_person\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 88.30%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +4.301\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        hyp_large_human\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 88.38%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +4.260\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        hyp_tall_person\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 88.41%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +4.247\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        hyp_not_enough\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 88.50%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +4.198\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        hyp_light_black\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 88.52%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +4.186\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        hyp_funny_human\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 88.52%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 29016 more positive &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 88.53%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 28239 more negative &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 88.53%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -4.185\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        hyp_Hitler\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 88.47%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -4.216\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        hyp_-PRON-_brush\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 87.83%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -4.553\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        hyp_have_live\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 87.72%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -4.609\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        hyp_enjoy_fun\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 87.66%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -4.645\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        hyp_about_whether\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 87.39%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -4.789\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        hyp_medicine_for\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 86.42%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -5.323\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        hyp_class_sprinter\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 86.34%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -5.369\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        hyp_happily_share\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 83.87%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -6.810\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        rouge-1-f\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 83.85%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -6.818\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        hyp_full_make\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 83.67%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -6.931\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        hyp_family_lose\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "                                \n",
       "                            \n",
       "                        </td>\n",
       "                    \n",
       "                \n",
       "            </tr>\n",
       "        </table>\n",
       "    \n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import eli5\n",
    "eli5.show_weights(lr_clf, vec=vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LigthGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_COMP = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_fscore(y_true, y_pred):\n",
    "    y_pred = y_pred.reshape(len(np.unique(y_true)), -1)\n",
    "    y_pred = y_pred.argmax(axis=0)\n",
    "    res = f1_score(y_true, y_pred, average='macro')\n",
    "    return 'macro_f1', res, True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8min 21s, sys: 18.5 s, total: 8min 39s\n",
      "Wall time: 4min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "t_svd = TruncatedSVD(n_components=N_COMP)\n",
    "\n",
    "train_trunc = t_svd.fit_transform(train_vec)\n",
    "dev_trunc = t_svd.transform(dev_vec)\n",
    "test_trunc = t_svd.transform(test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'num_class': 3,\n",
    "    'num_rounds': 10000,\n",
    "    'max_depth': -1,\n",
    "    'learning_rate': 0.01,\n",
    "    'num_leaves': 31,\n",
    "    'verbose': 100,\n",
    "    'early_stopping_rounds': 300,\n",
    "    'min_data_in_leaf': 30,\n",
    "    'lambda_l2': 0.7,\n",
    "    'feature_fraction': 0.7,\n",
    "    'metric': 'custom',\n",
    "    'random_state': RANDOM_STATE\n",
    "}\n",
    "\n",
    "lgb_clf = LGBMClassifier(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\tvalid_0's macro_f1: 0.552371\n",
      "[200]\tvalid_0's macro_f1: 0.563179\n",
      "[300]\tvalid_0's macro_f1: 0.568266\n",
      "[400]\tvalid_0's macro_f1: 0.574213\n",
      "[500]\tvalid_0's macro_f1: 0.581709\n",
      "[600]\tvalid_0's macro_f1: 0.5854\n",
      "[700]\tvalid_0's macro_f1: 0.590595\n",
      "[800]\tvalid_0's macro_f1: 0.594405\n",
      "[900]\tvalid_0's macro_f1: 0.600819\n",
      "[1000]\tvalid_0's macro_f1: 0.606922\n",
      "[1100]\tvalid_0's macro_f1: 0.610817\n",
      "[1200]\tvalid_0's macro_f1: 0.613504\n",
      "[1300]\tvalid_0's macro_f1: 0.616452\n",
      "[1400]\tvalid_0's macro_f1: 0.616313\n",
      "[1500]\tvalid_0's macro_f1: 0.61826\n",
      "[1600]\tvalid_0's macro_f1: 0.620515\n",
      "[1700]\tvalid_0's macro_f1: 0.622336\n",
      "[1800]\tvalid_0's macro_f1: 0.624225\n",
      "[1900]\tvalid_0's macro_f1: 0.624635\n",
      "[2000]\tvalid_0's macro_f1: 0.626886\n",
      "[2100]\tvalid_0's macro_f1: 0.628148\n",
      "[2200]\tvalid_0's macro_f1: 0.62941\n",
      "[2300]\tvalid_0's macro_f1: 0.631259\n",
      "[2400]\tvalid_0's macro_f1: 0.63311\n",
      "[2500]\tvalid_0's macro_f1: 0.634187\n",
      "[2600]\tvalid_0's macro_f1: 0.635844\n",
      "[2700]\tvalid_0's macro_f1: 0.636182\n",
      "[2800]\tvalid_0's macro_f1: 0.637071\n",
      "[2900]\tvalid_0's macro_f1: 0.637409\n",
      "[3000]\tvalid_0's macro_f1: 0.638123\n",
      "[3100]\tvalid_0's macro_f1: 0.639027\n",
      "[3200]\tvalid_0's macro_f1: 0.639842\n",
      "[3300]\tvalid_0's macro_f1: 0.640158\n",
      "[3400]\tvalid_0's macro_f1: 0.640765\n",
      "[3500]\tvalid_0's macro_f1: 0.641082\n",
      "[3600]\tvalid_0's macro_f1: 0.642758\n",
      "[3700]\tvalid_0's macro_f1: 0.644299\n",
      "[3800]\tvalid_0's macro_f1: 0.644534\n",
      "[3900]\tvalid_0's macro_f1: 0.646392\n",
      "[4000]\tvalid_0's macro_f1: 0.646395\n",
      "[4100]\tvalid_0's macro_f1: 0.646196\n",
      "[4200]\tvalid_0's macro_f1: 0.647804\n",
      "[4300]\tvalid_0's macro_f1: 0.64788\n",
      "[4400]\tvalid_0's macro_f1: 0.648408\n",
      "[4500]\tvalid_0's macro_f1: 0.64881\n",
      "[4600]\tvalid_0's macro_f1: 0.65056\n",
      "[4700]\tvalid_0's macro_f1: 0.649317\n",
      "[4800]\tvalid_0's macro_f1: 0.649728\n",
      "Early stopping, best iteration is:\n",
      "[4599]\tvalid_0's macro_f1: 0.65056\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "        early_stopping_rounds=300, feature_fraction=0.7,\n",
       "        importance_type='split', lambda_l2=0.7, learning_rate=0.01,\n",
       "        max_depth=-1, metric='custom', min_child_samples=20,\n",
       "        min_child_weight=0.001, min_data_in_leaf=30, min_split_gain=0.0,\n",
       "        n_estimators=100, n_jobs=-1, num_class=3, num_leaves=31,\n",
       "        num_rounds=10000, objective=None, random_state=0, reg_alpha=0.0,\n",
       "        reg_lambda=0.0, silent=True, subsample=1.0,\n",
       "        subsample_for_bin=200000, subsample_freq=0, verbose=100)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_clf.fit(\n",
    "    X=train_trunc,\n",
    "    y=train_labels,\n",
    "    eval_set=[(dev_trunc, dev_labels)],\n",
    "    verbose=params['verbose'],\n",
    "    eval_metric=lgb_fscore,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "contradiction       0.63      0.64      0.63      3249\n",
      "   entailment       0.72      0.69      0.71      3464\n",
      "      neutral       0.60      0.62      0.61      3129\n",
      "\n",
      "    micro avg       0.65      0.65      0.65      9842\n",
      "    macro avg       0.65      0.65      0.65      9842\n",
      " weighted avg       0.65      0.65      0.65      9842\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = lgb_clf.predict(dev_trunc)\n",
    "\n",
    "print(classification_report(pred, dev_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "contradiction       0.64      0.65      0.65      3228\n",
      "   entailment       0.73      0.70      0.71      3524\n",
      "      neutral       0.59      0.62      0.60      3072\n",
      "\n",
      "    micro avg       0.66      0.66      0.66      9824\n",
      "    macro avg       0.65      0.65      0.65      9824\n",
      " weighted avg       0.66      0.66      0.66      9824\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = lgb_clf.predict(test_trunc)\n",
    "\n",
    "print(classification_report(pred, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:p36] *",
   "language": "python",
   "name": "conda-env-p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
