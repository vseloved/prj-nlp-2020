
# Homework 3

## Problem 1: Synonyms extraction from wiktionary

Парсив сторінки німецького wiktionary з типом контенту `text/x-wiki` та без двокрапки у заголовку.

Ігнорував, якщо для заголовку сторінки чи всього синонімічного ряду вдалося
надійно визначити мову як *не* німецьку.

Рядів отримано: `57 076`

Від усього сміття позбутися не вдалося, але фільтр по мові обрізав
здається десь під пару десятків тисяч рядів.


## Problem 3: Inter-annotator agreement for text corrections

Спостереження 1. Перелік виправлень в якихось позиціях проанотованого речення,
означає неявний вердикт про відсутність помилок (`noop`) у всіх інших позиціях.

Спостереження 2. Виправлення, в такому вигляді як вони представлені у корпусі,
неможливо порівнювати між собою. Наприклад:

    S At the same time , we are prepared to know when there are other members got this disease .
    A 15 15|||Ssub|||who have|||REQUIRED|||-NONE-|||0
    A 15 15|||Ssub|||who|||REQUIRED|||-NONE-|||1
    A 15 15|||Vt|||have|||REQUIRED|||-NONE-|||1
    A 15 15|||Ssub|||who have|||REQUIRED|||-NONE-|||2
    A 17 17|||ArtOrDet||||||REQUIRED|||-NONE-|||2

Тому розглядав два напрямки думок для розв'язку:
1. Порівнювати речення які виходять у анотувальників після застосування виправлень.
2. Відобразити виправлення у об'єкти що можна буде порівнювати.

Перший підхід втрачає інформацію про типи помилок, а обчислити статистику по ним є частиною завдання.
У змаганнях CoNLL-2014 Shared Task для порівняння якості виправлень машиних систем із gold standard
[порівнювались множини елементарних операцій][1] редагувань токенів, обчислювався F1 score.
Самі множини операцій редагування отримувались як такі, що
[мінімізують відстань редагування][2] для послідовностей токенів.
Це, поміж іншого, дозволяло уникнути неоднозначності представлення та робило ці множини порівнюваними.

[1]: https://www.aclweb.org/anthology/W14-1701/
[2]: https://www.aclweb.org/anthology/N12-1067/

З огляду на все це я вирішив йти другим підходом - по наявному корпусу виправлень побудувати множини
елементарних операцій редагування токенів які були б порівнювані між собою.
А потім попарно для анотувальників обчислити F1 score на цих множинах.

Модель міток для анотування є такою: `edit := (region, tokens, type)`, де
`region` - напіввідкритий інтервал позицій токенів які треба видалити в початковому тексті,
`tokens` - список токенів для вставки в текст в позиції початку інтервала `region`,
`type` - тип мітки (`None` означає відсутність анотування).

Це дозволило привести анотації в корпусі до однорідного вигляду -
всі речення мають мітки виправлень, та інтервали виправлень покривають без пропусків увесь текст.

Також це дозволило конкатенувати всі речення у єдину послідовність токенів,
анотації конкатенуються простим перенумеруванням індексів в інтервалах.
Тепер немає проблеми агрегувати результати порівнянь речень у загальний результат по тексту
(мені здається якоїсь хорошої функції агрегації не існує).

Останнім кроком є розбиття всіх міток виправлень на мітки редагування *окремих токенів*:
відсутність анотації, видалення, вставка, заміна.
При цьому втрачається інформація про групування помилок, але отримані множини
операцій однозначно описують результат редагування та стають порівнюваними між собою.

Таким чином, отримано:
1. увесь початковий текст як послідовність токенів
2. відображення: анотувальник → множина редагувань окремих токенів в тексті

Для деяких анотувальників набори речень які вони перевіряли сильно відрізняються,
тож якщо просто порахувати метрики по отриманим множинам то навряд вони матимуть
якийсь сенс (вони наявні у результатах із `transforms: []`).

Тож всі подальші попарні порівняння робити має сенс тільки на токенах що перевірялися
обома анотувальниками (`filter_both_annotators_saw_token`).
Можливо можна було б ще якось нормувати на величини перетину та симметричної різницю,
але в мене не було вже часу особливо подумати чи дослідити.

Результати порівняння множин міток редагувань *із урахуванням типу помилок*:

    f1_a_mean: 0.8656
    f1_median: 0.8682
    pairs:
        [0, 1]: [0.8303, 27720, 28105, 23176]
        [0, 2]: [0.8841, 10124, 10200, 8984]
        [0, 3]: [0.8781, 2249, 2288, 1992]
        [0, 4]: [0.8815, 210, 212, 186]
        [1, 2]: [0.8612, 10266, 10200, 8813]
        [1, 3]: [0.8751, 2283, 2288, 2000]
        [1, 4]: [0.8485, 217, 212, 182]
        [2, 3]: [0.8806, 2270, 2288, 2007]
        [2, 4]: [0.8578, 210, 212, 181]
        [3, 4]: [0.8585, 212, 212, 182]
    transforms: [filter_both_annotators_saw_token]

Можливо розумніше було б приписати різні ваги до співпадіння самих виправлень,
та співпадіння типу помилок... Але адекватного способу для F1 score я не придумав,
а на розкопки теми не було часу. Може ще колись посиджу над оцінками умовних імовірностей
та пов'язаними з ними статистиками.

Результати порівняння множин міток редагувань *без урахування типу помилок*:

    f1_a_mean: 0.9086
    f1_median: 0.9134
    pairs:
        [0, 1]: [0.8814, 27720, 28105, 24602]
        [0, 2]: [0.919, 10124, 10200, 9339]
        [0, 3]: [0.9165, 2249, 2288, 2079]
        [0, 4]: [0.9194, 210, 212, 194]
        [1, 2]: [0.9042, 10266, 10200, 9253]
        [1, 3]: [0.921, 2283, 2288, 2105]
        [1, 4]: [0.8858, 217, 212, 190]
        [2, 3]: [0.9188, 2270, 2288, 2094]
        [2, 4]: [0.91, 210, 212, 192]
        [3, 4]: [0.9104, 212, 212, 193]
    transforms: [filter_both_annotators_saw_token, erase_all_edit_types]

Ще цікаво подивитись на узгодженність позицій відсутності виправлень:

    f1_a_mean: 0.942
    f1_median: 0.9446
    pairs:
        [0, 1]: [0.932, 24525, 23588, 22420]
        [0, 2]: [0.9492, 8832, 8688, 8315]
        [0, 3]: [0.95, 1942, 1879, 1815]
        [0, 4]: [0.9452, 175, 172, 164]
        [1, 2]: [0.9439, 8570, 8688, 8145]
        [1, 3]: [0.9534, 1878, 1879, 1791]
        [1, 4]: [0.9352, 183, 172, 166]
        [2, 3]: [0.9507, 1931, 1879, 1811]
        [2, 4]: [0.933, 186, 172, 167]
        [3, 4]: [0.927, 184, 172, 165]
    transforms: [filter_both_annotators_saw_token, edit.type == noop]

А також окремо на узгодженність лише самих результатів виправлень:

    f1_a_mean: 0.4999
    f1_median: 0.5046
    pairs:
        [0, 1]: [0.2819, 3195, 4517, 1087]
        [0, 2]: [0.5093, 1292, 1512, 714]
        [0, 3]: [0.5223, 307, 409, 187]
        [0, 4]: [0.6133, 35, 40, 23]
        [1, 2]: [0.4869, 1696, 1512, 781]
        [1, 3]: [0.6069, 405, 409, 247]
        [1, 4]: [0.4324, 34, 40, 16]
        [2, 3]: [0.5775, 339, 409, 216]
        [2, 4]: [0.4688, 24, 40, 15]
        [3, 4]: [0.5, 28, 40, 17]
    transforms: [filter_both_annotators_saw_token, edit.type != noop, erase_all_edit_types]

Та на узгодженність множин позицій, в яких, на думку анотаторів, є виправлення:

    f1_a_mean: 0.6096
    f1_median: 0.5978
    pairs:
        [0, 1]: [0.4473, 3102, 4406, 1679]
        [0, 2]: [0.5893, 1253, 1479, 805]
        [0, 3]: [0.6416, 297, 395, 222]
        [0, 4]: [0.72, 35, 40, 27]
        [1, 2]: [0.6063, 1655, 1479, 950]
        [1, 3]: [0.699, 389, 395, 274]
        [1, 4]: [0.5833, 32, 40, 21]
        [2, 3]: [0.6584, 328, 395, 238]
        [2, 4]: [0.5625, 24, 40, 18]
        [3, 4]: [0.5882, 28, 40, 20]
    transforms: [filter_both_annotators_saw_token, edit.type != noop, erase_all_edit_types, erase_all_tokens]

Всі результати можна знайти у [файлі](./output/3.agreement.results.yaml).
