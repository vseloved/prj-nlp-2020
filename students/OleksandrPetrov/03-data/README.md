
# Homework 3

## Problem 1: Synonyms extraction from wiktionary

Парсив сторінки німецького wiktionary з типом контенту `text/x-wiki` та без двокрапки у заоголовку.

Ігнорував, якщо ля заголовку сторінки чи всього синонімічного ряду вдалося
надійно визначити мову як не німецьку.

Рядів отримано: `57076`

Від усього сміття позбутися не вдалося, але фільтр по мові обрізав
здається десь пару десятків тисяч рядів.


## Problem 3: Inter-annotator agreement for text corrections

Спостереження 1. Перелік виправлень в якихось позиціях проанотованого речення,
означає неявний вердикт про відсутність помилок (`noop`) у всіх інших позиціях.

Спостереження 2. Виправлення, в такому вигляді як вони представлені у корпусі,
неможливо порівнювати між собою. Наприклад:

    S At the same time , we are prepared to know when there are other members got this disease .
    A 15 15|||Ssub|||who have|||REQUIRED|||-NONE-|||0
    A 15 15|||Ssub|||who|||REQUIRED|||-NONE-|||1
    A 15 15|||Vt|||have|||REQUIRED|||-NONE-|||1
    A 15 15|||Ssub|||who have|||REQUIRED|||-NONE-|||2
    A 17 17|||ArtOrDet||||||REQUIRED|||-NONE-|||2

Тому розглядав два напрямки думок для розв'язку:
1. Порівнювати речення які виходять у анотувальників після застосування виправлень.
2. Відобразити виправлення у об'єкти що можна буде порівнювати.

Перший підхід втрачає інформацію про типи помилок, а обчислити статистику по ним є частиною завдання.
У змаганнях CoNLL-2014 Shared Task для порівняння якості виправлень машиних систем із gold standard
[порівнювались множини елементарних операцій][1] редагувань токенів, обчислювався F1 score.
Самі множини операцій редагування отримувались як такі, що
[мінімізують відстань редагування][2] для послідовностей токенів.
Це, поміж іншого, дозволяло уникнути неоднозначності представлення та робило ці множини порівнюваними.

[1]: https://www.aclweb.org/anthology/W14-1701/
[2]: https://www.aclweb.org/anthology/N12-1067/

З огляду на все це я вирішив йти другим підходом - по наявному корпусу виправлень побудувати множини
елементарних операцій редагування токенів які були б порівнювані між собою.
А потім попарно для анотувальників обчислити F1 score на цих множинах.

Модель міток для анотування є такою: `edit := (region, tokens, type)`, де
`region` - напіввідкритий інтервал позицій токенів які треба видалити в початковому тексті,
`tokens` - список токенів для вставки в текст в позиції початку інтервала `region`,
`type` - тип мітки (`None` означає відсутність анотування).

Це дозволило привести анотації в корпусі до однорідного вигляду -
всі речення мають мітки виправлень, та інтервали виправлень покривають без пропусків увесь текст.

Також це дозволило конкатенувати всі речення у єдину послідовність токенів,
анотації конкатенуються простим перенумеруванням індексів в інтервалах.
Тепер немає проблеми агрегувати результати порівнянь речень у загальний результат по тексту
(мені здається якоїсь хорошої функції агрегації не існує).

Останнім кроком є розбиття всіх міток виправлень на мітки редагування *окремих токенів*:
відсутність анотації, видалення, вставка, заміна.
При цьому втрачається інформація про групування помилок, але отримані множини
операції однозначно описують результат редагування та стають порівнюваними між собою.

Таким чином, отримано:
* початковий текст = послідовність токенів
* розмітка: анотувальник --> множина редагувань окремих токенів

Для деяких анотувальників набори речень які вони перевіряли сильно відрізняються,
тож якщо просто порахувати метрики по отриманим множинам то навряд вони матимуть
якийсь сенс (вони наявні у результатах із `transforms: []`).

Тож всі подальші попарні порівняння робити має сенс тільки на токенах що перевірялися
обома анотувальниками (`filter_both_annotators_saw_token`).

Результати порівняння множин міток редагувань *із урахуванням типу помилок*:

    f1_a_mean: 0.1876
    f1_median: 0.14
    pairs:
        [0, 1]: [0.7945, 28981, 29358, 23176]
        [0, 2]: [0.3115, 28981, 28710, 8984]
        [0, 3]: [0.0693, 28981, 28509, 1992]
        [0, 4]: [0.0065, 28981, 28416, 186]
        [1, 2]: [0.3172, 28105, 27457, 8813]
        [1, 3]: [0.0723, 28105, 27256, 2000]
        [1, 4]: [0.0066, 28105, 27163, 182]
        [2, 3]: [0.1987, 10200, 9999, 2007]
        [2, 4]: [0.018, 10200, 9906, 181]
        [3, 4]: [0.0812, 2288, 2195, 182]
    transforms: [filter_both_annotators_saw_token]

Як бачимо, лише окремі пари анотувальників мають чималу узгодженність як щодо виправлень так і їх причин.
Для мене це виявилось трохи несподіванкою, я очікував низких результатів, але якось занадто низько.
(Спочатку я подумав що десь бага в коді, але див. результати без урахування типу помилок).

Можливо розумніше було б приписати різні ваги до співпадіння самих виправлень,
та співпадіння типу помилок... Але простого способу я не придумав, це потребує перегляду метрик.
Тож імхо виходить за рамки домашки.

Результати порівняння множин міток редагувань *без урахуванням типу помилок*:

    f1_a_mean: 0.9041
    f1_median: 0.9032
    pairs:
        [0, 1]: [0.884, 28981, 29358, 25787]
        [0, 2]: [0.9262, 28981, 28710, 26718]
        [0, 3]: [0.9268, 28981, 28509, 26640]
        [0, 4]: [0.9271, 28981, 28416, 26606]
        [1, 2]: [0.899, 28105, 27457, 24974]
        [1, 3]: [0.8951, 28105, 27256, 24777]
        [1, 4]: [0.8922, 28105, 27163, 24656]
        [2, 3]: [0.9051, 10200, 9999, 9141]
        [2, 4]: [0.9012, 10200, 9906, 9060]
        [3, 4]: [0.8842, 2288, 2195, 1982]
    transforms: [filter_both_annotators_saw_token, erase_all_edit_types]

Тут видно, що все насправді порівняно непогано/добре.
Розкид значень наче невеликий.
Люди мабуть інтуїтивно розуміють як має бути правильно значно краще ніж чому так має бути.

Ще цікаво подивитись на узгодженність щодо відсутності виправлень:

    f1_a_mean: 0.2739
    f1_median: 0.2518
    pairs:
        [0, 1]: [0.91, 25688, 23588, 22420]
        [0, 2]: [0.4838, 25688, 8688, 8315]
        [0, 3]: [0.1317, 25688, 1879, 1815]
        [0, 4]: [0.0127, 25688, 172, 164]
        [1, 2]: [0.5047, 23588, 8688, 8145]
        [1, 3]: [0.1407, 23588, 1879, 1791]
        [1, 4]: [0.014, 23588, 172, 166]
        [2, 3]: [0.3428, 8688, 1879, 1811]
        [2, 4]: [0.0377, 8688, 172, 167]
        [3, 4]: [0.1609, 1879, 172, 165]
    transforms: [filter_both_annotators_saw_token, edit.type == noop]

Величину цих чисел я поки що не знаю як пояснювати. Їх треба з чимось порівняти, з чим?
Але розкид значень теж виявився несподіванкою з огляду на маленький розкид в попередньому результаті.

Всі результати можна знайти у [файлі](./output/3.agreement.results.yaml).
